<!DOCTYPE HTML>
<html lang="en" class="sidebar-visible no-js light">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Machine Controller Manager Design</title>
        <meta name="robots" content="noindex" />


        <!-- Custom HTML head -->
        
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->

    </head>
    <body>
        <!-- Provide site root to javascript -->
        <script type="text/javascript">
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script type="text/javascript">
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script type="text/javascript">
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script type="text/javascript">
            var html = document.querySelector('html');
            var sidebar = 'hidden';
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded affix "><a href="intro.html">Introduction</a></li><li class="chapter-item expanded "><a href="k8s_facilities.html"><strong aria-hidden="true">1.</strong> Kubernetes Facilities</a></li><li class="chapter-item expanded "><a href="mcm_facilities.html"><strong aria-hidden="true">2.</strong> MCM Facilities</a></li><li class="chapter-item expanded "><a href="machine-controller/index.html"><strong aria-hidden="true">3.</strong> Machine Controller</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="machine-controller/reconcile-cluster-machine-class.html"><strong aria-hidden="true">3.1.</strong> Reconcile Cluster Machine Class</a></li><li class="chapter-item expanded "><a href="machine-controller/reconcile-cluster-secret.html"><strong aria-hidden="true">3.2.</strong> Reconcile Cluster Secret</a></li><li class="chapter-item expanded "><a href="machine-controller/cluster_machine_reconcile.html"><strong aria-hidden="true">3.3.</strong> Cluster Machine Reconciliation</a></li><li class="chapter-item expanded "><a href="machine-controller/mc_helper_methods.html"><strong aria-hidden="true">3.4.</strong> Machine Controller Helper Methods</a></li><li class="chapter-item expanded "><a href="machine-controller/node_drain.html"><strong aria-hidden="true">3.5.</strong> Node Drain</a></li></ol></li><li class="chapter-item expanded "><a href="issues.html"><strong aria-hidden="true">4.</strong> Issues</a></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky bordered">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light (default)</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">Machine Controller Manager Design</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script type="text/javascript">
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <ul>
<li><a href="intro.html#introduction">Introduction</a></li>
<li><a href="intro.html#change-log">Change Log</a></li>
</ul>
<p>Current location: <a href="https://elankath.github.io/mcmdesign/">MCM Design Book</a>. </p>
<p>(üöß Please see <a href="intro.html#change-log">Change Log</a> for new additions/corrections.Please Check on Oct 21th for v1.1 release!üèó)</p>
<h1 id="introduction"><a class="header" href="#introduction">Introduction</a></h1>
<p>A Kubernetes Controller is a program that watches for lifecycle events on specific resources and triggers one or more <em>reconcile</em> functions in response. A <em>reconcile function</em> is called with the <em>Namespace</em> and <em>Name</em> of an object corresponding to the resource and its job is to make the object <em>Status</em> match the declared state in the object <em>Spec</em>. </p>
<p>Machine Controller Manager aka MCM is a group of cooperative controllers that manage the lifecycle of the worker machines. A worker <code>Machine</code> is a provider specific VM/instance that corresponds to a k8s <a href="https://kubernetes.io/docs/concepts/architecture/nodes/">Node</a></p>
<p>The MCM project is divided into:</p>
<ol>
<li>The <a href="https://github.com/gardener/machine-controller-manager">MCM Module</a>. This contains 
<ol>
<li>The <a href="https://github.com/gardener/machine-controller-manager/blob/51cea3373d8be7c78aee3f7a4664ccd31f439269/pkg/controller/controller.go#L421">MCM Controller Type</a> and <a href="https://github.com/gardener/machine-controller-manager/blob/v0.47.0/pkg/controller/controller.go#L62">MCM Controller Factory Method</a>. The <code>MCM Controller</code> is responsible for reconciling the <code>MachineDeployment</code> and <code>MachineSet</code> custom resources. 
<ol>
<li>A <code>MachineDeployment</code> provides a declarative update for <code>MachineSet</code> and <code>Machines</code>. Analogous to k8s <a href="https://kubernetes.io/docs/concepts/workloads/controllers/deployment/">Deployments</a>. </li>
<li>A <code>MachineSet</code> ensures that the specified number of <code>Machine</code> replicas are running at a given point of time. Analogoues to k8s <a href="https://kubernetes.io/docs/concepts/workloads/controllers/replicaset/">ReplicaSets</a></li>
</ol>
</li>
<li><a href="https://github.com/gardener/machine-controller-manager/blob/v0.47.0/cmd/machine-controller-manager/controller_manager.go#L40">MCM Main</a> which creates and start s the MCM Controller.</li>
<li>The <a href="https://github.com/gardener/machine-controller-manager/blob/v0.47.0/pkg/util/provider/machinecontroller/controller.go#L252">MC Controller Type</a> and <a href="https://github.com/gardener/machine-controller-manager/blob/v0.47.0/pkg/util/provider/machinecontroller/controller.go#L77">MC Controller Factory Method</a>.
<ol>
<li>The <code>MC Controller</code> implements the reconciliation loop for <code>MachineClass</code> and <code>Machine</code> objects but delegates creation/updation/deletion/status-retrieval of Machines to the <code>Driver</code> facade. </li>
</ol>
</li>
<li>The <a href="https://github.com/gardener/machine-controller-manager/blob/v0.47.0/pkg/util/provider/driver/driver.go#L28">Driver</a> facade that abstracts away the lifecycle operations on Machines and obtaining Machine status.</li>
<li>Utility Code used provider modules (TODO: give internal links)</li>
</ol>
</li>
<li>The provider specific modules named as <code>machine-controller-manager-provider-&lt;providerName&gt;</code>. 
<ol>
<li>Contains a <em>main</em> file located at <code>cmd/machine-controller/main.go</code> that instantiate a <code>Driver</code> implementation (Ex: <a href="https://github.com/gardener/machine-controller-manager-provider-aws/blob/v0.13.0/pkg/aws/core.go#L56">AWSDriver</a>) and then create and start a <code>MC Controller</code> using the <a href="https://github.com/gardener/machine-controller-manager/blob/v0.47.0/pkg/util/provider/machinecontroller/controller.go#L77">MC Controller Factory Method</a>, passing the <code>Driver</code> impl.  In other worlds, each provider module starts its independent machine controller.</li>
<li>See <a href="https://github.com/gardener/machine-controller-manager/README.md">MCM README</a> for list of provider modules</li>
</ol>
</li>
</ol>
<p>The MCM leverages the <em>old-school</em> technique of writing controllers directly using <a href="https://github.com/kubernetes/sample-controller/blob/master/docs/controller-client-go.md">client-go</a>. Skeleton code for client types is generated using <a href="https://github.com/kubernetes/community/blob/master/contributors/devel/sig-api-machinery/generating-clientset.md">client-gen</a>. A barebones example is illustrated in the <a href="https://github.com/kubernetes/sample-controller">sample controller</a>. </p>
<p>The Modern Way of writing controllers is by leveraging the <a href="https://github.com/kubernetes-sigs/controller-runtime">Controller Runtime</a> and generating skeletal code fur custom controllers using the <a href="https://book.kubebuilder.io/quick-start.html">Kubebuilder Tool</a>.</p>
<p>The MCM has a planned backlog to port the project to the controller runtime. The details of this will be documented in a separate proposal. (TODO: link me). </p>
<p>This book describes the current design of the MCM in order to aid code comprehension for development, enhancement and migratiion/port activities.</p>
<h1 id="change-log"><a class="header" href="#change-log">Change Log</a></h1>
<ul>
<li><input disabled="" type="checkbox" checked=""/>
14th Oct 2022. Machine Health Reconciliation. See <a href="./machine-controller/cluster_machine_reconcile.html#controllerreconcilemachinehealth">Machine Health Reconcile</a></li>
<li><input disabled="" type="checkbox"/>
TODO: Reconcile Machine Safety Orphan VM's.</li>
<li><input disabled="" type="checkbox"/>
TODO: evictPodsWithPVInternal (complicated due to concurrent flow)</li>
<li><input disabled="" type="checkbox"/>
TODO: Machine Deployment Controller</li>
<li><input disabled="" type="checkbox"/>
TODO: reconcileClusterMachineSafetyAPIServer </li>
<li><input disabled="" type="checkbox"/>
TODO: Machine Status Diagram with actions/transitions (complicated due to concurrency)</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><ul>
<li><a href="k8s_facilities.html#kubernetes-client-facilities">Kubernetes Client Facilities</a>
<ul>
<li><a href="k8s_facilities.html#k8s-apimachinery">K8s apimachinery</a>
<ul>
<li><a href="k8s_facilities.html#k8s-objects">K8s objects</a>
<ul>
<li><a href="k8s_facilities.html#typemeta">TypeMeta</a></li>
<li><a href="k8s_facilities.html#objectmeta">ObjectMeta</a>
<ul>
<li><a href="k8s_facilities.html#ownerreferences">OwnerReferences</a></li>
<li><a href="k8s_facilities.html#finalizers-and-deletion">Finalizers and Deletion</a></li>
<li><a href="k8s_facilities.html#diff-between-labels-and-annotations">Diff between Labels and Annotations</a></li>
</ul>
</li>
<li><a href="k8s_facilities.html#api-errors">API Errors</a>
<ul>
<li><a href="k8s_facilities.html#errorsisnotfound">errors.IsNotFound</a></li>
<li><a href="k8s_facilities.html#errorsisnotfound-1">errors.IsNotFound</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="k8s_facilities.html#api-machinery-utilities">API Machinery Utilities</a>
<ul>
<li><a href="k8s_facilities.html#waituntil">wait.Until</a></li>
<li><a href="k8s_facilities.html#waitpollimmediate">wait.PollImmediate</a></li>
<li><a href="k8s_facilities.html#waitbackoff">wait.Backoff</a></li>
<li><a href="k8s_facilities.html#errors">Errors</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="k8s_facilities.html#k8s-api-core">K8s API Core</a>
<ul>
<li><a href="k8s_facilities.html#node">Node</a>
<ul>
<li><a href="k8s_facilities.html#nodespec">NodeSpec</a>
<ul>
<li><a href="k8s_facilities.html#node-taints">Node Taints</a></li>
</ul>
</li>
<li><a href="k8s_facilities.html#nodestatus">NodeStatus</a>
<ul>
<li><a href="k8s_facilities.html#capacity">Capacity</a></li>
<li><a href="k8s_facilities.html#conditions">Conditions</a>
<ul>
<li><a href="k8s_facilities.html#nodeconditiontype">NodeConditionType</a></li>
<li><a href="k8s_facilities.html#conditionstatus">ConditionStatus</a></li>
</ul>
</li>
<li><a href="k8s_facilities.html#nodesysteminfo">NodeSystemInfo</a></li>
<li><a href="k8s_facilities.html#images">Images</a></li>
<li><a href="k8s_facilities.html#attached-volumes">Attached Volumes</a></li>
</ul>
</li>
<li><a href="k8s_facilities.html#volumeattachment">VolumeAttachment</a></li>
<li><a href="k8s_facilities.html#volumeattachmentspec">VolumeAttachmentSpec</a></li>
</ul>
</li>
<li><a href="k8s_facilities.html#pod">Pod</a>
<ul>
<li><a href="k8s_facilities.html#pod-eviction">Pod Eviction</a></li>
<li><a href="k8s_facilities.html#pod-disruption-budget">Pod Disruption Budget</a>
<ul>
<li><a href="k8s_facilities.html#poddisruptionbudgetspec">PodDisruptionBudgetSpec</a></li>
<li><a href="k8s_facilities.html#poddisruptionbudgetstatus">PodDisruptionBudgetStatus</a></li>
</ul>
</li>
<li><a href="k8s_facilities.html#pod-volumes">Pod Volumes</a></li>
</ul>
</li>
<li><a href="k8s_facilities.html#persistentvolume">PersistentVolume</a>
<ul>
<li><a href="k8s_facilities.html#persistentvolumeclaim">PersistentVolumeClaim</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="k8s_facilities.html#client-go">client-go</a>
<ul>
<li><a href="k8s_facilities.html#client-go-shared-informers">client-go Shared Informers.</a></li>
<li><a href="k8s_facilities.html#client-go-workqueues">client-go workqueues</a></li>
<li><a href="k8s_facilities.html#client-go-controller-steps">client-go controller steps</a></li>
<li><a href="k8s_facilities.html#client-go-utilities">client-go utilities</a>
<ul>
<li><a href="k8s_facilities.html#k8sioclient-goutilretryretryonconflict">k8s.io/client-go/util/retry.RetryOnConflict</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="k8s_facilities.html#references">References</a></li>
</ul>
</li>
</ul>
<h1 id="kubernetes-client-facilities"><a class="header" href="#kubernetes-client-facilities">Kubernetes Client Facilities</a></h1>
<p>This chapter describes the types and functions provided by k8s core and client modules that are leveraged by the MCM - it only covers what is required to understand MCM code and is simply meant to be a helpful review. References are provided for further reading.</p>
<h2 id="k8s-apimachinery"><a class="header" href="#k8s-apimachinery">K8s apimachinery</a></h2>
<h3 id="k8s-objects"><a class="header" href="#k8s-objects">K8s objects</a></h3>
<p>A K8s object represents a persistent entity. When using the K8s client-go framework to define such an object, one should follow the rules:</p>
<ol>
<li>A Go type representing a object must embed the <a href="https://pkg.go.dev/k8s.io/apimachinery/pkg/apis/meta/v1#ObjectMeta">k8s.io/apimachinery/pkg/apis/meta/v1.ObjectMeta</a> struct. <code>ObjectMeta</code> is metadata that all persisted resources must have, which includes all objects users must create.</li>
<li>A Go type representing a <em>singluar</em> object must embed <a href="https://pkg.go.dev/k8s.io/apimachinery/pkg/apis/meta/v1#TypeMeta">k8s.io/apimachinery/pkg/apis/meta/v1.TypeMeta</a> which describes an <em>individual</em> object in an API response or request with strings representing the <em>Kind</em> of the object and its API schema version called <em>APIVersion</em>. </li>
</ol>
<pre class="mermaid">graph TB
    subgraph CustomType

    ObjectMeta
    TypeMeta
    end
</pre>
<ol start="3">
<li>A Go type representing a <em>list</em> of a custom type must embed <a href="https://pkg.go.dev/k8s.io/apimachinery/pkg/apis/meta/v1#ListMeta">k8s.io/apimachinery/pkg/apis/meta/v1.ListMeta</a></li>
</ol>
<pre class="mermaid">graph TB
    subgraph CustomTypeList

    ObjectMeta
    ListMeta
    end
</pre>
<h4 id="typemeta"><a class="header" href="#typemeta">TypeMeta</a></h4>
<pre><code class="language-go">type TypeMeta struct {
	// Kind is a string value representing the REST resource this object represents.
	Kind string 

	// APIVersion defines the versioned schema of this representation of an object.
	APIVersion string
}
</code></pre>
<h4 id="objectmeta"><a class="header" href="#objectmeta">ObjectMeta</a></h4>
<p>A snippet of <code>ObjectMeta</code> struct fields shown below for convenience with the MCM relevant fields that are used by controller code.</p>
<pre><code class="language-go">type ObjectMeta struct { //snippet 
    // Name must be unique within a namespace. Is required when creating resources,
    Name string 

    // Namespace defines the space within which each name must be unique. An empty namespace is  equivalent to the &quot;default&quot; namespace,
    Namespace string

    // An opaque value that represents the internal version of this object that can be used by clients to determine when objects have changed.
    ResourceVersion string

	// A sequence number representing a specific generation of the desired state.
	Generation int64 

    // UID is the unique in time and space value for this object. It is typically generated by the API server on successful creation of a resource and is not allowed to change on PUT operations.
    UID types.UID 

    // CreationTimestamp is a timestamp representing the server time when this object was  created.
    CreationTimestamp Time 

    // DeletionTimestamp is RFC 3339 date and time at which this resource will be deleted. This field is set by the server when a graceful deletion is requested by the user.  The resource is expected to be deleted (no longer reachable via APIs) after the time in this field, once the finalizers list is empty.
    DeletionTimestamp *Time


    // Must be empty before the object is deleted from the registry by the API server. Each entry is an identifier for the responsible controller that will remove the entry from the list.
    Finalizers []string 

    // Map of string keys and values that can be used to organize and categorize (scope and select) objects. Valid label keys have two segments: an optional prefix and name, separated by a slash (/).  Meant to be meaningful and relevant to USERS.
    Labels map[string]string

    // Annotations is an unstructured key value map stored with a resource that may be  set by controllers/tools to store and retrieve arbitrary metadata. Meant for TOOLS.
    Annotations map[string]string 

    // References to owner objects. Ex: Pod belongs to its owning ReplicaSet. A Machine belongs to its owning MachineSet.
    OwnerReferences []OwnerReference

    // The name of the cluster which the object belongs to. This is used to distinguish resources with same name and namespace in different clusters.
    ClusterName string

    //... other fields omitted.
}
</code></pre>
<h5 id="ownerreferences"><a class="header" href="#ownerreferences">OwnerReferences</a></h5>
<p><a href="https://pkg.go.dev/k8s.io/apimachinery/pkg/apis/meta/v1#OwnerReference">k8s.io/apimachinery/pkg/apis/meta/v1.OwnerReference</a> is a struct that contains <code>TypeMeta</code> fields and a small sub-set of the <code>ObjectMetadata</code> - enough to let you identify an owning object. An owning object must be in the same namespace as the dependent, or be cluster-scoped, so there is no namespace field.</p>
<pre><code class="language-go">type OwnerReference struct {
   APIVersion string
   Kind string 
   Name string 
   UID types.UID 
   //... other fields omitted. TODO: check for usages.
}
</code></pre>
<h5 id="finalizers-and-deletion"><a class="header" href="#finalizers-and-deletion">Finalizers and Deletion</a></h5>
<p>Every k8s object has a <code>Finalizers []string</code> field that can be explicitly assigned by a controller. Every k8s object has a <code>DeletionTimestamp *Time</code> that is set by API Server when graceful deletion is requested.</p>
<p>These are part of the <a href="https://pkg.go.dev/k8s.io/apimachinery/pkg/apis/meta/v1#ObjectMeta">k8s.io./apimachinery/pkg/apis/meta/v1.ObjectMeta</a> struct type which is embedded in all k8s objects. </p>
<p>When you tell Kubernetes to delete an object that has finalizers specified for it, the Kubernetes API marks the object for deletion by populating <code>.metadata.deletionTimestamp</code> aka <code>Deletiontimestamp</code>, and returns a <code>202</code> status code (HTTP <code>Accepted</code>). The target object remains in a terminating state while the control plane takes the actions defined by the finalizers. After these actions are complete, the controller should removes the relevant finalizers from the target object. When the <code>metadata.finalizers</code> field is empty, Kubernetes considers the deletion complete and deletes the object.</p>
<h5 id="diff-between-labels-and-annotations"><a class="header" href="#diff-between-labels-and-annotations">Diff between Labels and Annotations</a></h5>
<p><em>Labels</em> are used in conjunction with selectors to identify groups of related resources and meant to be meaningful to users. Because selectors are used to query labels, this operation needs to be efficient. To ensure efficient queries, labels are constrained by RFC 1123. RFC 1123, among other constraints, restricts labels to a maximum 63 character length. Thus, labels should be used when you want Kubernetes to group a set of related resources. See https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/ on label key and value restrictions</p>
<p><em>Annotations</em> are used for ‚Äúnon-identifying information‚Äù i.e., metadata that Kubernetes does not care about. As such, annotation keys and values have no constraints. Can include characters not </p>
<h4 id="api-errors"><a class="header" href="#api-errors">API Errors</a></h4>
<p><a href="https://pkg.go.dev/k8s.io/apimachinery@v0.25.2/pkg/api/errors">k8s.io/apimachinery/pkg/api/errors</a> provides detailed error types  ans <code>IsXXX</code> methods for k8s api errors.</p>
<h5 id="errorsisnotfound"><a class="header" href="#errorsisnotfound">errors.IsNotFound</a></h5>
<p><a href="https://pkg.go.dev/k8s.io/apimachinery@v0.25.2/pkg/api/errors#IsNotFound">k8s.io/apimachinery/pkg/api/errors.IsNotFound</a> returns true if the specified error was due to a k8s object not found. (error or wrapped error created by <a href="https://pkg.go.dev/k8s.io/apimachinery@v0.25.2/pkg/api/errors#NewNotFound">errors.NewNotFound</a>)</p>
<h5 id="errorsisnotfound-1"><a class="header" href="#errorsisnotfound-1">errors.IsNotFound</a></h5>
<p><a href="https://pkg.go.dev/k8s.io/apimachinery@v0.25.2/pkg/api/errors#IsTooManyRequests">k8s.io/apimachinery/pkg/api/errors.IsTooManyRequests</a>  determines if err (or any wrapped error) is an error which indicates that there are too many requests that the server cannot handle.</p>
<h3 id="api-machinery-utilities"><a class="header" href="#api-machinery-utilities">API Machinery Utilities</a></h3>
<h4 id="waituntil"><a class="header" href="#waituntil">wait.Until</a></h4>
<p><a href="https://github.com/kubernetes/apimachinery/blob/v0.25.0/pkg/util/wait/wait.go#L91">k8s.io/apimachinery/pkg/wait.Until</a> loops until <code>stop</code> channel is closed, running <code>f</code> every given <code>period.</code> </p>
<pre><code class="language-go">func Until(f func(), period time.Duration, stopCh &lt;-chan struct{})
</code></pre>
<h4 id="waitpollimmediate"><a class="header" href="#waitpollimmediate">wait.PollImmediate</a></h4>
<p><a href="https://pkg.go.dev/k8s.io/apimachinery@v0.25.2/pkg/util/wait#PollImmediate">k8s.io/apimachinery/pkg/util/wait.PollImmediate</a>  tries a condition func until it returns true, an error, or the timeout is reached.</p>
<pre><code class="language-go">func PollImmediate(interval, timeout time.Duration, condition ConditionFunc) error
</code></pre>
<h4 id="waitbackoff"><a class="header" href="#waitbackoff">wait.Backoff</a></h4>
<p><a href="https://pkg.go.dev/k8s.io/apimachinery/pkg/util/wait#Backoff">k8s.io/apimachinery/pkg/util/wait.Backoff</a> holds parameters applied to a Backoff function. There are many <code>retry</code> functions in <code>client-go</code> and MCM that take an instance of this struct as parameter.</p>
<pre><code class="language-go">type Backoff struct {
	Duration time.Duration
	Factor float64
	Jitter float64
	Steps int
	Cap time.Duration
}
</code></pre>
<ul>
<li><code>Duration</code> is the initial backoff duration.</li>
<li><code>Duration</code> is multiplied by <code>Factor</code> for the next iteration. </li>
<li><code>Jitter</code> is the random amount of each duration added (between <code>Duration</code> and <code>Duration*(1+jitter)</code></li>
<li><code>Steps</code> is the remaining number of iterations in which the duration may increase.</li>
<li><code>Cap</code> is the cap on the duration and may not exceed this value.</li>
</ul>
<h4 id="errors"><a class="header" href="#errors">Errors</a></h4>
<p><a href="https://pkg.go.dev/k8s.io/apimachinery@v0.25.2/pkg/util/errors#Aggregate">k8s.io/apimachinery/pkg/util/errors.Aggregate</a> represents an object that contains multiple errors</p>
<p>Use <a href="https://pkg.go.dev/k8s.io/apimachinery@v0.25.2/pkg/util/errors#NewAggregate">k8s.io/apimachinery/pkg/util/errors.NewAggregate</a> to construct the aggregate error from a slice of errors.</p>
<pre><code class="language-go">type Aggregate interface {
	error
	Errors() []error
	Is(error) bool
}
func NewAggregate(errlist []error) Aggregate {//...}
</code></pre>
<h2 id="k8s-api-core"><a class="header" href="#k8s-api-core">K8s API Core</a></h2>
<p>The MCM leverages several types from https://pkg.go.dev/k8s.io/api/core/v1 </p>
<h3 id="node"><a class="header" href="#node">Node</a></h3>
<p><a href="https://pkg.go.dev/k8s.io/api/core/v1#Node">k8s.io/api/core/v1.Node</a> represents a worker node in Kubernetes. </p>
<pre><code class="language-go">type Node struct {
    metav1.TypeMeta
    metav1.ObjectMeta 
    Spec NodeSpec
    // Most recently observed status of the node.
    Status NodeStatus
}
</code></pre>
<h4 id="nodespec"><a class="header" href="#nodespec">NodeSpec</a></h4>
<p><a href="https://pkg.go.dev/k8s.io/api/core/v1#NodeSpec">k8s.io/api/core/v1.NodeSpec</a>describes the attributes that a node is created with.  Both <a href="k8s_facilities.html#node">Node</a> and <a href="./mcm_facilities.html#machinespec">MachineSpec</a> use this. A snippet of MCM-relevant <code>NodeSpec</code> struct fields shown below for convenience.</p>
<pre><code class="language-go">type NodeSpec struct {
    // ID of the node assigned by the cloud provider in the format: &lt;ProviderName&gt;://&lt;ProviderSpecificNodeID&gt;
    ProviderID string 
    // podCIDRs represents the IP ranges assigned to the node for usage by Pods on that node.
    PodCIDRs []string 

    // Unschedulable controls node schedulability of new pods. By default, node is schedulable.
    Unschedulable bool

    // Taints represents the Node's Taints. (taint is opposite of affinity. allow a Node to repel pods as opposed to attracting them)
    Taints []Taint
}
</code></pre>
<h5 id="node-taints"><a class="header" href="#node-taints">Node Taints</a></h5>
<p>See <a href="https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration/">Taints and Tolerations</a></p>
<p><a href="https://pkg.go.dev/k8s.io/api/core/v1#Taint">k8s.io/api/core/v1.Taint</a> is a Kubernetes <code>Node</code> property that enable specific nodes to repel pods. <em>Tolerations</em> are a Kubernetes <code>Pod</code> property that overcome this and allow a pod to be scheduled on a node with a <em>matching</em> taint.</p>
<p>Instead of applying the label to a node, we apply a taint that tells a scheduler to repel Pods from this node if it does not match the taint. Only those Pods that have a <em>toleration</em> for the taint can be let into the node with that taint.</p>
<p><code>kubectl taint nodes &lt;node name&gt; &lt;taint key&gt;=&lt;taint value&gt;:&lt;taint effect&gt; </code></p>
<p>Example:</p>
<p><code>kubectl taint nodes node1 gpu=nvidia:NoSchedule</code></p>
<p>Users can specify any arbitrary string for the taint key and value. The taint effect defines how a tainted node reacts to a pod without appropriate toleration. It must be one of the following effects;</p>
<ul>
<li>
<p><code>NoSchedule</code>: The pod will not get scheduled to the node without a matching toleration.</p>
</li>
<li>
<p><code>NoExecute</code>:This will immediately evict all the pods without the matching toleration from the node.</p>
</li>
<li>
<p><code>PerferNoSchedule</code>:This is a softer version of NoSchedule where the controller will not try to schedule a pod with the tainted node. However, it is not a strict requirement.</p>
</li>
</ul>
<pre><code class="language-go">type Taint struct {
	// Key of taint to be applied to a node.
	Key string
	// Value of taint corresponding to the taint key.
	Value string 
	// Effect represents the effect of the taint on pods
	// that do not tolerate the taint.
	// Valid effects are NoSchedule, PreferNoSchedule and NoExecute.
	Effect TaintEffect 
	// TimeAdded represents the time at which the taint was added.
	// It is only written for NoExecute taints.
	// +optional
	TimeAdded *metav1.Time 
}
</code></pre>
<p>Example of a PodSpec with toleration below:</p>
<pre><code class="language-yaml">apiVersion: v1
kind: Pod
metadata:
  name: pod-1
  labels:
    security: s1
spec:
  containers:
  - name: bear
    image: supergiantkir/animals:bear
  tolerations:
  - key: &quot;gpu&quot;
    operator: &quot;Equal&quot;
    value: &quot;nvidia&quot;
    effect: &quot;NoSchedule&quot;
</code></pre>
<p>Example use case for a taint/tolerance: If you have nodes with special hardware (e.g GPUs) you want to repel Pods that do not need this hardware and attract Pods that do need it. This can be done by tainting the nodes that have the specialized hardware (e.g. kubectl taint nodes nodename gpu=nvidia:NoSchedule ) and adding corresponding toleration to Pods that must use this special hardware.</p>
<h4 id="nodestatus"><a class="header" href="#nodestatus">NodeStatus</a></h4>
<p>See <a href="https://kubernetes.io/docs/concepts/architecture/nodes/#node-status">Node status</a></p>
<p><a href="https://pkg.go.dev/k8s.io/api/core/v1#NodeStatus">k8s.io/api/core/v1.NodeStatus</a> represents the current status of a node and is an encapsulation illustrated below:</p>
<pre><code class="language-go">type NodeStatus struct {
	// Capacity represents the total resources of a node.
	Capacity ResourceList 
	// Allocatable represents the resources of a node that are available for scheduling. Defaults to Capacity.
	Allocatable ResourceList
	// Conditions is an array of current observed node conditions.
	Conditions []NodeCondition 
	// List of addresses reachable to the node.Queried from cloud provider, if available.
	Addresses []NodeAddress 
	// Set of ids/uuids to uniquely identify the node.
	NodeInfo NodeSystemInfo 
	// List of container images on this node
	Images []ContainerImage 
	// List of attachable volumes that are in use (mounted) by the node.
  //UniqueVolumeName is just typedef for string
	VolumesInUse []UniqueVolumeName 
	// List of volumes that are attached to the node.
	VolumesAttached []AttachedVolume 
}
</code></pre>
<h5 id="capacity"><a class="header" href="#capacity">Capacity</a></h5>
<p><a href="https://kubernetes.io/docs/concepts/storage/persistent-volumes#capacity">Capacity</a>. The fields in the capacity block indicate the total amount of resources that a Node has. </p>
<ul>
<li>Allocatable indicates the amount of resources on a Node that is available to be consumed by normal Pods. Defaults to Capacity.</li>
</ul>
<p>A Node <code>Capacity</code> is of type <a href="https://pkg.go.dev/k8s.io/api/core/v1#ResourceList">k8s.io/api/core/v1.ResourceList</a> which is effectively a set of set of (resource name, quantity) pairs. </p>
<pre><code class="language-go">type ResourceList map[ResourceName]resource.Quantity
</code></pre>
<p><code>ResourceName</code>s can be cpu/memory/storage</p>
<pre><code class="language-go">const (
	// CPU, in cores. (500m = .5 cores)
	ResourceCPU ResourceName = &quot;cpu&quot;
	// Memory, in bytes. (500Gi = 500GiB = 500 * 1024 * 1024 * 1024)
	ResourceMemory ResourceName = &quot;memory&quot;
	// Volume size, in bytes (e,g. 5Gi = 5GiB = 5 * 1024 * 1024 * 1024)
	ResourceStorage ResourceName = &quot;storage&quot;
	// Local ephemeral storage, in bytes. (500Gi = 500GiB = 500 * 1024 * 1024 * 1024)
	// The resource name for ResourceEphemeralStorage is alpha and it can change across releases.
	ResourceEphemeralStorage ResourceName = &quot;ephemeral-storage&quot;
)
</code></pre>
<p>A <a href="https://pkg.go.dev/k8s.io/apimachinery@v0.25.2/pkg/api/resource#Quantity">k8s.io/apimachinery/pkg/api/resource.Quantity</a> is a serializable/de-serializable number with a SI unit</p>
<h5 id="conditions"><a class="header" href="#conditions">Conditions</a></h5>
<p><a href="https://kubernetes.io/docs/concepts/nodes/node/#condition">Conditions</a> are valid conditions of nodes.</p>
<p><a href="https://pkg.go.dev/k8s.io/api/core/v1#NodeCondition">https://pkg.go.dev/k8s.io/api/core/v1.NodeCondition</a> contains condition information for a node.</p>
<pre><code class="language-go">type NodeCondition struct {
	// Type of node condition.
	Type NodeConditionType 
	// Status of the condition, one of True, False, Unknown.
	Status ConditionStatus 
	// Last time we got an update on a given condition.
	LastHeartbeatTime metav1.Time 
	// Last time the condition transitioned from one status to another.
	LastTransitionTime metav1.Time 
	// (brief) reason for the condition's last transition.
	Reason string 
	// Human readable message indicating details about last transition.
	Message string 
}
</code></pre>
<h6 id="nodeconditiontype"><a class="header" href="#nodeconditiontype">NodeConditionType</a></h6>
<p><code>NodeConditionType</code> is one of the following:</p>
<pre><code class="language-go">const (
	// NodeReady means kubelet is healthy and ready to accept pods.
	NodeReady NodeConditionType = &quot;Ready&quot;
	// NodeMemoryPressure means the kubelet is under pressure due to insufficient available memory.
	NodeMemoryPressure NodeConditionType = &quot;MemoryPressure&quot;
	// NodeDiskPressure means the kubelet is under pressure due to insufficient available disk.
	NodeDiskPressure NodeConditionType = &quot;DiskPressure&quot;
	// NodePIDPressure means the kubelet is under pressure due to insufficient available PID.
	NodePIDPressure NodeConditionType = &quot;PIDPressure&quot;
	// NodeNetworkUnavailable means that network for the node is not correctly configured.
	NodeNetworkUnavailable NodeConditionType = &quot;NetworkUnavailable&quot;
)
</code></pre>
<p>Note: The MCM extends the above with further custom node condition types of its own. Not sure if this is correct - could break later if k8s enforces some validation ?</p>
<h6 id="conditionstatus"><a class="header" href="#conditionstatus">ConditionStatus</a></h6>
<p>These are valid condition statuses. <code>ConditionTrue</code> means a resource is in the condition. <code>ConditionFalse</code> means a resource is not in the condition. <code>ConditionUnknown</code> means kubernetes can't decide if a resource is in the condition or not. </p>
<pre><code class="language-go">type ConditionStatus string

const (
	ConditionTrue    ConditionStatus = &quot;True&quot;
	ConditionFalse   ConditionStatus = &quot;False&quot;
	ConditionUnknown ConditionStatus = &quot;Unknown&quot;
)
</code></pre>
<h5 id="addresses"><a class="header" href="#addresses">Addresses</a></h5>
<p>See <a href="https://kubernetes.io/docs/concepts/architecture/nodes/#addresses">Node Addresses</a></p>
<p><a href="https://pkg.go.dev/k8s.io/api/core/v1#NodeAddress">k8s.io/api/core/v1.NodeAddress</a> contains information for the node's address.</p>
<pre><code class="language-go">type NodeAddress struct {
	// Node address type, one of Hostname, ExternalIP or InternalIP.
	Type NodeAddressType 
	// The node address string.
	Address string 
}
</code></pre>
<h5 id="nodesysteminfo"><a class="header" href="#nodesysteminfo">NodeSystemInfo</a></h5>
<p>Describes general information about the node, such as machine id, kernel version, Kubernetes version (kubelet and kube-proxy version), container runtime details, and which operating system the node uses. The kubelet gathers this information from the node and publishes it into the Kubernetes API.</p>
<pre><code class="language-go">type NodeSystemInfo struct {
	// MachineID reported by the node. For unique machine identification
	// in the cluster this field is preferred. 
	MachineID string 
	// Kernel Version reported by the node from 'uname -r' (e.g. 3.16.0-0.bpo.4-amd64).
	KernelVersion string 
	// OS Image reported by the node from /etc/os-release (e.g. Debian GNU/Linux 7 (wheezy)).
	OSImage string 
	// ContainerRuntime Version reported by the node through runtime remote API (e.g. docker://1.5.0).
	ContainerRuntimeVersion string 
	// Kubelet Version reported by the node.
	KubeletVersion string 
	// KubeProxy Version reported by the node.
	KubeProxyVersion string 
	// The Operating System reported by the node
	OperatingSystem string 
	// The Architecture reported by the node
	Architecture string 
}
</code></pre>
<ul>
<li>The <a href="http://man7.org/linux/man-pages/man5/machine-id.5.html">MachineID</a> is a single newline-terminated, hexadecimal, 32-character, lowercase ID. from <code>/etc/machine-id</code></li>
</ul>
<h5 id="images"><a class="header" href="#images">Images</a></h5>
<p>A slice of <a href="https://pkg.go.dev/k8s.io/api/core/v1#ContainerImage">k8s.io/api/core/v1.ContainerImage</a> which describes a contianer image.</p>
<pre><code class="language-go">type ContainerImage struct {
  // Names by which this image is known.
	// e.g. [&quot;kubernetes.example/hyperkube:v1.0.7&quot;, 
  // &quot;cloud-vendor.registry.example/cloud-vendor/hyperkube:v1.0.7&quot;]
	Names []string 
	// The size of the image in bytes.
	SizeBytes int64 
}
</code></pre>
<h5 id="attached-volumes"><a class="header" href="#attached-volumes">Attached Volumes</a></h5>
<p><a href="https://pkg.go.dev/k8s.io/api/core/v1#AttachedVolume">k8s.io/api/core/v1.AttachedVolume</a> describes a volume attached to a node.</p>
<pre><code class="language-go">type UniqueVolumeName string
type AttachedVolume struct {
	// Name of the attached volume
	Name UniqueVolumeName 
	// DevicePath represents the device path where the volume should be available
	DevicePath string 
}
</code></pre>
<h4 id="volumeattachment"><a class="header" href="#volumeattachment">VolumeAttachment</a></h4>
<p>A <a href="https://pkg.go.dev/k8s.io/api/storage/v1#VolumeAttachment">k8s.io/api/storage/v1.VolumeAttachment</a> is a non-namespaced object that captures the intent to attach or detach the specified volume to/from the specified node.</p>
<pre><code class="language-go">type VolumeAttachment struct {
	metav1.TypeMeta 
	metav1.ObjectMeta 

	// Specification of the desired attach/detach volume behavior.
	// Populated by the Kubernetes system.
	Spec VolumeAttachmentSpec 

	// Status of the VolumeAttachment request.
	// Populated by the entity completing the attach or detach
	// operation, i.e. the external-attacher.
	Status VolumeAttachmentStatus 
}
</code></pre>
<h4 id="volumeattachmentspec"><a class="header" href="#volumeattachmentspec">VolumeAttachmentSpec</a></h4>
<p>A <a href="https://pkg.go.dev/k8s.io/api/storage/v1#VolumeAttachmentSpec">k8s.ip/api/storage/v1.VolumeAttachmentSpec</a>is the specification of a VolumeAttachment request.</p>
<pre><code class="language-go">type VolumeAttachmentSpec struct {
	// Attacher indicates the name of the volume driver that MUST handle this
	// request. Same as CSI Plugin name
	Attacher string 

	// Source represents the volume that should be attached.
	Source VolumeAttachmentSource 

	// The node that the volume should be attached to.
	NodeName string
}
</code></pre>
<p>See <a href="https://pkg.go.dev/k8s.io/api@v0.25.2/storage/v1">Storage V1 Docs</a> for further elaboration. </p>
<h3 id="pod"><a class="header" href="#pod">Pod</a></h3>
<p><a href="k8s.io/api/core/v1#Pod">k8s.io/api/core/v1.Pod</a> struct represents a k8s <a href="https://kubernetes.io/docs/concepts/workloads/pods/">Pod</a> which a collection of containers that can run on a host. This resource is created by clients and scheduled onto hosts.</p>
<pre><code class="language-go">type Pod struct {
	metav1.TypeMeta `json:&quot;,inline&quot;`
	// Standard object's metadata.
	metav1.ObjectMeta

	// Specification of the desired behavior of the pod.
	Spec PodSpec 

	// Most recently observed status of the pod.
	Status PodStatus
}
</code></pre>
<p>See <a href="https://pkg.go.dev/k8s.io/api/core/v1#PodSpec">k8s.io/api/core/v1.PodSpec</a>. Each <code>PodSpec</code> has a priority value where the higher the value, the higher the priority of the Pod.</p>
<p><code>PodSpec.Volumes</code> slice is List of volumes that can be mounted by containers belonging to the pod and is relevant to MC code that attaches/detaches volumes .</p>
<pre><code class="language-go">type PodSpec struct {
	 Volumes []Volume 
	 //TODO: describe other PodSpec fields used by MC
}
</code></pre>
<h4 id="pod-eviction"><a class="header" href="#pod-eviction">Pod Eviction</a></h4>
<p>A <a href="k8s.io/api@v0.25.2/policy/v1#Eviction">k8s.io/api/policy/v1.Eviction</a> can be used to evict a <a href="k8s_facilities.html#pod">Pod</a> from its <a href="k8s_facilities.html#node">Node</a> - eviction is the <em>graceful</em> terimation of Pods on nodes.See <a href="https://kubernetes.io/docs/concepts/scheduling-eviction/api-eviction/">API Eviction</a></p>
<pre><code class="language-go">type Eviction struct {
	metav1.TypeMeta 

	// ObjectMeta describes the pod that is being evicted.
	metav1.ObjectMeta 

	// DeleteOptions may be provided
	DeleteOptions *metav1.DeleteOptions 
}

</code></pre>
<p>Construct the <code>ObjectMeta</code> using the Pod and namespace and then use instance of typed <a href="https://pkg.go.dev/k8s.io/client-go/kubernetes#Interface">Kubernetes Client Interface</a>, and get the <a href="https://pkg.go.dev/k8s.io/client-go@v0.25.2/kubernetes/typed/policy/v1#PolicyV1Interface">PolicyV1Interface</a>, get the <a href="https://pkg.go.dev/k8s.io/client-go@v0.25.2/kubernetes/typed/policy/v1#EvictionInterface">EvictionInterface</a> and invoke the invoke the <a href="https://pkg.go.dev/k8s.io/client-go@v0.25.2/kubernetes/typed/policy/v1#EvictionExpansion">Evict</a> method</p>
<p>Example</p>
<pre><code class="language-go">client.PolicyV1().Evictions(eviction.Namespace).Evict(ctx, eviction)
</code></pre>
<h4 id="pod-disruption-budget"><a class="header" href="#pod-disruption-budget">Pod Disruption Budget</a></h4>
<p>A <a href="https://pkg.go.dev/k8s.io/api@v0.25.2/policy/v1#PodDisruptionBudget">k8s.io/api/policy/v1.PodDisruptionBudget</a>is a struct type that represents a <a href="https://kubernetes.io/docs/tasks/run-application/configure-pdb/#specifying-a-poddisruptionbudget">Pod Disruption Budget</a> which is the max disruption that can be caused to a collection of pods.</p>
<pre><code class="language-go">type PodDisruptionBudget struct {
	metav1.TypeMeta 
	metav1.ObjectMeta

	// Specification of the desired behavior of the PodDisruptionBudget.
	Spec PodDisruptionBudgetSpec 
	// Most recently observed status of the PodDisruptionBudget.
	Status PodDisruptionBudgetStatus 
}
</code></pre>
<h5 id="poddisruptionbudgetspec"><a class="header" href="#poddisruptionbudgetspec">PodDisruptionBudgetSpec</a></h5>
<pre><code class="language-go">type PodDisruptionBudgetSpec struct {
	MinAvailable *intstr.IntOrString 
	Selector *metav1.LabelSelector 
	MaxUnavailable *intstr.IntOrString 
}
</code></pre>
<ul>
<li><code>Selector</code> specifies  Label query over pods whose evictions are managed by the disruption budget. A null selector will match no pods, while an empty ({}) selector will select all pods within the namespace.</li>
<li>An eviction is allowed if at least <code>MinAvailable</code> pods selected by <code>Selector</code> will still be available after the eviction, i.e. even in the absence of the evicted pod.  So for example you can prevent all voluntary evictions by specifying &quot;100%&quot;.</li>
<li>An eviction is allowed if at most <code>MaxUnavailable</code> pods selected by <code>Selector</code> are unavailable after the eviction, i.e. even in absence of  the evicted pod. For example, one can prevent all voluntary evictions  by specifying 0. </li>
<li><code>MinAvailable</code> is a mutually exclusive setting with <code>MaxUnavailable</code></li>
</ul>
<h5 id="poddisruptionbudgetstatus"><a class="header" href="#poddisruptionbudgetstatus">PodDisruptionBudgetStatus</a></h5>
<p>See godoc for <a href="https://pkg.go.dev/k8s.io/api@v0.25.2/policy/v1#PodDisruptionBudgetStatus">k8s.io/api/policy/v1.PodDisruptionBudgetStatus</a></p>
<h4 id="pod-volumes"><a class="header" href="#pod-volumes">Pod Volumes</a></h4>
<p>A <a href="https://pkg.go.dev/k8s.io/api/core/v1#Volume">k8s.io/api/core/v1.Volume</a> represents a named volume in a pod - which is a directory that may be accessed by any container in the pod. See <a href="https://kubernetes.io/docs/concepts/storage/volumes/">Pod Volumes</a></p>
<p>A <code>Volume</code> has a <code>Name</code> and embeds a <code>VolumeSource</code> as shown below. A <code>VolumeSource</code> represents the location and type of the mounted volume.</p>
<pre><code class="language-go">type Volume struct {
	Name string 
	VolumeSource
}
</code></pre>
<p><code>VolumeSource</code> which represents the source of a volume to mount should only have ONE of its fields popularted. The MC uses <code>PersistentVolumeClaim</code> field which is pointer to a <code>PersistentVolumeClaimVolumeSource</code> which represents a reference to a <a href="https://pkg.go.dev/k8s.io/api/core/v1#PersistentVolumeClaim">PersistentVolumeClaim</a> in the same namespace.</p>
<pre><code class="language-go">type VolumeSource struct {
	PersistentVolumeClaim *PersistentVolumeClaimVolumeSource
}
type PersistentVolumeClaimVolumeSource struct  {
	ClaimName string
	ReadOnly bool
}
</code></pre>
<h3 id="persistentvolume"><a class="header" href="#persistentvolume">PersistentVolume</a></h3>
<p>A <a href="https://pkg.go.dev/k8s.io/api/core/v1#PersistentVolume">k8s.io/api/core/v1.PersistentVolume</a> (PV) represents a piece of storage in the cluster.
See <a href="https://kubernetes.io/docs/concepts/storage/persistent-volumes/">K8s Persistent Volumes</a></p>
<h4 id="persistentvolumeclaim"><a class="header" href="#persistentvolumeclaim">PersistentVolumeClaim</a></h4>
<p>A <a href="https://pkg.go.dev/k8s.io/api/core/v1#PersistentVolumeClaim">k8s.io/api/core/v1.PersistentVolumeClaim</a> represents a user's request for and claim to a persistent volume. </p>
<pre><code class="language-go">type PersistentVolumeClaim struct {
	metav1.TypeMeta 
	metav1.ObjectMeta
	Spec PersistentVolumeClaimSpec
	Status PersistentVolumeClaimStatus
}
type PersistentVolumeClaimSpec struct {
	StorageClassName *string 
	//...
	VolumeName string
	//...
}
</code></pre>
<p>Note that <code>PersistentVolumeClaimSpec.VolumeName</code> is of interest to the MC which represents the binding reference to the <code>PersistentVolume</code> backing this claim. Please note that this is different from <code>Pod.Spec.Volumes[*].Name</code> which is more like a label for the volume directory.</p>
<h3 id="secret"><a class="header" href="#secret">Secret</a></h3>
<p>A <a href="https://pkg.go.dev/k8s.io/api/core/v1#Secret">k8s.io/api/core/v1.Secret</a> holds secret data of a secret type whose size &lt; 1MB.  See <a href="https://kubernetes.io/docs/concepts/configuration/secret/">K8s Secrets</a></p>
<ul>
<li>Secret Data is in <code>Secret.Data</code> which is a <code>map[string][]byte</code> where the bytes is the secret value and key is simple ASCII alphanumeric.</li>
</ul>
<pre><code class="language-go">type Secret struct {
	metav1.TypeMeta 
	metav1.ObjectMeta 
	Data map[string][]byte 
	Type SecretType 
	//... omitted for brevity
}
</code></pre>
<p><code>SecretType</code> can be of many types: <code>SecretTypeOpaque</code> which represents user-defined secreets, <code>SecretTypeServiceAccountToken</code> whichcontains a token that identifies a service account to the API, etc.</p>
<h2 id="client-go"><a class="header" href="#client-go">client-go</a></h2>
<p>k8s clients have the type  <a href="https://pkg.go.dev/k8s.io/client-go/kubernetes#Clientset">k8s.io/client-go/kubernetes.ClientSet</a> which is actually a high-level client set facade encapsulating clients for the  <code>core</code>, <code>appsv1</code>, <code>discoveryv1</code>, <code>eventsv1</code>, <code>networkingv1</code>, <code>nodev1</code>, <code>policyv1</code>, <code>storagev1</code> api groups. These individual clients are available via accessor methods. ie use <a href="https://pkg.go.dev/k8s.io/client-go/kubernetes#Clientset.AppsV1">clientset.AppsV1()</a> to get the the <a href="https://pkg.go.dev/k8s.io/client-go@v0.25.2/kubernetes/typed/apps/v1#AppsV1Interface">AppsV1</a> client.</p>
<pre><code class="language-go">// Clientset contains the clients for groups. Each group has exactly one
// version included in a Clientset.
type Clientset struct {
    appsV1                       *appsv1.AppsV1Client
    coreV1                       *corev1.CoreV1Client
    discoveryV1                  *discoveryv1.DiscoveryV1Client
    eventsV1                     *eventsv1.EventsV1Client
    // ...

  // AppsV1 retrieves the AppsV1Client
  func (c *Clientset) AppsV1() appsv1.AppsV1Interface {
    return c.appsV1
  }
    // ...
}
</code></pre>
<p>As can be noticed from the above snippet, each of these clients associated with api groups expose an interface named <em>GroupVersionInterface</em> that in-turn provides further access to a <em>generic</em> REST Interface as well as access to a <em>typed</em> interface containing getter/setter methods for objects within that API group.</p>
<p>For example <a href="https://pkg.go.dev/k8s.io/client-go@v0.25.0/kubernetes/typed/events/v1#EventsV1Client">EventsV1Client</a> which is used to interact with features provided by the <code>events.k8s.io</code> group implements <a href="https://pkg.go.dev/k8s.io/client-go@v0.25.0/kubernetes/typed/events/v1#EventsV1Interface">EventsV1Interface</a></p>
<pre><code class="language-go">type EventsV1Interface interface {
	RESTClient() rest.Interface // generic REST API access
	EventsGetter // typed interface access
}
// EventsGetter has a method to return a EventInterface.
type EventsGetter interface {
	Events(namespace string) EventInterface
}
</code></pre>
<p>The <code>ClientSet</code> struct implements the <a href="https://pkg.go.dev/k8s.io/client-go@v0.25.2/kubernetes#Interface">kubernetes.Interface</a> facade which is a high-level facade containing all the methods to access the individual <em>GroupVersionInterface</em> facade clients.</p>
<pre><code class="language-go">type Interface interface {
	Discovery() discovery.DiscoveryInterface
	AppsV1() appsv1.AppsV1Interface
	CoreV1() corev1.CoreV1Interface
	EventsV1() eventsv1.EventsV1Interface
	NodeV1() nodev1.NodeV1Interface
 // ... other facade accessor
}
</code></pre>
<p>One can <em>generate</em> k8s clients for custom k8s objects that follow the same pattern for core k8s objects. The details are not covered here. Please refer to <a href="https://itnext.io/how-to-generate-client-codes-for-kubernetes-custom-resource-definitions-crd-b4b9907769ba">How to generate client codes for Kubernetes Custom Resource Definitions</a>
, <a href="https://github.com/kubernetes/gengo">gengo</a>, <a href="https://github.com/kubernetes/code-generator">k8s.io codegenrator</a> and the slightly-old article:  <a href="https://cloud.redhat.com/blog/kubernetes-deep-dive-code-generation-customresources">Kubernetes Deep Dive: Code Generation for CustomResources</a></p>
<h3 id="client-go-shared-informers"><a class="header" href="#client-go-shared-informers">client-go Shared Informers.</a></h3>
<p>The vital role of a Kubernetes controller is to watch objects for the desired state and the actual state, then send instructions to make the actual state be more like the desired state. The controller thus first needs to retrieve the object's information. Instead of making direct API calls using k8s listers/watchers, client-go controllers should use <code>SharedInformer</code>s.</p>
<p><a href="https://pkg.go.dev/k8s.io/client-go/tools/cache#SharedInformer">cache.SharedInformer</a> is a primitive exposed by <code>client-go</code> lib that maintains a local cache of k8s objects of a particular API group and kind/resource. (restricable by namespace/label/field selectors) which is linked to the authoritative state of the corresponding objects in the API server. </p>
<p>Informers are used to reduced the load-pressure on the API Server and etcd.</p>
<p>All that is needed to be known at this point is that Informers internally watch for k8s object changes, update an internal indexed store and invoke registered event handlers. Client code must construct event handlers to inject the logic that one would like to execute when an object is Added/Updated/Deleted. </p>
<pre><code class="language-go">type SharedInformer interface {
	// AddEventHandler adds an event handler to the shared informer using the shared informer's resync period.  Events to a single handler are delivered sequentially, but there is no coordination between different handlers.
	AddEventHandler(handler cache.ResourceEventHandler)

	// HasSynced returns true if the shared informer's store has been
	// informed by at least one full LIST of the authoritative state
	// of the informer's object collection.  This is unrelated to &quot;resync&quot;.
	HasSynced() bool

	// Run starts and runs the shared informer, returning after it stops.
	// The informer will be stopped when stopCh is closed.
	Run(stopCh &lt;-chan struct{})
	//..
}
</code></pre>
<p>Note: resync period tells the informer to rebuild its cache every every time the period expires.</p>
<p><a href="https://pkg.go.dev/k8s.io/client-go/tools/cache#ResourceEventHandler">cache.ResourceEventHandler</a> handle notifications for events that happen to a resource.</p>
<pre><code class="language-go">type ResourceEventHandler interface {
	OnAdd(obj interface{})
	OnUpdate(oldObj, newObj interface{})
	OnDelete(obj interface{})
}
</code></pre>
<p><a href="https://pkg.go.dev/k8s.io/client-go/tools/cache#ResourceEventHandlerFuncs">cache.ResourceEventHandlerFuncs</a> is an adapter to let you easily specify as many or as few of the notification functions as you want while still implementing <code>ResourceEventHandler</code>. Nearly all controllers code use instance of this adapter struct to create event handlers to register on shared informers.</p>
<pre><code class="language-go">type ResourceEventHandlerFuncs struct {
	AddFunc    func(obj interface{})
	UpdateFunc func(oldObj, newObj interface{})
	DeleteFunc func(obj interface{})
}
</code></pre>
<p>Shared informers for standard k8s objects can be obtained using the <a href="https://pkg.go.dev/k8s.io/client-go/informers#NewSharedInformerFactory">k8s.io/client-go/informers.NewSharedInformerFactory</a> or one of the variant factory methods in the same package.</p>
<p>Informers and their factory functions for custom k8s objects are usually found in the generated factory code usually in a <code>factory.go</code> file. </p>
<p>See <a href="https://github.com/gardener/machine-controller-manager/blob/v0.47.0/pkg/client/informers/externalversions/factory.go#L79">github.com/machine-controller-manager/pkg/client/informers/externalversions/externalversions.NewSharedInformerFactory</a></p>
<h3 id="client-go-workqueues"><a class="header" href="#client-go-workqueues">client-go workqueues</a></h3>
<p>The basic <a href="https://pkg.go.dev/k8s.io/client-go/util/workqueue#Interface">workqueue.Interface</a> has the following methods:</p>
<pre><code class="language-go">type Interface interface {
	Add(item interface{})
	Len() int
	Get() (item interface{}, shutdown bool)
	Done(item interface{})
	ShutDown()
	ShutDownWithDrain()
	ShuttingDown() bool
}
</code></pre>
<p>This is extended with ability to Add Item as a later time using the <a href="https://pkg.go.dev/k8s.io/client-go/util/workqueue#DelayingInterface">workqueue.DelayingInterface</a>. </p>
<pre><code class="language-go">type DelayingInterface interface {
	Interface
	// AddAfter adds an item to the workqueue after the indicated duration has passed
	// Used to requeue items after failueres to avoid ending in hot-loop
	AddAfter(item interface{}, duration time.Duration)
}
</code></pre>
<p>This is further extended with rate limiting using <a href="https://pkg.go.dev/k8s.io/client-go/util/workqueue#RateLimiter">workqueue.RateLimiter</a></p>
<pre><code class="language-go">type RateLimiter interface {
 	// When gets an item and gets to decide how long that item should wait
	When(item interface{}) time.Duration
	// Forget indicates that an item is finished being retried.  Doesn't matter whether its for perm failing
	// or for success, we'll stop tracking it
	Forget(item interface{})
	// NumRequeues returns back how many failures the item has had
	NumRequeues(item interface{}) int
}

</code></pre>
<h3 id="client-go-controller-steps"><a class="header" href="#client-go-controller-steps">client-go controller steps</a></h3>
<p>The basic high-level contract for a k8s-client controller leveraging work-queues goes like the below:</p>
<ol>
<li>Create rate-limited work queue(s) created using <a href="https://pkg.go.dev/k8s.io/client-go/util/workqueue#NewNamedRateLimitingQueue">workqueue.NewNamedRateLimitingQueue</a></li>
<li>Define lifecycle callback functions (Add/Update/Delete) which accept k8s objects and enqueue k8s object keys (namespace/name) on these rate-limited work queue(s).</li>
<li>Create informers using the shared informer factory functions.</li>
<li>Add event handlers to the informers specifying these callback functions.
<ol>
<li>When informers are started, they will invoke the appropriate registered callbacks when k8s objects are added/updated/deleted.</li>
</ol>
</li>
<li>The controller <code>Run</code> loop then picks up objects from the work queue using <code>Get</code> and reconciles them by invoking the appropriate reconcile function, ensuring that <code>Done</code> is called after reconcile to mark it as done processing.</li>
</ol>
<p>Example:</p>
<pre class="mermaid">%%{init: {'themeVariables': { 'fontSize': '10px'}, &quot;flowchart&quot;: {&quot;useMaxWidth&quot;: false }}}%%
flowchart TD

CreateWorkQueue[&quot;machineQueue:=workqueue.NewNamedRateLimitingQueue(workqueue.DefaultControllerRateLimiter(), 'machine')&quot;]
--&gt;
CreateInformer[&quot;machineInformerFactory := externalversions.NewSharedInformerFactory(...)
machineInformer := machineInformerFactory.Machine().V1alpha1().Machines()&quot;]
--&gt;
AddEventHandler[&quot;machineInformer.Informer().AddEventHandler(cache.ResourceEventHandlerFuncs{
		AddFunc:    controller.machineToMachineClassAdd,
		UpdateFunc: controller.machineToMachineClassUpdate,
		DeleteFunc: controller.machineToMachineClassDelete,
	})&quot;]
--&gt;Run[&quot;while (!shutdown) {
  key, shutdown := queue.Get()
  defer queue.Done(key)
  reconcile(key.(string))
}
&quot;]
--&gt;Z((&quot;End&quot;))
</pre>
<p>A more elaborate example of basic client-go controller flow is demonstrated in the <a href="https://github.com/kubernetes/client-go/blob/master/examples/workqueue/main.go">clien-go workqueue example</a></p>
<h3 id="client-go-utilities"><a class="header" href="#client-go-utilities">client-go utilities</a></h3>
<h4 id="k8sioclient-goutilretryretryonconflict"><a class="header" href="#k8sioclient-goutilretryretryonconflict">k8s.io/client-go/util/retry.RetryOnConflict</a></h4>
<pre><code class="language-go">func RetryOnConflict(backoff wait.Backoff, fn func() error) error
</code></pre>
<ul>
<li><a href="https://pkg.go.dev/k8s.io/client-go@v0.25.2/util/retry#RetryOnConflict">retry.RetryOnConflict</a> is used to make an update to a resource when you have to worry about conflicts caused by other code making unrelated updates to the resource at the same time. </li>
<li><code>fn</code> should fetch the resource to be modified, make appropriate changes to it, try to update it, and return (unmodified) the error from the update function.</li>
<li>On a successful update, <code>RetryOnConflict</code> will return <code>nil</code>. If the update <code>fn</code> returns a <em>Conflict</em> error, <code>RetryOnConflict</code> will wait some amount of time as described by <code>backoff</code>, and then try again. </li>
<li>On a <em>non-Conflict</em> error, or if it retries too many times (<code>backoff.Steps</code> has reached zero) and gives up, <code>RetryOnConflict</code> will return an error to the caller.</li>
</ul>
<h2 id="references"><a class="header" href="#references">References</a></h2>
<ul>
<li><a href="https://github.com/kubernetes/community/blob/master/contributors/devel/sig-architecture/api-conventions.md">K8s API Conventions</a></li>
<li><a href="https://iximiuz.com/en/posts/kubernetes-api-go-types-and-common-machinery/">How To Call Kubernetes API using Go - Types and Common Machinery</a></li>
<li><a href="https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration/">Node Taints and Tolerances</a></li>
<li><a href="https://kubernetes.io/docs/concepts/architecture/nodes/#node-status">Node status</a></li>
<li><a href="https://medium.com/kubernetes-tutorials/making-sense-of-taints-and-tolerations-in-kubernetes-446e75010f4e">Making Sense of Taints and Tolerations</a></li>
<li><a href="https://www.ionos.com/digitalguide/server/know-how/cidr-classless-inter-domain-routing/">CIDR</a></li>
<li><a href="https://mxtoolbox.com/subnetcalculator.aspx">CIDR Calculator</a></li>
<li><a href="https://github.com/kubernetes/code-generator">k8s.io codegenrator</a></li>
<li><a href="https://itnext.io/how-to-generate-client-codes-for-kubernetes-custom-resource-definitions-crd-b4b9907769ba">How to generate client codes for Kubernetes Custom Resource Definitions</a></li>
<li><a href="https://cloud.redhat.com/blog/kubernetes-deep-dive-code-generation-customresources">Kubernetes Deep Dive: Code Generation for CustomResources</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><ul>
<li><a href="mcm_facilities.html#mcm-facilities">MCM Facilities</a>
<ul>
<li><a href="mcm_facilities.html#machine-controller-core-types">Machine Controller Core Types</a>
<ul>
<li><a href="mcm_facilities.html#machine">Machine</a>
<ul>
<li><a href="mcm_facilities.html#machinespec">MachineSpec</a></li>
<li><a href="mcm_facilities.html#machinestatus">MachineStatus</a></li>
<li><a href="mcm_facilities.html#extended-nodeconditiontypes">Extended NodeConditionTypes</a></li>
<li><a href="mcm_facilities.html#lastoperation">LastOperation</a>
<ul>
<li><a href="mcm_facilities.html#machinestate-should-be-called-machineoperationstate">MachineState (should be called MachineOperationState)</a></li>
<li><a href="mcm_facilities.html#machineoperationtype">MachineOperationType</a></li>
</ul>
</li>
<li><a href="mcm_facilities.html#currentstatus">CurrentStatus</a>
<ul>
<li><a href="mcm_facilities.html#machinephase">MachinePhase</a></li>
</ul>
</li>
<li><a href="mcm_facilities.html#finalizers">Finalizers</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="mcm_facilities.html#utilities">Utilities</a>
<ul>
<li><a href="mcm_facilities.html#nodeops">NodeOps</a>
<ul>
<li><a href="mcm_facilities.html#nodeopsgetnodecondition">nodeops.GetNodeCondition</a></li>
<li><a href="mcm_facilities.html#nodeopscloneandaddcondition">nodeops.CloneAndAddCondition</a></li>
<li><a href="mcm_facilities.html#nodeopsaddorupdateconditionsonnode">nodeops.AddOrUpdateConditionsOnNode</a></li>
</ul>
</li>
<li><a href="mcm_facilities.html#machineutils">MachineUtils</a>
<ul>
<li><a href="mcm_facilities.html#operation-descriptions">Operation Descriptions</a></li>
<li><a href="mcm_facilities.html#retry-periods">Retry Periods</a></li>
</ul>
</li>
<li><a href="mcm_facilities.html#misc">Misc</a>
<ul>
<li><a href="mcm_facilities.html#permitspermitgiver">permits.PermitGiver</a>
<ul>
<li><a href="mcm_facilities.html#permitsnewpermitgiver">permits.NewPermitGiver</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><a href="mcm_facilities.html#main-server-structs">Main Server Structs</a>
<ul>
<li><a href="mcm_facilities.html#mcserver">MCServer</a>
<ul>
<li><a href="mcm_facilities.html#mcserver-usage">MCServer Usage</a></li>
<li><a href="mcm_facilities.html#machinecontrollerconfiguration-struct">MachineControllerConfiguration struct</a>
<ul>
<li><a href="mcm_facilities.html#safetyoptions">SafetyOptions</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><a href="mcm_facilities.html#controller-structs">Controller Structs</a>
<ul>
<li><a href="mcm_facilities.html#machine-controller-core-struct">Machine Controller Core Struct</a></li>
</ul>
</li>
<li><a href="mcm_facilities.html#driver">Driver</a></li>
<li><a href="mcm_facilities.html#codes-and-error-status">Codes and (error) Status</a>
<ul>
<li><a href="mcm_facilities.html#code">Code</a></li>
<li><a href="mcm_facilities.html#status">Status</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<h1 id="mcm-facilities"><a class="header" href="#mcm-facilities">MCM Facilities</a></h1>
<p>This chapter describes the core types and utilities present in the MCM module and used by the controllers and drivers.</p>
<h2 id="machine-controller-core-types"><a class="header" href="#machine-controller-core-types">Machine Controller Core Types</a></h2>
<p>The relevant machine types managed by the MCM controlled reside in <a href="https://pkg.go.dev/github.com/gardener/machine-controller-manager@v0.47.0/pkg/apis/machine/v1alpha1">github.com/gardener/machine-controller-manager/pkg/apis/machine/v1alpha1</a>. This follows the standard location for client gen types <code>&lt;module&gt;/pkg/apis/&lt;group&gt;/&lt;version&gt;</code></p>
<h3 id="machine"><a class="header" href="#machine">Machine</a></h3>
<p>Machine is the representation of a physical or virtual machine that corresponds to a front-end k8s node object. An example YAML looks like the below</p>
<pre><code class="language-yaml">apiVersion: machine.sapcloud.io/v1alpha1
kind: Machine
metadata:
  name: test-machine
  namespace: default
spec:
  class:
    kind: MachineClass
    name: test-class
</code></pre>
<p><a href="https://github.com/gardener/machine-controller-manager/blob/v0.47.0/pkg/apis/machine/v1alpha1/machine_types.go#L39">pkg/apis/machine/v1alpha1.Machine</a></p>
<p>A <code>Machine</code> has a <code>Spec</code> field represented by <a href="mcm_facilities.html#machinespec">MachineSpec</a></p>
<pre><code class="language-go">type Machine struct {
	// ObjectMeta for machine object
	metav1.ObjectMeta 

	// TypeMeta for machine object
	metav1.TypeMeta 

	// Spec contains the specification of the machine
	Spec MachineSpec 

	// Status contains fields depicting the status
	Status MachineStatus 
}
</code></pre>
<pre class="mermaid">graph TB
    subgraph Machine
    ObjectMeta
    TypeMeta
    MachineSpec
    MachineStatus
    end
</pre>
<h4 id="machinespec"><a class="header" href="#machinespec">MachineSpec</a></h4>
<p><a href="https://github.com/gardener/machine-controller-manager/blob/v0.47.0/pkg/apis/machine/v1alpha1/machine_types.go#L54">MachineSpec</a> represents the specification of a Machine.</p>
<pre><code class="language-go">type MachineSpec struct {

	// Class is the referrent to the MachineClass. 
	Class ClassSpec 

    // Unique identification of the VM at the cloud provider
	ProviderID string 

	// NodeTemplateSpec describes the data a node should have when created from a template
	NodeTemplateSpec NodeTemplateSpec 

	// Configuration for the machine-controller.  
	*MachineConfiguration 
}
type NodeTemplateSpec struct { // BADLY NAMED!
	metav1.ObjectMeta

	// NodeSpec describes the attributes that a node is created with.
	Spec corev1.NodeSpec
}
</code></pre>
<ul>
<li><code>ProviderID</code> is the unique identification of the VM at the cloud provider. <code>ProviderID</code> typically matches with the <code>node.Spec.ProviderID</code> on the node object.</li>
<li><code>Class</code> field is of type <code>ClassSpec</code> which is just the (<code>Kind</code> and the <code>Name</code>) referring to the <code>MachineClass</code>. (Ideally the field, type should have been called <code>ClassReference</code>) like <code>OwnerReference</code></li>
<li><code>NodeTemplateSpec</code> describes the data a node should have when created from a template, embeds <code>ObjectMeta</code> and holds a <a href="https://pkg.go.dev/k8s.io/api/core/v1#NodeSpec">corev1.NodeSpec</a> in its <code>Spec</code> field.
<ul>
<li>The <code>Machine.Spec.NodeTemplateSpec.Spec</code> mirrors k8s <code>Node.Spec</code></li>
</ul>
</li>
<li><code>MachineSpec</code> embeds a <code>MachineConfiguration</code> which is just a configuration object that is a connection of timeouts, maxEvictRetries and NodeConditions</li>
</ul>
<pre class="mermaid">graph TB
    subgraph MachineSpec
	Class:ClassSpec
	ProviderID:string
	NodeTemplateSpec:NodeTemplateSpec
	MachineConfiguration
    end
</pre>
<pre><code class="language-go">type MachineConfiguration struct {
	// MachineDraintimeout is the timeout after which machine is forcefully deleted.
	MachineDrainTimeout *Duration

	// MachineHealthTimeout is the timeout after which machine is declared unhealhty/failed.
	MachineHealthTimeout *Duration 

	// MachineCreationTimeout is the timeout after which machinie creation is declared failed.
	MachineCreationTimeout *Duration 

	// MaxEvictRetries is the number of retries that will be attempted while draining the node.
	MaxEvictRetries *int32 

	// NodeConditions are the set of conditions if set to true for MachineHealthTimeOut, machine will be declared failed.
	NodeConditions *string 
}
</code></pre>
<h4 id="machinestatus"><a class="header" href="#machinestatus">MachineStatus</a></h4>
<p><a href="https://github.com/gardener/machine-controller-manager/blob/v0.47.0/pkg/apis/machine/v1alpha1/machine_types.go#L97">pkg/apis/machine/v1alpha1.MachineStatus</a> represents the most recently observed status of Machine.</p>
<pre><code class="language-go">type MachineStatus struct {
	// Node string. 
	Node string // TODO: describe me more

	// Conditions of this machine, same as NodeStatus.Conditions
	Conditions []NodeCondition 

	// Last operation refers to the status of the last operation performed. NOTE: this is usually the NextOperation for reconcile!! Discuss!
	LastOperation LastOperation 

	// Current status of the machine object
	CurrentStatus CurrentStatus

	// LastKnownState can store details of the last known state of the VM by the plugins.
	// It can be used by future operation calls to determine current infrastucture state
	LastKnownState string 
}
</code></pre>
<h4 id="extended-nodeconditiontypes"><a class="header" href="#extended-nodeconditiontypes">Extended NodeConditionTypes</a></h4>
<p>The MCM extends standard k8s <a href="./k8s_facilities.html#nodeconditiontype">NodeConditionType</a> with several custom conditions. (TODO: isn't this hacky/error prone?)</p>
<ul>
<li><a href="">NodeTerminationCondition</a> defined as <code>	NodeTerminationCondition v1.NodeConditionType = &quot;Terminating&quot;</code></li>
</ul>
<p>NodeTerminationCondition</p>
<h4 id="lastoperation"><a class="header" href="#lastoperation">LastOperation</a></h4>
<p><a href="https://pkg.go.dev/github.com/gardener/machine-controller-manager/pkg/apis/machine/v1alpha1#LastOperation">github.com/machine-controller-manager/pkg/apis/machine/v1alpha1.LastOperation</a> represents the last operation performed on the object</p>
<pre><code class="language-go">type LastOperation struct {
	// Description of the operation
	Description string 

	// Last update time of operation
	LastUpdateTime Time 

	// State of operation (bad naming)
	State MachineState 

	// Type of operation
	Type MachineOperationType 
}

</code></pre>
<h5 id="machinestate-should-be-called-machineoperationstate"><a class="header" href="#machinestate-should-be-called-machineoperationstate">MachineState (should be called MachineOperationState)</a></h5>
<p>NOTE: BADLY NAMED: Should be called <code>MachineOperationState</code></p>
<p><a href="https://pkg.go.dev/github.com/gardener/machine-controller-manager/pkg/apis/machine/v1alpha1#MachineState">machine-controller-manager/pkg/apis/machine/v1alpha1.MachineState</a> represents the  current state of a machine operation and is one of <code>Processing</code>, <code>Failed</code> or <code>Successful</code>.</p>
<pre><code class="language-go">// MachineState is  current state of the machine.
// BAD Name: Should be MachineOperationState
type MachineState string

// These are the valid (operation) states of machines.
const (
	// MachineStatePending means there are operations pending on this machine state
	MachineStateProcessing MachineState = &quot;Processing&quot;

	// MachineStateFailed means operation failed leading to machine status failure
	MachineStateFailed MachineState = &quot;Failed&quot;

	// MachineStateSuccessful indicates that the node is not ready at the moment
	MachineStateSuccessful MachineState = &quot;Successful&quot;
)
</code></pre>
<h5 id="machineoperationtype"><a class="header" href="#machineoperationtype">MachineOperationType</a></h5>
<p><a href="https://pkg.go.dev/github.com/gardener/machine-controller-manager/pkg/apis/machine/v1alpha1#MachineOperationType">github.com/machine-controller-manager/pkg/apis/machine/v1alpha1.MachineOperationType</a> is a label for the operation performed on a machine object: <code>Create</code>/<code>Update</code>/<code>HealthCheck</code>/<code>Delete</code>.</p>
<pre><code class="language-go">type MachineOperationType string
const (
	// MachineOperationCreate indicates that the operation is a create
	MachineOperationCreate MachineOperationType = &quot;Create&quot;

	// MachineOperationUpdate indicates that the operation is an update
	MachineOperationUpdate MachineOperationType = &quot;Update&quot;

	// MachineOperationHealthCheck indicates that the operation is a create
	MachineOperationHealthCheck MachineOperationType = &quot;HealthCheck&quot;

	// MachineOperationDelete indicates that the operation is a delete
	MachineOperationDelete MachineOperationType = &quot;Delete&quot;
)

</code></pre>
<h4 id="currentstatus"><a class="header" href="#currentstatus">CurrentStatus</a></h4>
<p><a href="https://pkg.go.dev/github.com/gardener/machine-controller-manager/pkg/apis/machine/v1alpha1#CurrentStatus">github.com/machine-controller-manager/pkg/apis/machine/v1alpha1.CurrentStatus</a> encapsulates information about the current status of Machine.</p>
<pre><code class="language-go">type CurrentStatus struct {
	// Phase refers to the Machien (Lifecycle) Phase
	Phase MachinePhase 
	// TimeoutActive when set to true drives the machine controller
	// to check whether	machine failed the configured creation timeout or health check timeout and change machine phase to Failed.
	TimeoutActive bool 
	// Last update time of current status
	LastUpdateTime Time
}
</code></pre>
<h5 id="machinephase"><a class="header" href="#machinephase">MachinePhase</a></h5>
<p><code>MachinePhase</code> is a label for the life-cycle phase of a machine at a given time: <code>Unknown</code>, <code>Pending</code>, <code>Available</code>, <code>Running</code>, <code>Terminating</code>, <code>Failed</code>, <code>CrashLoopBackOff</code>,.</p>
<pre><code class="language-go">type MachinePhase string
const (
	// MachinePending means that the machine is being created
	MachinePending MachinePhase = &quot;Pending&quot;

	// MachineAvailable means that machine is present on provider but hasn't joined cluster yet
	MachineAvailable MachinePhase = &quot;Available&quot;

	// MachineRunning means node is ready and running successfully
	MachineRunning MachinePhase = &quot;Running&quot;

	// MachineRunning means node is terminating
	MachineTerminating MachinePhase = &quot;Terminating&quot;

	// MachineUnknown indicates that the node is not ready at the movement
	MachineUnknown MachinePhase = &quot;Unknown&quot;

	// MachineFailed means operation failed leading to machine status failure
	MachineFailed MachinePhase = &quot;Failed&quot;

	// MachineCrashLoopBackOff means creation or deletion of the machine is failing.
	MachineCrashLoopBackOff MachinePhase = &quot;CrashLoopBackOff&quot;
)
</code></pre>
<h4 id="finalizers"><a class="header" href="#finalizers">Finalizers</a></h4>
<p>See <a href="./k8s_facilities.html#finalizers-and-deletion">K8s Finalizers</a>. The MC defines the following finalizer keys</p>
<pre><code class="language-go">const (
	MCMFinalizerName = &quot;machine.sapcloud.io/machine-controller-manager&quot;
	MCFinalizerName = &quot;machine.sapcloud.io/machine-controller&quot;
)
</code></pre>
<ol>
<li><code>MCMFinalizerName</code> is the finalizer used to tag dependecies before deletion</li>
<li><code>MCFinalizerName</code> is the finalizer added on <code>Secret</code> objects.</li>
</ol>
<h2 id="utilities"><a class="header" href="#utilities">Utilities</a></h2>
<h3 id="nodeops"><a class="header" href="#nodeops">NodeOps</a></h3>
<h4 id="nodeopsgetnodecondition"><a class="header" href="#nodeopsgetnodecondition">nodeops.GetNodeCondition</a></h4>
<p><a href="https://github.com/gardener/machine-controller-manager/blob/v0.47.0/pkg/util/nodeops/conditions.go#L72">machine-controller-manager/pkg/util/nodeops.GetNodeCondition</a> get the nodes condition matching the specified type </p>
<pre><code class="language-go">func GetNodeCondition(ctx context.Context, c clientset.Interface, nodeName string, conditionType v1.NodeConditionType) (*v1.NodeCondition, error) {
	node, err := c.CoreV1().Nodes().Get(ctx, nodeName, metav1.GetOptions{})
	if err != nil {
		return nil, err
	}
	return getNodeCondition(node, conditionType), nil
}
func getNodeCondition(node *v1.Node, conditionType v1.NodeConditionType) *v1.NodeCondition {
	for _, cond := range node.Status.Conditions {
		if cond.Type == conditionType {
			return &amp;cond
		}
	}
	return nil
}
</code></pre>
<h4 id="nodeopscloneandaddcondition"><a class="header" href="#nodeopscloneandaddcondition">nodeops.CloneAndAddCondition</a></h4>
<p><a href="https://github.com/gardener/machine-controller-manager/blob/v0.47.0/pkg/util/nodeops/conditions.go#L31">machine-controller-manager/pkg/util/nodeops.CloneAndAddCondition</a> adds a condition to the node condition slice. If condition with this type already exists, it updates the <code>LastTransitionTime</code></p>
<pre><code class="language-go">func CloneAndAddCondition(conditions []v1.NodeCondition, condition v1.NodeCondition) []v1.NodeCondition {
	if condition.Type == &quot;&quot; || condition.Status == &quot;&quot; {
		return conditions
	}
	var newConditions []v1.NodeCondition

	for _, existingCondition := range conditions {
		if existingCondition.Type != condition.Type { 
			newConditions = append(newConditions, existingCondition)
		} else { 
			// condition with this type already exists
			if existingCondition.Status == condition.Status 
			&amp;&amp; existingCondition.Reason == condition.Reason {
				// condition status and reason are  the same, keep existing transition time
				condition.LastTransitionTime = existingCondition.LastTransitionTime
			}
		}
	}
	newConditions = append(newConditions, condition)
	return newConditions
}
</code></pre>
<p>TODO: Bug ? Logic above will end up adding duplicate node condition if status and reason phrase are different</p>
<h4 id="nodeopsaddorupdateconditionsonnode"><a class="header" href="#nodeopsaddorupdateconditionsonnode">nodeops.AddOrUpdateConditionsOnNode</a></h4>
<p><a href="https://github.com/gardener/machine-controller-manager/blob/v0.47.0/pkg/util/nodeops/conditions.go#L81">machine-controller-manager/pkg/util/nodeops.AddOrUpdateConditionsOnNode</a> adds a condition to the node's status, retrying on conflict with backoff.</p>
<pre><code class="language-go">func AddOrUpdateConditionsOnNode(ctx context.Context, c clientset.Interface, nodeName string, condition v1.NodeCondition) error 
</code></pre>
<pre class="mermaid">%%{init: {'themeVariables': { 'fontSize': '10px'}, &quot;flowchart&quot;: {&quot;useMaxWidth&quot;: false }}}%%
flowchart TD

Init[&quot;backoff = wait.Backoff{
	Steps:    5,
	Duration: 100 * time.Millisecond,
	Jitter:   1.0,
}&quot;]
--&gt;retry.RetryOnConflict[&quot;retry.RetryOnConflict(backoff, fn)&quot;]
--&gt;GetNode[&quot;oldNode, err = c.CoreV1().Nodes().Get(ctx, nodeName, metav1.GetOptions{})&quot;]
subgraph &quot;fn&quot;
    GetNode--&gt;ChkIfErr{&quot;err != nil&quot;}
	ChkIfErr--Yes--&gt;ReturnErr((&quot;return err&quot;))
	ChkIfErr--No--&gt;InitNewNode[&quot;newNode := oldNode.DeepCopy()&quot;]
	InitNewNode--&gt;InitConditions[&quot;newNode.Status.Conditions:= CloneAndAddCondition(newNode.Status.Conditions, condition)&quot;]
	--&gt;UpdateNewNode[&quot;_, err := c.CoreV1().Nodes().UpdateStatus(ctx, newNodeClone, metav1.UpdateOptions{}&quot;]
	--&gt;ReturnErr
end
</pre>
<h3 id="machineutils"><a class="header" href="#machineutils">MachineUtils</a></h3>
<h4 id="operation-descriptions"><a class="header" href="#operation-descriptions">Operation Descriptions</a></h4>
<p><code>machineutils</code> has a bunch of constants that are descriptions of machine operations that are set into <code>machine.Status.LastOperation.Description</code> by the machine controller while performing reconciliation. It also has some <a href="k8s_facilities.html#conditions">reason phrase</a></p>
<pre><code class="language-go">const (
	// GetVMStatus sets machine status to terminating and specifies next step as getting VMs
	GetVMStatus = &quot;Set machine status to termination. Now, getting VM Status&quot;

	// InitiateDrain specifies next step as initiate node drain
	InitiateDrain = &quot;Initiate node drain&quot;

	// InitiateVMDeletion specifies next step as initiate VM deletion
	InitiateVMDeletion = &quot;Initiate VM deletion&quot;

	// InitiateNodeDeletion specifies next step as node object deletion
	InitiateNodeDeletion = &quot;Initiate node object deletion&quot;

	// InitiateFinalizerRemoval specifies next step as machine finalizer removal
	InitiateFinalizerRemoval = &quot;Initiate machine object finalizer removal&quot;

	// LastAppliedALTAnnotation contains the last configuration of annotations, 
	// labels &amp; taints applied on the node object
	LastAppliedALTAnnotation = &quot;node.machine.sapcloud.io/last-applied-anno-labels-taints&quot;

	// MachinePriority is the annotation used to specify priority
	// associated with a machine while deleting it. The less its
	// priority the more likely it is to be deleted first
	// Default priority for a machine is set to 3
	MachinePriority = &quot;machinepriority.machine.sapcloud.io&quot;

	// MachineClassKind is used to identify the machineClassKind for generic machineClasses
	MachineClassKind = &quot;MachineClass&quot;

	// MigratedMachineClass annotation helps in identifying machineClasses who have been migrated by migration controller
	MigratedMachineClass = &quot;machine.sapcloud.io/migrated&quot;

	// NotManagedByMCM annotation helps in identifying the nodes which are not handled by MCM
	NotManagedByMCM = &quot;node.machine.sapcloud.io/not-managed-by-mcm&quot;

	// TriggerDeletionByMCM annotation on the node would trigger the deletion of the corresponding machine object in the control cluster
	TriggerDeletionByMCM = &quot;node.machine.sapcloud.io/trigger-deletion-by-mcm&quot;

	// NodeUnhealthy is a node termination reason for failed machines
	NodeUnhealthy = &quot;Unhealthy&quot;

	// NodeScaledDown is a node termination reason for healthy deleted machines
	NodeScaledDown = &quot;ScaleDown&quot;

	// NodeTerminationCondition describes nodes that are terminating
	NodeTerminationCondition v1.NodeConditionType = &quot;Terminating&quot;
)

</code></pre>
<h4 id="retry-periods"><a class="header" href="#retry-periods">Retry Periods</a></h4>
<p>These are standard retry periods that are internally used by the machine controllers to enqueue keys into the work queue after the specified duration so that reconciliation can be retried afer elapsed duration.</p>
<pre><code class="language-go">// RetryPeriod is an alias for specifying the retry period
type RetryPeriod time.Duration

// These are the valid values for RetryPeriod
const (
	// ShortRetry tells the controller to retry after a short duration - 15 seconds
	ShortRetry RetryPeriod = RetryPeriod(15 * time.Second)
	// MediumRetry tells the controller to retry after a medium duration - 2 minutes
	MediumRetry RetryPeriod = RetryPeriod(3 * time.Minute)
	// LongRetry tells the controller to retry after a long duration - 10 minutes
	LongRetry RetryPeriod = RetryPeriod(10 * time.Minute)
)

</code></pre>
<h3 id="misc"><a class="header" href="#misc">Misc</a></h3>
<h4 id="permitspermitgiver"><a class="header" href="#permitspermitgiver">permits.PermitGiver</a></h4>
<p><code>permits.PermitGiver</code> provides the ability to register, obtain, release and delete permits for a given key. All operations are concurrent safe.</p>
<pre><code class="language-go">type PermitGiver interface {
	RegisterPermits(key string, numPermits int) //numPermits should be  maxNumPermits
	TryPermit(key string, timeout time.Duration) bool
	ReleasePermit(key string)
	DeletePermits(key string)
	Close()
}
</code></pre>
<p>The implementation of <a href="https://github.com/gardener/machine-controller-manager/blob/v0.47.0/pkg/util/permits/permits.go#L29">github.com/gardener/machine-controller-manager/pkg/util/permits.PermitGiver</a> maintains:</p>
<ul>
<li>a sync map of permit keys mapped to permits, where each permit is a structure comprising a buffered empty struct <code>struct{}</code> channel  with buffer size equalling the (max) number of permits. 
<ul>
<li><code>RegisterPermits(key, numPermits)</code> registers <code>numPermits</code> for the given <code>key</code>. A <code>permit</code> struct is initialized with <code>permit.c</code> buffer size as <code>numPermits</code>.</li>
</ul>
</li>
<li>entries are deleted if not accessed for a configured time represented by <code>stalePermitKeyTimeout</code>. This is done by 'janitor' go-routine associated with the permit giver instance.</li>
<li>When attempting to get a permit, one writes an empty struct to the permit channel within a given timeout. If one can do so within the timeout one has acquired the permit, else not. 
<ul>
<li><code>TryPermit(key, timeout)</code> attempts to get a permit for the given key by sending a <code>struct{}{}</code> instance to the buffered <code>permit.c</code> channel. </li>
</ul>
</li>
</ul>
<pre><code class="language-go">type permit struct {
	// lastAcquiredPermitTime is time since last successful TryPermit or new RegisterPermits
	lastAcquiredPermitTime time.Time
	// c is initialized with buffer size N representing num permits
	c                      chan struct{} 
}
type permitGiver struct {
	keyPermitsMap sync.Map // map of string keys to permit struct values
	stopC         chan struct{}
}

</code></pre>
<h5 id="permitsnewpermitgiver"><a class="header" href="#permitsnewpermitgiver">permits.NewPermitGiver</a></h5>
<p><code>permits.NewPermitGiver</code> returns a new <code>PermitGiver</code></p>
<pre><code class="language-go">func NewPermitGiver(stalePermitKeyTimeout time.Duration, janitorFrequency time.Duration) PermitGiver
</code></pre>
<pre class="mermaid">
%%{init: {'themeVariables': { 'fontSize': '10px'}, &quot;flowchart&quot;: {&quot;useMaxWidth&quot;: false }}}%%

flowchart TB
	Begin((&quot; &quot;))
	--&gt;InitStopCh[&quot;stopC := make(chan struct{})&quot;]
	--&gt;InitPG[&quot;
		pg := permitGiver{
		keyPermitsMap: sync.Map{},
		stopC:         stopC,
	}&quot;]
	--&gt;LaunchCleanUpGoroutine[&quot;go cleanup()&quot;]
	LaunchCleanUpGoroutine--&gt;Return((&quot;return &amp;pg&quot;))
	LaunchCleanUpGoroutine---&gt;InitTicker
	subgraph cleanup
	InitTicker[&quot;ticker := time.NewTicker(janitorFrequency)&quot;]
	--&gt;caseReadStopCh{&quot;&lt;-stopC ?&quot;}
	caseReadStopCh--Yes--&gt;End((&quot;End&quot;))
	caseReadStopCh--No
		--&gt;ReadTickerCh{&quot;&lt;-ticker.C ?&quot;}
	ReadTickerCh--Yes--&gt;CleanupStale[&quot;
	pg.cleanupStalePermitEntries(stalePermitKeyTimeout)
	(Iterates keyPermitsMap, remove entries whose 
	lastAcquiredPermitTime exceeds stalePermitKeyTimeout)
	&quot;]
	ReadTickerCh--No--&gt;caseReadStopCh
	end
</pre>
<h2 id="main-server-structs"><a class="header" href="#main-server-structs">Main Server Structs</a></h2>
<h3 id="mcserver"><a class="header" href="#mcserver">MCServer</a></h3>
<p><a href="https://github.com/gardener/machine-controller-manager/blob/v0.47.0/pkg/util/provider/app/options/options.go#L40">machine-controller-manager/pkg/util/provider/app/options.MCServer</a>
is the main server context object for the machine controller. It embeds <a href="https://github.com/gardener/machine-controller-manager/blob/v0.47.0/pkg/util/provider/options/types.go#L45">options.MachineControllerConfiguration</a> and has a <code>ControlKubeConfig</code> and <code>TargetKubeConfig</code> string fields.</p>
<pre><code class="language-go">type MCServer struct {
	options.MachineControllerConfiguration

	ControlKubeconfig string
	TargetKubeconfig  string

</code></pre>
<p>The <code>MCServer</code> is constructed and initialized using the  <a href="https://github.com/gardener/machine-controller-manager/blob/v0.47.0/pkg/util/provider/app/options/options.go#L48">pkg/util/provider/app/options.NewMCServer</a> function which sets most of the default values for fields for the embedded struct.</p>
<h4 id="mcserver-usage"><a class="header" href="#mcserver-usage">MCServer Usage</a></h4>
<p>Individual providers leverage the MCServer as follows:</p>
<pre><code class="language-go">  s := options.NewMCServer()
  driver := &lt;providerSpecificDriverInitialization&gt;
  if err := app.Run(s, driver); err != nil {
      fmt.Fprintf(os.Stderr, &quot;%v\n&quot;, err)
      os.Exit(1)
  }
</code></pre>
<p>The MCServer is thus re-used across different providers.</p>
<h4 id="machinecontrollerconfiguration-struct"><a class="header" href="#machinecontrollerconfiguration-struct">MachineControllerConfiguration struct</a></h4>
<p>An imnportant struct that represents machine configuration that supports deep-coopying and is embedded within the <code>MCServer</code></p>
<p><code>machine-controller-manager/pkg/util/provider/options.MachineControllerConfiguration</code></p>
<pre><code class="language-go">type MachineControllerConfiguration struct {
	metav1.TypeMeta

	// namespace in seed cluster in which controller would look for the resources.
	Namespace string

	// port is the port that the controller-manager's http service runs on.
	Port int32
	// address is the IP address to serve on (set to 0.0.0.0 for all interfaces).
	Address string
	// CloudProvider is the provider for cloud services.
	CloudProvider string
	// ConcurrentNodeSyncs is the number of node objects that are
	// allowed to sync concurrently. Larger number = more responsive nodes,
	// but more CPU (and network) load.
	ConcurrentNodeSyncs int32

	// enableProfiling enables profiling via web interface host:port/debug/pprof/
	EnableProfiling bool
	// enableContentionProfiling enables lock contention profiling, if enableProfiling is true.
	EnableContentionProfiling bool
	// contentType is contentType of requests sent to apiserver.
	ContentType string
	// kubeAPIQPS is the QPS to use while talking with kubernetes apiserver.
	KubeAPIQPS float32
	// kubeAPIBurst is the burst to use while talking with kubernetes apiserver.
	KubeAPIBurst int32
	// leaderElection defines the configuration of leader election client.
	LeaderElection mcmoptions.LeaderElectionConfiguration
	// How long to wait between starting controller managers
	ControllerStartInterval metav1.Duration
	// minResyncPeriod is the resync period in reflectors; will be random between
	// minResyncPeriod and 2*minResyncPeriod.
	MinResyncPeriod metav1.Duration

	// SafetyOptions is the set of options to set to ensure safety of controller
	SafetyOptions SafetyOptions

	//NodeCondition is the string of known NodeConditions. If any of these NodeCondition is set for a timeout period, the machine  will be declared failed and will replaced. Default is &quot;KernelDeadlock,ReadonlyFilesystem,DiskPressure,NetworkUnavailable&quot;
	NodeConditions string

	//BootstrapTokenAuthExtraGroups is a comma-separated string of groups to set bootstrap token's &quot;auth-extra-groups&quot; field to.
	BootstrapTokenAuthExtraGroups string
}

</code></pre>
<h5 id="safetyoptions"><a class="header" href="#safetyoptions">SafetyOptions</a></h5>
<p>An important struct availablea as the <code>SafetyOptions</code> field in <code>MachineControllerConfiguration</code> containing several timeouts, retry-limits, etc. Most of these fields are set via <a href="https://github.com/gardener/machine-controller-manager/blob/master/pkg/util/provider/app/options/options.go#L48">pkg/util/provider/app/options.NewMCServer</a> function</p>
<p><code>pkg/util/provider/option.SafetyOptions</code></p>
<pre><code class="language-go">// SafetyOptions are used to configure the upper-limit and lower-limit
// while configuring freezing of machineSet objects
type SafetyOptions struct {
	// Timeout (in durartion) used while creation of
	// a machine before it is declared as failed
	MachineCreationTimeout metav1.Duration
	// Timeout (in durartion) used while health-check of
	// a machine before it is declared as failed
	MachineHealthTimeout metav1.Duration
	// Maximum number of times evicts would be attempted on a pod for it is forcibly deleted
	// during draining of a machine.
	MaxEvictRetries int32
	// Timeout (in duration) used while waiting for PV to detach
	PvDetachTimeout metav1.Duration
	// Timeout (in duration) used while waiting for PV to reattach on new node
	PvReattachTimeout metav1.Duration

	// Timeout (in duration) for which the APIServer can be down before
	// declare the machine controller frozen by safety controller
	MachineSafetyAPIServerStatusCheckTimeout metav1.Duration
	// Period (in durartion) used to poll for orphan VMs
	// by safety controller
	MachineSafetyOrphanVMsPeriod metav1.Duration
	// Period (in duration) used to poll for APIServer's health
	// by safety controller
	MachineSafetyAPIServerStatusCheckPeriod metav1.Duration

	// APIserverInactiveStartTime to keep track of the
	// start time of when the APIServers were not reachable
	APIserverInactiveStartTime time.Time
	// MachineControllerFrozen indicates if the machine controller
	// is frozen due to Unreachable APIServers
	MachineControllerFrozen bool
}
</code></pre>
<h2 id="controller-structs"><a class="header" href="#controller-structs">Controller Structs</a></h2>
<h3 id="machine-controller-core-struct"><a class="header" href="#machine-controller-core-struct">Machine Controller Core Struct</a></h3>
<p><code>controller</code> struct in package <code>controller</code> inside go file: <code>machine-controller-manager/pkg/util/provider/machinecontroller.go</code> (Bad convention) is the concrete Machine Controller struct that holds state data for the MC and implements the classifical controller <code>Run(workers int, stopCh &lt;-chan struct{})</code> method.</p>
<p>The top level <code>MCServer.Run</code> method initializes this controller struct and calls its <code>Run</code> method</p>
<pre><code class="language-go">package controller
type controller struct {
	namespace                     string // control clustern namespace
	nodeConditions                string // Default: &quot;KernelDeadlock,ReadonlyFilesystem,DiskPressure,NetworkUnavailable&quot;

	controlMachineClient    machineapi.MachineV1alpha1Interface
	controlCoreClient       kubernetes.Interface
	targetCoreClient        kubernetes.Interface
	targetKubernetesVersion *semver.Version

	recorder                record.EventRecorder
	safetyOptions           options.SafetyOptions
	internalExternalScheme  *runtime.Scheme
	driver                  driver.Driver
	volumeAttachmentHandler *drain.VolumeAttachmentHandler
	// permitGiver store two things:
	// - mutex per machinedeployment
	// - lastAcquire time
	// it is used to limit removal of `health timed out` machines
	permitGiver permits.PermitGiver

	// listers
	pvcLister               corelisters.PersistentVolumeClaimLister
	pvLister                corelisters.PersistentVolumeLister
	secretLister            corelisters.SecretLister
	nodeLister              corelisters.NodeLister
	pdbV1beta1Lister        policyv1beta1listers.PodDisruptionBudgetLister
	pdbV1Lister             policyv1listers.PodDisruptionBudgetLister
	volumeAttachementLister storagelisters.VolumeAttachmentLister
	machineClassLister      machinelisters.MachineClassLister
	machineLister           machinelisters.MachineLister
	// queues
    // secretQueue = workqueue.NewNamedRateLimitingQueue(workqueue.DefaultControllerRateLimiter(), &quot;secret&quot;),
	secretQueue                 workqueue.RateLimitingInterface
	nodeQueue                   workqueue.RateLimitingInterface
	machineClassQueue           workqueue.RateLimitingInterface
	machineQueue                workqueue.RateLimitingInterface
	machineSafetyOrphanVMsQueue workqueue.RateLimitingInterface
	machineSafetyAPIServerQueue workqueue.RateLimitingInterface
	// syncs
	pvcSynced               cache.InformerSynced
	pvSynced                cache.InformerSynced
	secretSynced            cache.InformerSynced
	pdbV1Synced             cache.InformerSynced
	volumeAttachementSynced cache.InformerSynced
	nodeSynced              cache.InformerSynced
	machineClassSynced      cache.InformerSynced
	machineSynced           cache.InformerSynced
}

</code></pre>
<h2 id="driver"><a class="header" href="#driver">Driver</a></h2>
<p><a href="https://pkg.go.dev/github.com/gardener/machine-controller-manager@v0.47.0/pkg/util/provider/driver#Driver">github.com/gardener/machine-controller-manager/pkg/util/provider/driver.Driver</a>  is the abstraction facade that decouplesthe machine controller from the cloud-provider specific machine lifecycle details. The MC invokes driver methods while performing reconciliation.</p>
<pre><code class="language-go">type Driver interface {
	CreateMachine(context.Context, *CreateMachineRequest) (*CreateMachineResponse, error)
	DeleteMachine(context.Context, *DeleteMachineRequest) (*DeleteMachineResponse, error)
	GetMachineStatus(context.Context, *GetMachineStatusRequest) (*GetMachineStatusResponse, error)
	ListMachines(context.Context, *ListMachinesRequest) (*ListMachinesResponse, error)
	GetVolumeIDs(context.Context, *GetVolumeIDsRequest) (*GetVolumeIDsResponse, error)
	GenerateMachineClassForMigration(context.Context, *GenerateMachineClassForMigrationRequest) (*GenerateMachineClassForMigrationResponse, error)
}
</code></pre>
<ul>
<li><code>GetVolumeIDs</code> returns a list volumeIDs for the given list of <a href="https://pkg.go.dev/k8s.io/api/core/v1#PersistentVolumeSpec">PVSpecs</a>
<ul>
<li>Example: the AWS driver checks if <code>spec.AWSElasticBlockStore.VolumeID</code> is not nil and coverts the k8s <code>spec.AWSElasticBlockStore.VolumeID</code> to the EBS volume ID. Or if storage is provided by CSI <code>spec.CSI.Driver=&quot;ebs.csi.aws.com&quot;</code> just gets <code>spec.CSI.VolumeHandle</code></li>
</ul>
</li>
<li><code>GetMachineStatus</code> gets the status of the VM backing the machine object on the provider</li>
</ul>
<h2 id="codes-and-error-status"><a class="header" href="#codes-and-error-status">Codes and (error) Status</a></h2>
<h3 id="code"><a class="header" href="#code">Code</a></h3>
<p><a href="https://pkg.go.dev/github.com/gardener/machine-controller-manager@v0.47.0/pkg/util/provider/machinecodes/codes#Code">github.com/gardener/machine-controller-manager/pkg/util/provider/machinecodes/codes.Code</a> is a <code>uint32</code> with following error codes. These error codes are contained in errors returned from Driver methods.</p>
<p>Note: Un-happy with current design. It is clear that some error codes overlap each other in the sense that they are supersets of other codes. The right thing to do would have been to make an ErrorCategory.</p>
<div class="table-wrapper"><table><thead><tr><th>Value</th><th>Code</th><th>Description</th></tr></thead><tbody>
<tr><td>0</td><td>Ok</td><td>Success</td></tr>
<tr><td>1</td><td>Canceled</td><td>the operation was canceled (by caller)</td></tr>
<tr><td>2</td><td>Unknown</td><td>Unknown error (unrecognized code)</td></tr>
<tr><td>3</td><td>InvalidArgument</td><td>InvalidArgument indicates client specified an invalid argument.</td></tr>
<tr><td>4</td><td>DeadlineExceeded</td><td>DeadlineExceeded means operation expired before completion.  For operations that change the state of the system, this error may be  returned even if the operation has completed successfully. For example, a successful response from a server could have been delayed long enough for the deadline to expire.</td></tr>
<tr><td>5</td><td>NotFound</td><td>requested entity not found.</td></tr>
<tr><td>6</td><td>AlreadyExists</td><td>an attempt to create an entity failed because one already exists.</td></tr>
<tr><td>7</td><td>PermissionDenied</td><td>caller does not have permission to execute the specified operation.</td></tr>
<tr><td>8</td><td>ResourceExhausted</td><td>indicates some resource has been exhausted, perhaps a per-user quota, or perhaps the entire file system is out of space.</td></tr>
<tr><td>9</td><td>FailedPrecondition</td><td>operation was rejected because the	 system is not in a state required for the operation's execution.</td></tr>
<tr><td>10</td><td>Aborted</td><td>operation was aborted and client should retry the full process</td></tr>
<tr><td>11</td><td>OutOfRange</td><td>operation was attempted past the valid range. Unlike InvalidArgument, this error indicates a problem that may be fixed if the system state changes.</td></tr>
<tr><td>12</td><td>UnImplemented</td><td>operation is not implemented or not supported</td></tr>
<tr><td>13</td><td>Internal</td><td>BAD. Some internal invariant broken.</td></tr>
<tr><td>14</td><td>Unavailable</td><td>Service is currently unavailable (transient and op may be tried with backoff)</td></tr>
<tr><td>15</td><td>DataLoss</td><td>unrecoverable data loss or corruption.</td></tr>
<tr><td>16</td><td>Unauthenticated</td><td>request does not have valid creds for operation. Note: It would have been nice if 7 was called Unauthorized.</td></tr>
</tbody></table>
</div>
<h3 id="status"><a class="header" href="#status">Status</a></h3>
<p>(OPINION: I beleive this is a minor NIH design defect. Ideally one should have re-levaraged the k8s API machinery Status <a href="https://pkg.go.dev/k8s.io/apimachinery@v0.25.2/pkg/apis/meta/v1#Status">k8s.io/apimachinery/pkg/apis/meta/v1.Status</a>
instead of making custom status object.)</p>
<p><a href="https://pkg.go.dev/github.com/gardener/machine-controller-manager@v0.47.0/pkg/util/provider/machinecodes/status">status</a> implements errors returned by MachineAPIs. MachineAPIs service handlers should return an error created by this package, and machineAPIs clients should expect a corresponding error to be returned from the RPC call.</p>
<p><a href="https://pkg.go.dev/github.com/gardener/machine-controller-manager@v0.47.0/pkg/util/provider/machinecodes/status#Status">status.Status</a> implements <code>error</code> and encapsulates a <code>code</code> which should be onf the codes in <a href="https://pkg.go.dev/github.com/gardener/machine-controller-manager@v0.47.0/pkg/util/provider/machinecodes/codes#Code">codes.Code</a> and a develoer-facing error message in English</p>
<pre><code class="language-go">type Status struct {
	code int32
	message string
}
// New returns a Status encapsulating code and msg.
func New(code codes.Code, msg string) *Status {
	return &amp;Status{code: int32(code), message: msg}
}
</code></pre>
<p>NOTE: No ideally why we are doing such hard work as shown in <a href="https://github.com/gardener/machine-controller-manager/blob/v0.47.0/pkg/util/provider/machinecodes/status/status.go#L84">status.FromError</a> which involves time-consuming regex parsing of an error string into a status. This is actually being used to parse error strings of errors returned by Driver methods. Not good - should be better designed.</p>
<div style="break-before: page; page-break-before: always;"></div><ul>
<li><a href="machine-controller/index.html#machine-controller">Machine Controller</a>
<ul>
<li><a href="machine-controller/index.html#mc-launch">MC Launch</a></li>
<li><a href="machine-controller/index.html#machine-controller-loop">machine controller loop</a>
<ul>
<li><a href="machine-controller/index.html#apprun">app.run</a></li>
<li><a href="machine-controller/index.html#appstartcontrollers">app.startcontrollers</a></li>
<li><a href="machine-controller/index.html#controller-initialization">controller initialization</a>
<ul>
<li><a href="machine-controller/index.html#1-newcontroller-factory-func">1. newcontroller factory func</a></li>
<li><a href="machine-controller/index.html#11-create-controller-struct">1.1 create controller struct</a></li>
<li><a href="machine-controller/index.html#12-assign-listers-and-hassynced-funcs-to-controller-struct">1.2 assign listers and hassynced funcs to controller struct</a></li>
<li><a href="machine-controller/index.html#13-register-controller-event-handlers-on-informers">1.3 register controller event handlers on informers.</a></li>
<li><a href="machine-controller/index.html#14-event-handler-functions">1.4 event handler functions</a>
<ul>
<li><a href="machine-controller/index.html#141-adding-secrets-keys-to-secretsqueue">1.4.1 adding secrets keys to secretsqueue</a></li>
<li><a href="machine-controller/index.html#142-adding-machine-class-names-and-keys-to-machineclassqueue">1.4.2 adding machine class names and keys to machineclassqueue</a></li>
<li><a href="machine-controller/index.html#143-adding-machine-keys-to-machinequeue">1.4.3 adding machine keys to machinequeue</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="machine-controller/index.html#machinecontrollerrun">machinecontroller.run</a>
<ul>
<li><a href="machine-controller/index.html#1-wait-for-informer-caches-to-sync">1. wait for informer caches to sync</a></li>
<li><a href="machine-controller/index.html#2-register-metrics">2. register metrics</a>
<ul>
<li><a href="machine-controller/index.html#21-controllerdescribe">2.1 controller.describe</a></li>
<li><a href="machine-controller/index.html#21-controllercollect">2.1 controller.collect</a></li>
</ul>
</li>
<li><a href="machine-controller/index.html#3-create-controller-worker-go-routines-applying-reconciliations">3. create controller worker go-routines applying reconciliations</a>
<ul>
<li><a href="machine-controller/index.html#31-createworker">3.1 createworker</a></li>
</ul>
</li>
<li><a href="machine-controller/index.html#4-reconciliation-functions-executed-by-worker">4. reconciliation functions executed by worker</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h1 id="machine-controller"><a class="header" href="#machine-controller">Machine Controller</a></h1>
<h2 id="mc-launch"><a class="header" href="#mc-launch">MC Launch</a></h2>
<p>most of these timeout flags are redundant since exact same values are 
given in <code>machine-controller-manager/pkg/util/provider/app/options.newmcserver</code></p>
<pre><code>go run -mod=vendor cmd/machine-controller/main.go \
			--control-kubeconfig=$(control_kubeconfig) \
			--target-kubeconfig=$(target_kubeconfig) \
			--namespace=$(control_namespace) \
			--machine-creation-timeout=20m \
			--machine-drain-timeout=5m \
			--machine-health-timeout=10m \
			--machine-pv-detach-timeout=2m \
			--machine-safety-apiserver-statuscheck-timeout=30s \
			--machine-safety-apiserver-statuscheck-period=1m \
			--machine-safety-orphan-vms-period=30m \
			--leader-elect=$(leader_elect) \
			--v=3

</code></pre>
<p>entrypoint: 
<code>cmd/machine-controller/main.go</code></p>
<ul>
<li>
<p>creates <code>machine-controller-manager/pkg/util/provider/app/options.mcserver</code> using <code>options.newmcserver</code> which is the main context object for the machinecontroller that embeds a
<code>machineconfig.machinecontrollerconfiguration</code>,   the <code>options.newmcserver</code> initializes <code>options.mcserver</code> with default values for <code>port: 10258</code>, <code>namespace: default</code>, <code>concurrentnodesyncs: 50</code>, <code>nodeconditions: &quot;kerneldeadlock,readonlyfilesystem,diskpressure,networkunavailable&quot;</code>, <code>minresyncperiod: 12 hours</code>, <code>kubeapiqps: 20</code>, <code>kubeapiburst:30</code> </p>
</li>
<li>
<p>calls <code>mcserver.addflags</code> which defines all parsing flags for the machine controller into fields of <code>mcserver</code> instance created in the last step.</p>
</li>
<li>
<p>calls <code>k8s.io/component-base/logs.newoptions</code> and then <code>options.addflags</code> for logging options. probably get rid of this when moving to <code>logr</code>. see <a href="https://github.com/gardener/gardener/blob/master/docs/development/logging.md">logging in gardener components</a>. then use the <a href="https://github.com/gardener/gardener/tree/master/hack/tools/logcheck">logcheck</a>tool.</p>
</li>
<li>
<p>calls <code>newdriver</code> with control kube config that creates a controller runtime client (<code>sigs.k8s.io/controller-runtime/pkg/client</code>) which then calls <code>pkg/local/driver.newdriver</code> passing the controlloer-runtime client which constructs a <code>localdriver</code> encapsulating the passed in client.</p>
<ul>
<li>the <code>localdriver</code> implements <a href="https://github.com/gardener/machine-controller-manager/blob/master/pkg/util/provider/driver/driver.go#l28">driver</a> is the facade for creation/deletion of vm's</li>
</ul>
</li>
<li>
<p>calls <a href="https://github.com/gardener/machine-controller-manager/blob/master/pkg/util/provider/app/app.go#l77">app.run</a> passing in the previously created <code>mcserver</code> and <code>driver</code> instances.</p>
</li>
<li></li>
</ul>
<h2 id="machine-controller-loop"><a class="header" href="#machine-controller-loop">machine controller loop</a></h2>
<h3 id="apprun"><a class="header" href="#apprun">app.run</a></h3>
<p><code>app.run</code> is the function that setups the main control loop of the machine controller server. </p>
<ul>
<li><a href="https://github.com/gardener/machine-controller-manager/blob/master/pkg/util/provider/app/app.go#l77">app.run(s *options.mcserver, driver driver.driger)</a> is the common run loop for all machine controllers</li>
<li>creates <code>targetkubeconfig</code> and <code>controlkubeconfig</code> of type <code>k8s.io/client-go/rest.config</code> from the target kube config path using <code>clientcmd.buildconfigfromflags</code></li>
<li>set fields such as <code>config.qps</code> and <code>config.burst</code>  in both <code>targetkubeconfig</code> and <code>controlkubeconfig</code> from the <code>options.newmcserver</code></li>
<li>create <code>kubeclientcontrol</code> from the <code>controlkubeconfig</code> using the standard client-go client factory metohd: <code>kubernetes.newforconfig</code> that returns a <code>client-go/kubernetes.clientset</code></li>
<li>similarly create another <code>clientset</code> named <code>leaderelectionclient</code> using <code>controlkubeconfig</code></li>
<li>start a go routine using the function <code>starthttp</code> that registers a bunch of http handlers for the go profiler, prometheus metrics and the health check.</li>
<li>call <code>createrecorder</code> passing the <code>kubeclientcontrol</code> client set instance that returns a <a href="https://github.com/kubernetes/client-go/blob/master/tools/record/event.go#l91">client-go/tools/record.eventrecorder</a>
<ul>
<li>creates a new <code>eventbroadcaster</code> of type <a href="https://github.com/kubernetes/client-go/blob/master/tools/record/event.go#l113">event.eventbroadcaster</a></li>
<li>set the logging function of the broadcaster to <code>klog.infof</code>.</li>
<li>sets the event slink using <code>startrecordingtoslink</code> passing the event interface as <code>kubeclient.corev1().restclient()).events(&quot;&quot;)</code>. effectively events will be published remotely.</li>
<li>returns the <code>record.eventrecorder</code> associated with the <code>eventbroadcaster</code> using <code>eventbroadcaster.newrecorder</code></li>
<li>constructs the <code>run</code> anonmous function assigned to <code>run</code> variable which does the following:
<ul>
<li>initializes a <code>stop</code> receive channel.</li>
<li>creates a <code>controlmachineclientbuilder</code> using <code>machineclientbuilder.simpleclientbuilder</code> using the <code>controlkubeconfig</code>.</li>
<li>creates a <code>controlcoreclientbuidler</code> using <code>coreclientbuilder.simplecontrollerclientbuilder</code> wrapping <code>controlkubeconfig</code>.</li>
<li>creates <code>targetcoreclientbuilder</code> using <code>coreclientbuilder.simplecontrollerclientbuilder</code> wrapping <code>controlkubeconfig</code>.</li>
<li>// imho far too many clients created</li>
<li>call the <code>startcontrollers</code> function passing the <code>mcserver</code>, <code>driver</code>, <code>controlkubeconfig</code>, <code>targetkubeconfig</code>, <code>controlmachineclientbuilder</code>, <code>controlcoreclientbuilder</code>, <code>targetcoreclientbuilder</code>, <code>recorder</code> and <code>stop</code> channel.
<ul>
<li>// ?: if you are going to pass the controlkubeconfig and targetkubeconfig - why not create the client builders inside the startcontrollers ?</li>
<li>if <code>startcontrollers</code> return an error panic and exit <code>run</code>.</li>
</ul>
</li>
</ul>
</li>
<li>use <a href="https://github.com/kubernetes/client-go/blob/master/tools/leaderelection/leaderelection.go#l218">leaderelection.runordie</a> to start a leader election and pass the previously created <code>run</code> function to the leader callbacks for <code>onstartedleading</code>. <code>onstartedleading</code> is called when a leaderelector client starts leading.</li>
</ul>
</li>
</ul>
<h3 id="appstartcontrollers"><a class="header" href="#appstartcontrollers">app.startcontrollers</a></h3>
<p><a href="https://github.com/gardener/machine-controller-manager/blob/master/pkg/util/provider/app/app.go#l202">app.startcontrollers</a> starts all controllers which are part fo machine controller. currently there is only one controller: the machine controller started.</p>
<ul>
<li>calls <code>getavailableresources</code> using the <code>controlcoreclientbuilder</code> that returns a <code>map[schema.groupversionresource]bool]</code> assigned to <code>availableresources</code>
<ul>
<li><code>getavailableresources</code> waits till the api server is running by checking its <code>/healthz</code> using <code>wait.pollimmediate</code>. keeps re-creating the client using <code>clientbuilder.client</code> method. </li>
<li>then uses <code>clientset.interface.discovery.serverresources</code> to get a <code>[]*metav1.apiresourcelist</code> (which encapsulates a <code>[]apiresources</code>) and then converts that to a <code>map[schema.groupversionresource]bool]</code> `</li>
</ul>
</li>
<li>creates a <code>controlmachineclient</code> which is a client for the controller crd types (type: <code>versioned.interface</code>) using <code>controlmachineclientbuilder.clientordie</code> using <code>machine-controller</code> as client name. this client targets the control cluster - ie the cluster holding the machine cr's.</li>
<li>creates a <code>controlcoreclient</code> (of type: <code>kubernetes.clientset</code>) which is the standard k8s client-go client for accessing the k8s control cluster.</li>
<li>creates a <code>targetcoreclient</code> (of type: <code>kubernetes.clientset</code>) which is the standard k8s client-go client for accessing the k8s target cluster. </li>
<li>obtain the target cluster k8s version using the discovery interface and preserve it in <code>targetkubernetesversion</code></li>
<li>if the <code>availableresources</code> does not contain the <code>machinegvr</code> exit this loop with error.</li>
<li>creates the following informer factories:
<ul>
<li><code>controlmachineinformerfactory</code> using the generated <code>client/informers/externalversions.newfilteredsharedinformerfactory</code> passing the conrol machine client, the configured min resync period and control namespace obtained from mcserver.</li>
<li><code>controlcoreinformerfactory</code> using the standard k8s client-go <code>k8s.io/client-go/informers.newfilteredsharedinformerfactory</code> method passing in the k8s client for the , the control cluster, configured min resync period and control namespace obtained from mcserver.</li>
<li><code>targetcoreinformerfactory</code> using the standard k8s client-go <code>k8s.io/client-go/informers.newfilteredsharedinformerfactory</code> method passing in the k8s core client for the target cluster, the configured min resync period and control namespace obtained from mcserver.</li>
<li>get the controller's informer access facade <code>v1alpha1.interface</code> using <code>controlmachineinformerfactory.machine().v1alpha1()</code> and assign to <code>machinesharedinformers</code></li>
<li>now create the <code>machinecontroller</code> using <code>pkg/util/provider/machinecontroller/controller.newcontroller</code> factory function, passing the below:
<ul>
<li>control namespace from <code>mcserver.namespace</code></li>
<li><code>safetyoptions</code> from <code>mcserver.safetyoptions</code></li>
<li><code>nodeconditions</code> from <code>mcserver.nodeconditions</code>. (by default these would be : &quot;kerneldeadlock,readonlyfilesystem,diskpressure,networkunavailable&quot;)</li>
<li>clients: <code>controlmachineclient</code>, <code>controlcoreclient</code>, <code>targetcoreclient</code></li>
<li>the <code>driver</code> </li>
<li>target cluster informers: <code>nodeinformer</code>, <code>persistentvolumeclaimsinformer</code>, <code>persistentvolumeinformer</code>, <code>volumeattachmentinformer</code> and <code>poddisruptionbudgetinformer</code> obtained from <code>targetcoreinformerfactory</code></li>
<li>control cluster informers: 
<ul>
<li><code>secretinformer</code> from <code>controlcoreinformerfactory</code></li>
<li><code>machineclassinformer</code>, <code>machineinformer</code> from <code>machinesharedinformers</code></li>
</ul>
</li>
<li>event recorder</li>
<li><code>targetkubernetesversion</code></li>
</ul>
</li>
<li>start all informers by calling <code>sharedinformerfactory.start(stopch &lt;-chan struct{})</code> for <code>controlmachineinformerfactory</code>, <code>controlcoreinformerfactory</code> and <code>targetcoreinformerfactory</code> passing teh <code>stop</code> channel</li>
<li>launches the <code>machinecontroller</code> in new go-routine by invoking: <code>go machinecontroller.run(mcserver.concurrentnodesyncs, stop)</code></li>
</ul>
</li>
</ul>
<h3 id="controller-initialization"><a class="header" href="#controller-initialization">controller initialization</a></h3>
<p>the machine controller is constructed using
<code>machine-controller-manager/pkg/util/provider/machinecontroller/controller.newcontroller</code> factory function which initializes the <code>controller</code> struct.</p>
<h4 id="1-newcontroller-factory-func"><a class="header" href="#1-newcontroller-factory-func">1. newcontroller factory func</a></h4>
<p>mc is constructed using the factory function below:</p>
<pre><code class="language-go">func newcontroller(
	namespace string,
	controlmachineclient machineapi.machinev1alpha1interface,
	controlcoreclient kubernetes.interface,
	targetcoreclient kubernetes.interface,
	driver driver.driver,
	pvcinformer coreinformers.persistentvolumeclaiminformer,
	pvinformer coreinformers.persistentvolumeinformer,
	secretinformer coreinformers.secretinformer,
	nodeinformer coreinformers.nodeinformer,
	pdbinformer policyinformers.poddisruptionbudgetinformer,
	volumeattachmentinformer storageinformers.volumeattachmentinformer,
	machineclassinformer machineinformers.machineclassinformer,
	machineinformer machineinformers.machineinformer,
	recorder record.eventrecorder,
	safetyoptions options.safetyoptions,
	nodeconditions string,
	bootstraptokenauthextragroups string,
) (controller, error) {
	// etc

}
</code></pre>
<h4 id="11-create-controller-struct"><a class="header" href="#11-create-controller-struct">1.1 create controller struct</a></h4>
<p>create the controller struct initializing rate-limiting work queues for all relevant resources</p>
<pre><code class="language-go">	controller := &amp;controller{
		namespace:                     namespace,
		controlmachineclient:          controlmachineclient,
		controlcoreclient:             controlcoreclient,
		targetcoreclient:              targetcoreclient,
		recorder:                      recorder,
		secretqueue:                   workqueue.newnamedratelimitingqueue(workqueue.defaultcontrollerratelimiter(), &quot;secret&quot;),
		nodequeue:                     workqueue.newnamedratelimitingqueue(workqueue.defaultcontrollerratelimiter(), &quot;node&quot;),
		machineclassqueue:             workqueue.newnamedratelimitingqueue(workqueue.defaultcontrollerratelimiter(), &quot;machineclass&quot;),
		machinequeue:                  workqueue.newnamedratelimitingqueue(workqueue.defaultcontrollerratelimiter(), &quot;machine&quot;),
		machinesafetyorphanvmsqueue:   workqueue.newnamedratelimitingqueue(workqueue.defaultcontrollerratelimiter(), &quot;machinesafetyorphanvms&quot;),
		machinesafetyapiserverqueue:   workqueue.newnamedratelimitingqueue(workqueue.defaultcontrollerratelimiter(), &quot;machinesafetyapiserver&quot;),
		safetyoptions:                 safetyoptions,
		nodeconditions:                nodeconditions,
		driver:                        driver,
		bootstraptokenauthextragroups: bootstraptokenauthextragroups,
		volumeattachmenthandler:       nil,
		permitgiver:                   permits.newpermitgiver(permitgiverstaleentrytimeout, janitorfreq),
	}


</code></pre>
<h4 id="12-assign-listers-and-hassynced-funcs-to-controller-struct"><a class="header" href="#12-assign-listers-and-hassynced-funcs-to-controller-struct">1.2 assign listers and hassynced funcs to controller struct</a></h4>
<pre><code class="language-go">	// initialize controller listers from the passed-in shared informers (8 listers)
	controller.pvclister = pvcinformer
	controller.pvlister = pvinformer.lister()
    controller.machinelister = machineinformer.lister()
	// etc
	// assign the hassynced function from the passed-in shared informers
	controller.pvcsynced = pvcinformer.informer().hassynced
	controller.pvsynced = pvinformer.informer().hassynced
    controller.machinesynced = machineinformer.informer().hassynced
</code></pre>
<h4 id="13-register-controller-event-handlers-on-informers"><a class="header" href="#13-register-controller-event-handlers-on-informers">1.3 register controller event handlers on informers.</a></h4>
<p>an informer invokes registered event handler when a k8s object changes. event handlers are registered using <code>&lt;type&gt;informer().addeventhandler(resourceeventhandler)</code> function. the controller initialization registers event handlers: on control-cluster <code>secretinformer</code>, control-cluster <code>machineclassinformer</code>, control-cluster <code>machineinformer</code> and target-cluster <code>nodeinformer</code>.</p>
<pre><code class="language-go">   // event handlers added for control-cluster secret add/delete
	secretinformer.informer().addeventhandler(cache.resourceeventhandlerfuncs{
		addfunc:    controller.secretadd,
		deletefunc: controller.secretdelete,
	})

   // 2 event handlers added for controlcluster machineclass add/update/delete
	machineclassinformer.informer().addeventhandler(cache.resourceeventhandlerfuncs{
		addfunc:    controller.machineclasstosecretadd,
		updatefunc: controller.machineclasstosecretupdate,
		deletefunc: controller.machineclasstosecretdelete,
	})

	machineclassinformer.informer().addeventhandler(cache.resourceeventhandlerfuncs{
		addfunc:    controller.machineclassadd,
		updatefunc: controller.machineclassupdate,
		deletefunc: controller.machineclassdelete,
	})

   // 3 event handlers added for control-cluster machine add/update/delete
	machineinformer.informer().addeventhandler(cache.resourceeventhandlerfuncs{
		addfunc:    controller.machinetomachineclassadd,
		updatefunc: controller.machinetomachineclassupdate,
		deletefunc: controller.machinetomachineclassdelete,
	})
	machineinformer.informer().addeventhandler(cache.resourceeventhandlerfuncs{
		addfunc:    controller.addmachine,
		updatefunc: controller.updatemachine,
		deletefunc: controller.deletemachine,
	})

	machineinformer.informer().addeventhandler(cache.resourceeventhandlerfuncs{
		// updatemachinetosafety makes sure that orphan vm handler is invoked on some specific machine obj updates
		updatefunc: controller.updatemachinetosafety,
		// deletemachinetosafety makes sure that orphan vm handler is invoked on any machine deletion
		deletefunc: controller.deletemachinetosafety,
	})

    // event handler registered for target-cluster node add/update/delete
	nodeinformer.informer().addeventhandler(cache.resourceeventhandlerfuncs{
		addfunc:    controller.addnodetomachine,
		updatefunc: controller.updatenodetomachine,
		deletefunc: controller.deletenodetomachine,
	}		

	// event handler added for target-cluster volume attachments is handled by
	// utility volumeattachmenthandler that can distribute incoming volueattachment 
	// add/updates to a bunch of workers.
	controller.volumeattachmenthandler = drain.newvolumeattachmenthandler()
	volumeattachmentinformer.informer().addeventhandler(cache.resourceeventhandlerfuncs{
		addfunc:    controller.volumeattachmenthandler.addvolumeattachment,
		updatefunc: controller.volumeattachmenthandler.updatevolumeattachment,
	})
</code></pre>
<h4 id="14-event-handler-functions"><a class="header" href="#14-event-handler-functions">1.4 event handler functions</a></h4>
<p>controller informer event handlers generally add the object keys to the appropriate work queues which are later picked up and reconciled in processing in <code>controller.run</code>.</p>
<p>the work queue is used to separate the delivery of the object from its processing. resource event handler functions extract the key of the delivered object and add it to the relevant work queue for future processing. (in <code>controller.run</code>) </p>
<h5 id="141-adding-secrets-keys-to-secretsqueue"><a class="header" href="#141-adding-secrets-keys-to-secretsqueue">1.4.1 adding secrets keys to secretsqueue</a></h5>
<p><code>controller.secretadd(obj interfade{})</code> which is the <code>addfunc</code> callback registered for the <code>secretinformer</code> extracts the secret <code>key</code> using <code>cache.deletionhandlingmetanamespacekeyfunc(obj)</code> and then adds this <code>key</code> to the <code>secretqueue</code>.</p>
<pre><code class="language-go">func (c *controller) secretadd(obj interface{}) {
// confusing. should just use metanamespacekeyfunc(obj)
	key, err := cache.deletionhandlingmetanamespacekeyfunc(obj) 
	if err != nil {
		c.secretqueue.add(key)
	}
}
func (c *controller) secretdelete(obj interface{}) {
	c.secretadd(obj) // dont like this delegation
}
</code></pre>
<p>in the case of <code>controller.secretdelete</code>, we must check for the <a href="https://pkg.go.dev/k8s.io/client-go/tools/cache#deletedfinalstateunknown">deletedfinalstateunknown</a> state of that secret in the cache before enqueuing its key. the <code>deletedfinalstateunknown</code> state means that the object has been deleted but that the watch deletion event was missed while disconnected from apiserver and the controller didn't react accordingly, hence we need to add to the secretqueue for processing.</p>
<p><code>controller.machineclasstosecretadd</code>  is the <code>addfunc</code> callback registered for the <code>machineclassinformer</code> adds the key (namespace/name) of the secret obtained from the newly added <code>machineclass</code> object.</p>
<pre><code class="language-go">func (c *controller) machineclasstosecretadd(obj interface{}) {
	machineclass, ok := obj.(*v1alpha1.machineclass)
	// if error or nil ref return
	secretrefs := []*corev1.secretreference{machineclass.secretref, machineclass.credentialssecretref}
	for _, secretref := range secretrefs {
		if secretref != nil {
			queue.add(secretref.namespace + &quot;/&quot; + secretref.name)
		}
	}
}
</code></pre>
<p><code>controller.machineclasstosecretupdate</code> is the <code>updatefunc</code> callback registered for the <code>machine classinformer</code> which adds the key (namespace/name) of the secret obtained from the old/new machine class if its <code>secretref</code> is not nil.</p>
<pre><code class="language-go">func (c *controller) machineclasstosecretupdate(oldobj interface{}, newobj interface{}) {
	oldmachineclass, ok := oldobj.(*v1alpha1.machineclass)
	newmachineclass, ok := newobj.(*v1alpha1.machineclass)
	// if error or nil refs return
	secretqueue.add(oldmachineclass.secretref.namespace + &quot;/&quot; + oldmachineclass.secretref.name)
	secretqueue.add(newmachineclass.secretref.namespace + &quot;/&quot; + newmachineclass.secretref.name)
}
</code></pre>
<h5 id="142-adding-machine-class-names-and-keys-to-machineclassqueue"><a class="header" href="#142-adding-machine-class-names-and-keys-to-machineclassqueue">1.4.2 adding machine class names and keys to machineclassqueue</a></h5>
<p><code>controller.machineclassadd</code>is specified as both the <code>addfunc</code> and <code>deletefunc</code> callback registered on the <code>machineclassinformer</code>. it gets the object key <code>namespace/name</code> for the machine class <code>obj</code> and adds the key to the <code>machineclassqueue</code></p>
<p><code>controller.machineclassupdate</code> just delegates to <code>controller.machineclassadd(newobj)</code>.</p>
<pre><code class="language-go">func (c *controller) machineclassadd(obj interface{}) {
	key, err := cache.deletionhandlingmetanamespacekeyfunc(obj)
	// log &amp; return on err != nil
	c.machineclassqueue.add(key)
}
func (c *controller) machineclassupdate(oldobj, newobj interface{}) {
	old, ok := oldobj.(*v1alpha1.machineclass)
	if old == nil || !ok {
		return
	}
	new, ok := newobj.(*v1alpha1.machineclass)
	if new == nil || !ok {
		return
	}

	c.machineclassadd(newobj)
}
</code></pre>
<p><code>controller.machinetomachineclassadd</code> is both an <code>addfunc</code> and <code>deletefunc</code> callback registered on the <code>machineinfomer</code> . this simply adds the machine spec class name to the <code>machineclassqueue</code>. </p>
<pre><code class="language-go">
func (c *controller) machinetomachineclassadd(obj interface{}) {
	c.machineclassqueue.add(machine.spec.class.name)
}
</code></pre>
<p><code>controller.machinetomachineclassupdate</code> is the <code>updatefunc</code> callback registered on the <code>machineinformer</code>.  it enqueues the <code>newmacine</code> spec class name if there are no changes in the machine class name, otherwise it adds both the old and new machine classnames to the `machineclassqueue'.</p>
<pre><code class="language-go">func (c *controller) machinetomachineclassupdate(oldobj, newobj interface{}) {
	oldmachine, ok := oldobj.(*v1alpha1.machine)
	newmachine, ok := newobj.(*v1alpha1.machine)
	// return if nil or not ok
	if oldmachine.spec.class.kind == newmachine.spec.class.kind {
		c.machineclassqueue.add(newmachine.spec.class.name)
	} else {
		c.machineclassqueue.add(oldmachine.spec.class.name)
		c.machineclassqueue.add(newmachine.spec.class.name)
	}
}
</code></pre>
<p>so, the <code>machineclassqueue</code> effectively holds machine-class keys (ns/name) and plain class names (name)
for added/updated/delete machine classes.</p>
<h5 id="143-adding-machine-keys-to-machinequeue"><a class="header" href="#143-adding-machine-keys-to-machinequeue">1.4.3 adding machine keys to machinequeue</a></h5>
<p><code>controller.addmachine</code>, <code>controller.updatemachine</code> and <code>controller.deletemachine</code> all just deletgate the newly added/newly updated and newly delete machine obj to <code>controller.enqueuemachine</code> which simpy gets the object key for the machine and adds it to the <code>machinequeue</code>.</p>
<pre><code class="language-go">func (c *controller) enqueuemachine(obj interface{}) {
	key, err := cache.metanamespacekeyfunc(obj)
	// return if err
	c.machinequeue.add(key)
}
</code></pre>
<p><code>controller.addnodetomachine</code> is specified as the <code>addfunc</code> registered for the <code>nodeinformer</code>.  basically, when a new node is created, the corresponding <code>machine</code> obj is obtained for the <code>node</code> and if the <code>machine.status.conditions</code>  does not match the <code>nodestatusconditions</code> then the machine <code>key</code> is added to the <code>machinequeue</code> for reconciliation.</p>
<p>snippet shown be below with error handling+logging omitted.</p>
<pre><code class="language-go">func (c *controller) addnodetomachine(obj interface{}) {
	// if err != nil log err and return
	node := obj.(*corev1.node)
	key, err := cache.deletionhandlingmetanamespacekeyfunc(obj)
	machine, err := c.getmachinefromnode(key) // leverages machinelister and gets machine whose 'node' label matches key
	if machine.status.currentstatus.phase != v1alpha1.machinecrashloopbackoff &amp;&amp; nodeconditionshavechanged(machine.status.conditions, node.status.conditions) {
		macinekey, err = cache.metanamespacekeyfunc(obj)
		c.machinequeue.add(key)
	}
}

</code></pre>
<p><code>controller.updatenodetomachine</code> is specified as <code>updatefunc</code> registered for the <code>nodeinformer</code>. in a nutshell, it simply delegates to <code>addnodetomachine(newobj)</code> except if the node has the annotation <code>machineutils.triggerdeletionbymcm</code> (value: <code>node.machine.sapcloud.io/trigger-deletion-by-mcm</code>), in which case get the <code>machine</code> obj corresponding to the node and then leverages the <code>controlmachineclient</code> to delete the machine object.</p>
<p>todo: who sets this annotation ?? can't find the guy.</p>
<p>snippet shown be below without error handling+logging omitted.</p>
<pre><code class="language-go">func (c *controller) updatenodetomachine(oldobj, newobj interface{}) {
	node := newobj.(*corev1.node)
	// check for the triggerdeletionbymcm annotation on the node object
	// if it is present then mark the machine object for deletion
	if value, ok := node.annotations[machineutils.triggerdeletionbymcm]; ok &amp;&amp; value == &quot;true&quot; {
		machine, err := c.getmachinefromnode(node.name)
		if machine.deletiontimestamp == nil {
			c.controlmachineclient
			.machines(c.namespace)
			.delete(context.background(), machine.name, metav1.deleteoptions{});		
		} 
	}  else {
		c.addnodetomachine(newobj)
	}
}
</code></pre>
<p><code>controller.deletenodetomachine</code> is specified as <code>deletefunc</code> registered for the <code>nodeinformer</code> and is quite simple. it just finds the corresponding machine object and adds its key to the <code>machinequeue</code></p>
<p>snippet shown be below without error handling+logging omitted.</p>
<pre><code class="language-go">func (c *controller) deletenodetomachine(obj interface{}) {
	// if err != nil log error and return for statements below
	key, err := cache.deletionhandlingmetanamespacekeyfunc(obj)
	machine, err := c.getmachinefromnode(key) // leverages machinelister and gets machine whose 'node' label matches key
	macinekey, err = cache.metanamespacekeyfunc(obj)
	c.machinequeue.add(key)
}

</code></pre>
<h3 id="machinecontrollerrun"><a class="header" href="#machinecontrollerrun">machinecontroller.run</a></h3>
<pre><code class="language-go">func (c *controller) run(workers int, stopch &lt;-chan struct{}) {
	// ...
}

</code></pre>
<h4 id="1-wait-for-informer-caches-to-sync"><a class="header" href="#1-wait-for-informer-caches-to-sync">1. wait for informer caches to sync</a></h4>
<p>when an informer starts, it will build a cache of all resources it currently watches which is lost when the application
restarts. this means that on startup, each of your handler functions will be invoked as the initial state is built. if this
is not desirable for your use case, you can wait until the caches are synced before performing any updates using the
<code>cache.waitforcachesync</code> function:</p>
<pre><code class="language-go">if !cache.waitforcachesync(stopch, c.secretsynced, c.pvcsynced, c.pvsynced, c.pdbsynced, c.volumeattachementsynced, c.nodesynced, c.machineclasssynced, c.machinesynced) {
		runtimeutil.handleerror(fmt.errorf(&quot;timed out waiting for caches to sync&quot;))
		return
}
</code></pre>
<h4 id="2-register-metrics"><a class="header" href="#2-register-metrics">2. register metrics</a></h4>
<p>the controller struct implements the <a href="https://pkg.go.dev/github.com/prometheus/client_golang@v1.13.0/prometheus#collector">prometheus.collector</a> interface and can therefore
be registered on prometheus metrics registry. </p>
<p>collectors which are added to the registry will collect metrics to expose them via the metrics endpoint of the mcm every time when the endpoint is called.</p>
<pre><code class="language-go">prometheus.mustregister(c)
</code></pre>
<h5 id="21-controllerdescribe"><a class="header" href="#21-controllerdescribe">2.1 controller.describe</a></h5>
<p>all <a href="https://pkg.go.dev/github.com/prometheus/client_golang@v1.13.0/prometheus#metric">promethueus.metric</a> that are collected must first be described using a <a href="https://pkg.go.dev/github.com/prometheus/client_golang@v1.13.0/prometheus#desc">prometheus.desc</a> which is the <em>meta-data</em> about a metric.</p>
<p>as can be seen below the machine controller sends a description of <code>metrics.machinecountdesc</code> to prometheus. this is <code>mcm_machine_items_total</code> which is the count of machines managed by controller. doubt: we currently appear to have  only have one metric for the mc ?</p>
<pre><code class="language-go">var machinecountdesc = prometheus.newdesc(&quot;mcm_machine_items_total&quot;, &quot;count of machines currently managed by the mcm.&quot;, nil, nil)

func (c *controller) describe(ch chan&lt;- *prometheus.desc) {
	ch &lt;- metrics.machinecountdesc
}
</code></pre>
<h5 id="21-controllercollect"><a class="header" href="#21-controllercollect">2.1 controller.collect</a></h5>
<p><code>collect</code> is called by the prometheus registry when collecting
metrics. the implementation sends each collected metric via the
provided channel and returns once the last metric has been sent. the
descriptor of each sent metric is one of those returned by <code>describe</code></p>
<p>todo: describe each of the collect methods.</p>
<pre><code class="language-go">// collect is method required to implement the prometheus.collect interface.
func (c *controller) collect(ch chan&lt;- prometheus.metric) {
	c.collectmachinemetrics(ch)
	//c.collectmachinesetmetrics(ch)
	//c.collectmachinedeploymentmetrics(ch)
	c.collectmachinecontrollerfrozenstatus(ch)
}
</code></pre>
<h4 id="3-create-controller-worker-go-routines-applying-reconciliations"><a class="header" href="#3-create-controller-worker-go-routines-applying-reconciliations">3. create controller worker go-routines applying reconciliations</a></h4>
<pre><code class="language-go">func (c *controller) run(workers int, stopch &lt;-chan struct{}) {
	//.. 3
	waitgroup sync.waitgroup
	for i := 0; i &lt; workers; i++ {
		createworker(c.secretqueue, &quot;clustersecret&quot;, maxretries, true, c.reconcileclustersecretkey, stopch, &amp;waitgroup)
		createworker(c.machineclassqueue, &quot;clustermachineclass&quot;, maxretries, true, c.reconcileclustermachineclasskey, stopch, &amp;waitgroup)
		createworker(c.nodequeue, &quot;clusternode&quot;, maxretries, true, c.reconcileclusternodekey, stopch, &amp;waitgroup)
		createworker(c.machinequeue, &quot;clustermachine&quot;, maxretries, true, c.reconcileclustermachinekey, stopch, &amp;waitgroup
		createworker(c.machinesafetyorphanvmsqueue, &quot;clustermachinesafetyorphanvms&quot;, maxretries, true, c.reconcileclustermachinesafetyorphanvms, stopch, &amp;waitgroup)
		createworker(c.machinesafetyapiserverqueue, &quot;clustermachineapiserver&quot;, maxretries, true, c.reconcileclustermachinesafetyapiserver, stopch, &amp;waitgroup)
	}
	&lt;-stopch
	waitgroup.wait()
}

</code></pre>
<h5 id="31-createworker"><a class="header" href="#31-createworker">3.1 createworker</a></h5>
<p><code>createworker</code> creates and runs a go-routine that just processes items in the
specified <code>queue</code>. the worker will run until <code>stopch</code> is closed. the worker will be
added to the wait group when started and marked done when finished.</p>
<pre><code class="language-go">func createworker(queue workqueue.ratelimitinginterface, resourcetype string, maxretries int, forgetaftersuccess bool, reconciler func(key string) error, stopch &lt;-chan struct{}, waitgroup *sync.waitgroup) {
	waitgroup.add(1)
	go func() {
		wait.until(worker(queue, resourcetype, maxretries, forgetaftersuccess, reconciler), time.second, stopch)
		waitgroup.done()
	}()
}
</code></pre>
<p><a href="https://github.com/gardener/machine-controller-manager/blob/v0.47.0/pkg/util/provider/machinecontroller/controller.go#l369">worker</a> returns a function that </p>
<ol>
<li>de-queues items (keys) from the work <code>queue</code>. the <code>key</code>s that are obtained using work <code>queue.get</code> to be strings of the form <code>namespace/name</code> of the resource. </li>
<li>processes them by invoking the <code>reconciler(key)</code> function 
<ol>
<li>the purpose of the <code>reconciler</code> is to compares the actual state with the desired state, and attempts to converge the two. it should then update the <code>status</code> block of the resource.</li>
<li>if <code>reconciler</code> returns an error, requeue the item up to <code>maxretries</code> before giving up.</li>
</ol>
</li>
<li>marks items as done.</li>
</ol>
<p>then we execute the <code>reconciler</code>. </p>
<pre><code class="language-go">func worker(queue workqueue.ratelimitinginterface, resourcetype string, maxretries int, forgetaftersuccess bool, reconciler func(key string) error) func() {
	return func() {
		exit := false
		for !exit {
			exit = func() bool {
				key, quit := queue.get()
				if quit {
					return true
				}
				defer queue.done(key)

				err := reconciler(key.(string))
				if err == nil {
					if forgetaftersuccess { // always true for mc
						queue.forget(key)
					}
					return false
				}

				if queue.numrequeues(key) &lt; maxretries {
					queue.addratelimited(key)
					return false
				}

				queue.forget(key)
				return false
			}()
		}
	}
}
</code></pre>
<h4 id="4-reconciliation-functions-executed-by-worker"><a class="header" href="#4-reconciliation-functions-executed-by-worker">4. reconciliation functions executed by worker</a></h4>
<p>the controller starts worker go-routines that pop out keys from the relevant workqueue and execute the reconcile function.</p>
<p>See reconcile chapters.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="reconcile-cluster-machine-class-key"><a class="header" href="#reconcile-cluster-machine-class-key">Reconcile Cluster Machine Class Key</a></h1>
<p><code>reconcileClusterMachineClassKey</code> reconciles an machineClass due to controller resync or an event on the machineClass.</p>
<pre><code class="language-go">func (c *controller) reconcileClusterMachineClassKey(key string) error
</code></pre>
<pre class="mermaid">%%{init: {'themeVariables': { 'fontSize': '10px'}, &quot;flowchart&quot;: {&quot;useMaxWidth&quot;: false }}}%%
flowchart TD


a[&quot;ns,name=cache.splitmetanamespacekey(mkey)&quot;]
getm[&quot;machine=machinelister.machines(ns).get(name)&quot;]
valm[&quot;validation.validatemachine(machine)&quot;]
valmc[&quot;machineclz,secretdata,err=validation.validatemachineclass(machine)&quot;]
longr[&quot;retryperiod=machineutils.longretry&quot;]
shortr[&quot;retryperiod=machineutils.shortretry&quot;]
enqm[&quot;machinequeue.addafter(mkey, retryperiod)&quot;]
checkmdel{&quot;is\nmachine.deletiontimestamp\nset?&quot;}
newdelreq[&quot;req=&amp;driver.deletemachinerequest{machine,machineclz,secretdata}&quot;]
delflow[&quot;retryperiod=controller.triggerdeletionflow(req)&quot;]
createflow[&quot;retryperiod=controller.triggercreationflow(req)&quot;]
hasfin{&quot;hasfinalizer(machine)&quot;}
addfin[&quot;addmachinefinalizers(machine)&quot;]
checkmachinenodeexists{&quot;machine.status.node\nexists?&quot;}
reconcilemachinehealth[&quot;controller.reconcilemachinehealth(machine)&quot;]
syncnodetemplates[&quot;controller.syncnodetemplates(machine)&quot;]
newcreatereq[&quot;req=&amp;driver.createmachinerequest{machine,machineclz,secretdata}&quot;]
z((&quot;end&quot;))

a--&gt;getm
enqm--&gt;z
longr--&gt;enqm
shortr--&gt;enqm
getm--&gt;valm
valm--&gt;ok--&gt;valmc
valm--err--&gt;longr
valmc--err--&gt;longr
valmc--ok--&gt;checkmdel
checkmdel--yes--&gt;newdelreq
checkmdel--no--&gt;hasfin
newdelreq--&gt;delflow
hasfin--no--&gt;addfin
hasfin--yes--&gt;shortr
addfin--&gt;checkmachinenodeexists
checkmachinenodeexists--yes--&gt;reconcilemachinehealth
checkmachinenodeexists--no--&gt;newcreatereq
reconcilemachinehealth--ok--&gt;syncnodetemplates
syncnodetemplates--ok--&gt;longr
syncnodetemplates--err--&gt;shortr
delflow--&gt;enqm
newcreatereq--&gt;createflow
createflow--&gt;enqm

</pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="reconcile-cluster-secret"><a class="header" href="#reconcile-cluster-secret">Reconcile Cluster Secret</a></h1>
<p><code>reconcileClusterSecretKey</code> reconciles an secret due to controller resync
or an event on the secret</p>
<pre><code class="language-go">func (c *controller) reconcileClusterSecretKey(key string) error 
// which looks up secret and delegates to
func (c *controller) reconcileClusterSecret(ctx context.Context, secret *corev1.Secret) error 
</code></pre>
<h2 id="usage"><a class="header" href="#usage">Usage</a></h2>
<p>Worker go-routines are created for this as below</p>
<pre><code class="language-go">createWorker(c.secretQueue, 
    &quot;ClusterSecret&quot;, 
    maxRetries, 
    true, 
    c.reconcileClusterSecretKey,
     stopCh, 
     &amp;waitGroup)
</code></pre>
<h2 id="flow"><a class="header" href="#flow">Flow</a></h2>
<p><a href="https://github.com/gardener/machine-controller-manager/blob/v0.47.0/pkg/util/provider/machinecontroller/secret.go#L37">controller.reconcileClusterSecretkey</a>
basically adds the <a href="machine-controller/../mcm_facilities.html#finalizers">MCFinalizerName</a>  (value: <code>machine.sapcloud.io/machine-controller</code>) to the list of finalizers for all secrets that are referenced by machine classes within the same namespace.</p>
<pre class="mermaid">%%{init: {'themeVariables': { 'fontSize': '10px'}, &quot;flowchart&quot;: {&quot;useMaxWidth&quot;: false }}}%%

flowchart TD

a[ns, name = cache.splitmetanamespacekey]
b[&quot;sec=secretLister.secrets(ns).get(name)&quot;]
c[&quot;machineclasses=findMachineClassForsecret(name)
// gets the set of MachineClasses referring to the passed secret
&quot;]
d{machineclasses empty?}
e[&quot;updateSecretFinalizers(sec)&quot;] 
f[&quot;secretq.addafter(key,10min)&quot;]
z((&quot;end&quot;))
a--&gt;b
b--&gt;c
c--&gt;d
d--yes--&gt;z
d--no--&gt;e
e--err--&gt;f
e--success--&gt;z
f--&gt;z
</pre>
<h3 id="updatesecretfinalizers"><a class="header" href="#updatesecretfinalizers">updateSecretFinalizers</a></h3>
<pre><code class="language-go">func (c *controller) updateSecretFinalizers(ctx context.Context, secret *corev1.Secret, finalizers []string) error 
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><ul>
<li><a href="machine-controller/cluster_machine_reconcile.html#cluster-machine-reconciliation">Cluster Machine Reconciliation</a>
<ul>
<li><a href="machine-controller/cluster_machine_reconcile.html#controllertriggercreationflow">controller.triggerCreationFlow</a>
<ul>
<li><a href="machine-controller/cluster_machine_reconcile.html#controlleraddbootstraptokentouserdata">controller.addBootstrapTokenToUserData</a></li>
</ul>
</li>
<li><a href="machine-controller/cluster_machine_reconcile.html#controllertriggerdeletionflow">controller.triggerDeletionFlow</a>
<ul>
<li><a href="machine-controller/cluster_machine_reconcile.html#controllergetvmstatus">controller.getVMStatus</a></li>
<li><a href="machine-controller/cluster_machine_reconcile.html#controllerdrainnode">controller.drainNode</a></li>
</ul>
</li>
<li><a href="machine-controller/cluster_machine_reconcile.html#controllerreconcilemachinehealth">controller.reconcileMachineHealth</a>
<ul>
<li><a href="machine-controller/cluster_machine_reconcile.html#health-check-flow-diagram">Health Check FLow Diagram</a></li>
<li><a href="machine-controller/cluster_machine_reconcile.html#health-check-summary">Health Check Summary</a></li>
<li><a href="machine-controller/cluster_machine_reconcile.html#health-check-doubts">Health Check Doubts</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<p>While perusing the below, you might need to reference <a href="machine-controller/./mc_helper_funcs.html">Machine Controller Helper Functions</a>  as several reconcile functions delegate to helper methods defined on the machine controller struct.</p>
<h1 id="cluster-machine-reconciliation"><a class="header" href="#cluster-machine-reconciliation">Cluster Machine Reconciliation</a></h1>
<pre><code class="language-go">func (c *controller) reconcileClusterMachineKey(key string) error
</code></pre>
<p>The top-level reconcile function for the machine that analyzes machine status and delegates to the individual reconcile functions for machine-creation, machine-deletion and machine-health-check flows. </p>
<pre class="mermaid">%%{init: {'themeVariables': { 'fontSize': '10px'}, &quot;flowchart&quot;: {&quot;useMaxWidth&quot;: false }}}%%
flowchart TD

A[&quot;ns,name=cache.SplitMetaNamespaceKey(mKey)&quot;]
GetM[&quot;machine=machineLister.Machines(ns).Get(name)&quot;]
ValM[&quot;validation.ValidateMachine(machine)&quot;]
ValMC[&quot;machineClz,secretData,err=validation.ValidateMachineClass(machine)&quot;]
LongR[&quot;retryPeriod=machineutils.LongRetry&quot;]
ShortR[&quot;retryPeriod=machineutils.ShortRetry&quot;]
EnqM[&quot;machineQueue.AddAfter(mKey, retryPeriod)&quot;]
CheckMDel{&quot;Is\nmachine.DeletionTimestamp\nSet?&quot;}
NewDelReq[&quot;req=&amp;driver.DeleteMachineRequest{machine,machineClz,secretData}&quot;]
DelFlow[&quot;retryPeriod=controller.triggerDeletionFlow(req)&quot;]
CreateFlow[&quot;retryPeriod=controller.triggerCreationFlow(req)&quot;]
HasFin{&quot;HasFinalizer(machine)&quot;}
AddFin[&quot;addMachineFinalizers(machine)&quot;]
CheckMachineNodeExists{&quot;machine.Status.Node\nExists?&quot;}
ReconcileMachineHealth[&quot;controller.reconcileMachineHealth(machine)&quot;]
SyncNodeTemplates[&quot;controller.syncNodeTemplates(machine)&quot;]
NewCreateReq[&quot;req=&amp;driver.CreateMachineRequest{machine,machineClz,secretData}&quot;]
Z((&quot;End&quot;))

Begin((&quot; &quot;))--&gt;A
A--&gt;GetM
EnqM--&gt;Z
LongR--&gt;EnqM
ShortR--&gt;EnqM
GetM--&gt;ValM
ValM--Ok--&gt;ValMC
ValM--Err--&gt;LongR
ValMC--Err--&gt;LongR
ValMC--Ok--&gt;CheckMDel
CheckMDel--Yes--&gt;NewDelReq
CheckMDel--No--&gt;HasFin
NewDelReq--&gt;DelFlow
HasFin--No--&gt;AddFin
HasFin--Yes--&gt;ShortR
AddFin--&gt;CheckMachineNodeExists
CheckMachineNodeExists--Yes--&gt;ReconcileMachineHealth
CheckMachineNodeExists--No--&gt;NewCreateReq
ReconcileMachineHealth--Ok--&gt;SyncNodeTemplates
SyncNodeTemplates--Ok--&gt;LongR
SyncNodeTemplates--Err--&gt;ShortR
DelFlow--&gt;EnqM
NewCreateReq--&gt;CreateFlow
CreateFlow--&gt;EnqM

</pre>
<h2 id="controllertriggercreationflow"><a class="header" href="#controllertriggercreationflow">controller.triggerCreationFlow</a></h2>
<p><a href="https://github.com/gardener/machine-controller-manager/blob/v0.47.0/pkg/util/provider/machinecontroller/machine.go#L326">Controller Method</a> that orchestraes the call to the <a href="machine-controller/../mcm_facilities.html#driver">Driver.CreateMachine</a></p>
<p>This method badly requires to be split into several functions. It is too long. </p>
<pre><code class="language-go">func (c *controller) triggerCreationFlow(ctx context.Context, 
cmr *driver.CreateMachineRequest) 
  (machineutils.RetryPeriod, error) 
</code></pre>
<p>Apologies for HUMONGOUS flow diagram - all this is in one method - will split into several sections later for clarity!</p>
<pre class="mermaid">%%{init: {'themeVariables': { 'fontSize': '10px'}, &quot;flowchart&quot;: {&quot;useMaxWidth&quot;: false }}}%%
flowchart TD

ShortP[&quot;retryPeriod=machineutils.ShortRetry&quot;]
MediumP[&quot;retryPeriod=machineutils.MediumRetry&quot;]
Return((&quot;return retryPeriod, err&quot;))


Begin((&quot; &quot;))--&gt;Init[&quot;
  machine     = cmr.Machine
	machineName = cmr.Machine.Name
  secretCopy := cmr.Secret.DeepCopy() //NOTE: seems Un-necessary?
&quot;]
--&gt;AddBootStrapToken[&quot;
 err = c.addBootstrapTokenToUserData(ctx, machine.Name, secretCopy)
//  get/create bootstrap token and populate inside secretCopy['userData']
&quot;]
--&gt;ChkErr{err != nil?}

ChkErr--Yes--&gt;ShortP--&gt;Return

ChkErr--No--&gt;CreateMachineStatusReq[&quot;
  statusReq = &amp; driver.GetMachineStatusRequest{
			Machine:      machine,
			MachineClass: cmr.MachineClass,
			Secret:       cmr.Secret,
		},
&quot;]--&gt;GetMachineStatus[&quot;
  statusResp, err := c.driver.GetMachineStatus(ctx, statusReq)
  //check if VM already exists
&quot;]--&gt;ChkStatusErr{err!=nil}

ChkStatusErr--No--&gt;InitNodeNameFromStatusResp[&quot;
   nodeName = statusResp.NodeName
  providerID = statusResp.ProviderID
&quot;]

ChkStatusErr--Yes--&gt;DecodeErrorStatus[&quot;
  errStatus,decodeOk= status.FromError(err)
&quot;]
DecodeErrorStatus--&gt;CheckDecodeOk{&quot;decodeOk ?&quot;}

CheckDecodeOk--No--&gt;MediumP--&gt;Return
CheckDecodeOk--Yes--&gt;AnalyzeCode{status.Code?}


AnalyzeCode--NotFound,Unimplemented--&gt;ChkNodeLabel{&quot;machine.Labels['node']?&quot;}

ChkNodeLabel--No--&gt;CreateMachine[&quot;
// node label is not present -&gt; no machine
 resp, err := c.driver.CreateMachine(ctx, cmr)
&quot;]--&gt;ChkCreateError{err!=nil?}

ChkNodeLabel--Yes--&gt;InitNodeNameFromMachine[&quot;
  nodeName = machine.Labels['node']
&quot;]


AnalyzeCode--Unknown,DeadlineExceeded,Aborted,Unavailable--&gt;ShortRetry[&quot;
retryPeriod=machineutils.ShortRetry
&quot;]--&gt;GetLastKnownState[&quot;
  lastKnownState := machine.Status.LastKnownState
&quot;]--&gt;InitFailedOp[&quot;
 lastOp := LastOperation{
    Description: err.Error(),
    State: MachineStateFailed,
    Type: MachineOperationCreatea,
    LastUpdateTime: Now(),
 };
 currStatus := CurrentStatus {
    Phase: MachineCrashLoopBackOff || MachineFailed (on create timeout)
    LastUpdateTime: Now()
 }
&quot;]--&gt;UpdateMachineStatus[&quot;
c.machineStatusUpdate(ctx,machine,lastOp,currStatus,lastKnownState)
&quot;]--&gt;Return


ChkCreateError--Yes--&gt;SetLastKnownState[&quot;
  	lastKnownState = resp.LastKnownState
&quot;]--&gt;InitFailedOp

ChkCreateError--No--&gt;InitNodeNameFromCreateResponse[&quot;
  nodeName = resp.NodeName
  providerID = resp.ProviderID
&quot;]--&gt;ChkStaleNode{&quot;
// check stale node
nodeName != machineName 
&amp;&amp; nodeLister.Get(nodeName) exists&quot;}


InitNodeNameFromStatusResp--&gt;ChkNodeLabelAnnotPresent{&quot;
cmr.Machine.Labels['node']
&amp;&amp; cmr.Machine.Annotations[MachinePriority] ?
&quot;}
InitNodeNameFromMachine--&gt;ChkNodeLabelAnnotPresent

ChkNodeLabelAnnotPresent--No--&gt;CloneMachine[&quot;
  clone := machine.DeepCopy;
  clone.Labels['node'] = nodeName
  clone.Annotations[machineutils.MachinePriority] = '3'
  clone.Spec.ProviderID = providerID
&quot;]--&gt;UpdateMachine[&quot;
  _, err := c.controlMachineClient.Machines(clone.Namespace).Update(ctx, clone, UpdateOptions{})
&quot;]--&gt;ShortP




ChkStaleNode--No--&gt;CloneMachine
ChkStaleNode--Yes--&gt;CreateDMR[&quot;
  dmr := &amp;driver.DeleteMachineRequest{
						Machine: &amp;Machine{
							ObjectMeta: machine.ObjectMeta,
							Spec: MachineSpec{
								ProviderID: providerID,
							},
						},
						MachineClass: createMachineRequest.MachineClass,
						Secret:       secretCopy,
					}
&quot;]--&gt;DeleteMachine[&quot;
  _, err := c.driver.DeleteMachine(ctx, deleteMachineRequest)
  // discuss stale node case
&quot;]--&gt;ShortRetry[&quot;retryPeriod=machineutils.ShortRetry&quot;]

ChkNodeLabelAnnotPresent--Yes--&gt;ChkMachineStatus{&quot;machine.Status.Node != nodeName
  || machine.Status.CurrentStatus.Phase == ''&quot;}

ChkMachineStatus--No--&gt;LongP[&quot;retryPeriod = machineutils.LongRetry&quot;]--&gt;Return

ChkMachineStatus--Yes--&gt;CloneMachine1[&quot;
  clone := machine.DeepCopy()
  clone.Status.Node = nodeName
&quot;]--&gt;SetLastOp[&quot;
 lastOp := LastOperation{
    Description: 'Creating Machine on Provider',
    State: MachineStateProcessing,
    Type: MachineOperationCreate,
    LastUpdateTime: Now(),
 };
 currStatus := CurrentStatus {
    Phase: MachinePending,
    TimeoutActive:  true,
    LastUpdateTime: Now()
 }
 lastKnownState = clone.Status.LastKnownState
&quot;]--&gt;UpdateMachineStatus

style InitFailedOp text-align:left

</pre>
<h3 id="controlleraddbootstraptokentouserdata"><a class="header" href="#controlleraddbootstraptokentouserdata">controller.addBootstrapTokenToUserData</a></h3>
<p>This method is responsible for adding the bootstrap token for the machine. Bootstrap tokens are used when joining new nodes to a cluster. Bootstrap Tokens are defined with a specific <code>SecretType</code>: <code>bootstrap.kubernetes.io/token</code> and live in the <code>kube-system</code> namespace. These Secrets are then read by the Bootstrap Authenticator in the API Server</p>
<p>Reference</p>
<ul>
<li><a href="https://kubernetes.io/docs/reference/access-authn-authz/bootstrap-tokens/">Bootstrap Tokens</a></li>
<li><a href="https://github.com/kubernetes/design-proposals-archive/blob/main/cluster-lifecycle/bootstrap-discovery.md#new-bootstrap-token-secrets">Bootstrap Token Secrets</a></li>
<li><a href="https://github.com/kubernetes/design-proposals-archive/blob/main/cluster-lifecycle/bootstrap-discovery.md#new-bootstrap-token-structure">Bootstrap Token Structure</a></li>
</ul>
<pre><code class="language-go">func (c *controller) addBootstrapTokenToUserData(ctx context.Context, machineName string, secret *corev1.Secret) error 

</code></pre>
<pre class="mermaid">%%{init: {'themeVariables': { 'fontSize': '10px'}, &quot;flowchart&quot;: {&quot;useMaxWidth&quot;: false }}}%%
flowchart TD

Begin((&quot; &quot;))
--&gt;InitTokenSecret[&quot;
tokenID := hex.EncodeToString([]byte(machineName)[len(machineName)-5:])[:6]
// 6 chars length
secretName :='bootstrap-token-' + tokenID
&quot;]
--&gt;GetSecret[&quot;
	secret, err = c.targetCoreClient.CoreV1().Secrets('kube-system').Get(ctx, secretName, GetOptions{}) 
&quot;]
--&gt;ChkErr{err!=nil?}

ChkErr--Yes--&gt;ChkNotFound{&quot;IsNotFound(err)&quot;}

ChkNotFound--Yes--&gt;GenToken[&quot;
  tokenSecretKey = generateRandomStrOf16Chars
&quot;]--&gt;InitSecretData[&quot;
  data := map[string][]byte{
    'token-id': []byte(tokenID),
    'token-secret': []byte(tokenSecretKey),
    'expiration': []byte(c.safetyOptions.MachineCreationTimeout.Duration)
    //..others
 }
&quot;]
--&gt;InitSecret[&quot;
  	secret = &amp;corev1.Secret{
				ObjectMeta: metav1.ObjectMeta{
					Name:      secretName,
					Namespace: metav1.NamespaceSystem,
				},
				Type: 'bootstrap.kubernetes.io/token'
				Data: data,
			}
&quot;]
--&gt;CreateSecret[&quot;
secret, err =c.targetCoreClient.CoreV1().Secrets('kube-system').Create(ctx, secret, CreateOptions{})
&quot;]
--&gt;ChkErr1{err!=nil?}

ChkErr1--Yes--&gt;ReturnErr((&quot;return err&quot;))
ChkNotFound--No--&gt;ReturnErr

ChkErr1--No--&gt;CreateToken[&quot;
token = tokenID + '.' + tokenSecretKey
&quot;]--&gt;InitUserData[&quot;
  userDataByes = secret.Data['userData']
  userDataStr = string(userDataBytes)
&quot;]--&gt;ReplaceUserData[&quot;
  	userDataS = strings.ReplaceAll(userDataS, 'BOOTSTRAP_TOKEN',placeholder, token)
   	secret.Data['userData'] = []byte(userDataS)
    //discuss this.
&quot;]--&gt;ReturnNil((&quot;return nil&quot;))

style InitSecretData text-align:left
style InitSecret text-align:left
</pre>
<h2 id="controllertriggerdeletionflow"><a class="header" href="#controllertriggerdeletionflow">controller.triggerDeletionFlow</a></h2>
<pre><code class="language-go">func (c *controller) triggerDeletionFlow(ctx context.Context, dmr *driver.DeleteMachineRequest) (machineutils.RetryPeriod, error) 

</code></pre>
<p>Please note that there is sad use of <code>machine.Status.LastOperation</code>  as semantically the <em>next</em> requested operation. This is confusing. TODO: DIscuss This.</p>
<pre class="mermaid">%%{init: {'themeVariables': { 'fontSize': '10px'}, &quot;flowchart&quot;: {&quot;useMaxWidth&quot;: false }}}%%
flowchart TD

GM[&quot;machine=dmr.Machine\n
machineClass=dmr.MachineClass\n
secret=dmr.Secret&quot;]
HasFin{&quot;HasFinalizer(machine)&quot;}
LongR[&quot;retryPeriod=machineUtils.LongRetry&quot;]
ShortR[&quot;retryPeriod=machineUtils.ShortRetry&quot;]
ChkMachineTerm{&quot;machine.Status.CurrentStatus.Phase\n==MachineTerminating ?&quot;}
CheckMachineOperation{&quot;Check\nmachine.Status.LastOperation.Description&quot;}
DrainNode[&quot;retryPeriod=c.drainNode(dmr)&quot;]
DeleteVM[&quot;retryPeriod=c.deleteVM(dmr)&quot;]
DeleteNode[&quot;retryPeriod=c.deleteNodeObject(dmr)&quot;]
DeleteMachineFin[&quot;retryPeriod=c.deleteMachineFinalizers(machine)\n(dead code?)&quot;]
SetMachineTermStatus[&quot;c.setMachineTerminationStatus(dmr)&quot;]

CreateMachineStatusRequest[&quot;statusReq=&amp;driver.GetMachineStatusRequest{machine, machineClass,secret}&quot;]
GetVMStatus[&quot;retryPeriod=c.getVMStatus(statusReq)&quot;]



Z((&quot;End&quot;))

Begin((&quot; &quot;))--&gt;HasFin
HasFin--Yes--&gt;GM
HasFin--No--&gt;LongR
LongR--&gt;Z
GM--&gt;ChkMachineTerm
ChkMachineTerm--No--&gt;SetMachineTermStatus
ChkMachineTerm--Yes--&gt;CheckMachineOperation
SetMachineTermStatus--&gt;ShortR
CheckMachineOperation--GetVMStatus--&gt;CreateMachineStatusRequest
CheckMachineOperation--InitiateDrain--&gt;DrainNode
CheckMachineOperation--InitiateVMDeletion--&gt;DeleteVM
CheckMachineOperation--InitiateNodeDeletion--&gt;DeleteNode
CheckMachineOperation--InitiateFinalizerRemoval--&gt;DeleteMachineFin
CreateMachineStatusRequest--&gt;GetVMStatus
GetVMStatus--&gt;Z


DrainNode--&gt;Z
DeleteVM--&gt;Z
DeleteNode--&gt;Z
DeleteMachineFin--&gt;Z
ShortR--&gt;Z

</pre>
<h3 id="controllergetvmstatus"><a class="header" href="#controllergetvmstatus">controller.getVMStatus</a></h3>
<p>(BAD NAME FOR METHOD: should be called <code>checkMachineExistenceAndEnqueNextOperation</code>)</p>
<pre><code class="language-go">func (c *controller) getVMStatus(ctx context.Context, 
    statusReq *driver.GetMachineStatusRequest) (machineutils.RetryPeriod, error)
</code></pre>
<p>This method is only called for the delete flow. </p>
<ol>
<li>It attempts to get the machine status</li>
<li>If the machine exists, it updates the machine status operation to <code>InitiateDrain</code> and returns a <code>ShortRetry</code> for the machine work queue. </li>
<li>If attempt to get machine status failed, it will obtain the error code from the error.
<ol>
<li>If decoding the error code failed, it will update the  machine status operation to <code>machineutils.GetVMStatus</code>returns a <code>LongRetry</code> for the machine work queue. 
<ol>
<li>Unsure how we get out of this Loop. TODO: Discuss this. Is this dead code?</li>
</ol>
</li>
<li>For <code>Unknown|DeadlineExceeded|Aborted|Unavailable</code> it updates the machine status operation to <code>machineutils.GetVMStatus</code> status and returns a <code>ShortRetry</code> for the machine work queue.  (So that reconcile will run this method again in future)</li>
<li>For <code>NotFound</code> code (ie machine is not found), it will enqueue node deletion by updating the machine stauts operation to <code>machineutils.InitiateNodeDeletion</code> and returning a <code>ShortRetry</code> for the machine work queue.</li>
</ol>
</li>
</ol>
<pre class="mermaid">%%{init: {'themeVariables': { 'fontSize': '10px'}, &quot;flowchart&quot;: {&quot;useMaxWidth&quot;: false }}}%%
flowchart TD

GetMachineStatus[&quot;_,err=driver.GetMachineStatus(statusReq)&quot;]
ChkMachineExists{&quot;err==nil ?\n (ie machine exists)&quot;}
DecodeErrorStatus[&quot;errStatus,decodeOk= status.FromError(err)&quot;]
CheckDecodeOk{&quot;decodeOk ?&quot;}

CheckErrStatusCode{&quot;Check errStatus.Code&quot;}

CreateDrainOp[&quot;op:=LastOperation{Description: machineutils.InitiateDrain
State: v1alpha1.MachineStateProcessing,
Type: v1alpha1.MachineOperationDelete,
Time: time.Now()}&quot;]

CreateNodeDelOp[&quot;op:=LastOperation{Description: machineutils.InitiateNodeDeletion
State: v1alpha1.MachineStateProcessing,
Type: v1alpha1.MachineOperationDelete,
Time: time.Now()}&quot;]

CreateDecodeFailedOp[&quot;op:=LastOperation{Description: machineutils.GetVMStatus,
State: v1alpha1.MachineStateFailed,
Type: v1alpha1.MachineOperationDelete,
Time: time.Now()}&quot;]

CreaterRetryVMStatusOp[&quot;op:=LastOperation{Description: machineutils.GetVMStatus,
State: v1alpha1.MachineStateFailed,
Type:  v1alpha1.MachineOperationDelete,
Time: time.Now()}&quot;]

ShortR[&quot;retryPeriod=machineUtils.ShortRetry&quot;]
LongR[&quot;retryPeriod=machineUtils.LongRetry&quot;]
MachineStatusUpdate[&quot;c.machineStatusUpdate(machine,op,machine.Status.CurrentStatus, machine.Status.LastKnownState)&quot;]

Z((&quot;End&quot;))

GetMachineStatus--&gt;ChkMachineExists

ChkMachineExists--Yes--&gt;CreateDrainOp
ChkMachineExists--No--&gt;DecodeErrorStatus
DecodeErrorStatus--&gt;CheckDecodeOk
CheckDecodeOk--Yes--&gt;CheckErrStatusCode
CheckDecodeOk--No--&gt;CreateDecodeFailedOp
CreateDecodeFailedOp--&gt;LongR
CheckErrStatusCode--&quot;Unimplemented&quot;--&gt;CreateDrainOp
CheckErrStatusCode--&quot;Unknown|DeadlineExceeded|Aborted|Unavailable&quot;--&gt;CreaterRetryVMStatusOp
CheckErrStatusCode--&quot;NotFound&quot;--&gt;CreateNodeDelOp
CreaterRetryVMStatusOp--&gt;ShortR

CreateDrainOp--&gt;ShortR
CreateNodeDelOp--&gt;ShortR
ShortR--&gt;UpdateMachineStatus
LongR--&gt;UpdateMachineStatus
UpdateMachineStatus--&gt;Z
</pre>
<h3 id="controllerdrainnode"><a class="header" href="#controllerdrainnode">controller.drainNode</a></h3>
<p>Inside <code>pkg/util/provider/machinecontroller/machine_util.go</code></p>
<pre><code class="language-go">func (c *controller) drainNode(ctx context.Context, dmr *driver.DeleteMachineRequest) (machineutils.RetryPeriod, error)
</code></pre>
<pre class="mermaid">
%%{init: {'themeVariables': { 'fontSize': '10px'}, &quot;flowchart&quot;: {&quot;useMaxWidth&quot;: false }}}%%
flowchart TD


Initialize[&quot;err = nil
machine = dmr.Machine
nodeName= machine.Labels['node']
drainTimeout=machine.Spec.MachineConfiguration.MachineDrainTimeout || c.safetyOptions.MachineDrainTimeout
maxEvictRetries=machine.Spec.MachineConfiguration.MaxEvictRetries || c.safetyOptions.MaxEvictRetries
skipDrain = false&quot;]
--&gt;GetNodeReadyCond[&quot;nodeReadyCond = machine.Status.Conditions contains k8s.io/api/core/v1/NodeReady
readOnlyFSCond=machine.Status.Conditions contains 'ReadonlyFilesystem' 
&quot;]
--&gt;ChkNodeNotReady[&quot;skipDrain = (nodeReadyCond.Status == ConditionFalse) &amp;&amp; nodeReadyCondition.LastTransitionTime.Time &gt; 5m
or (readOnlyFSCond.Status == ConditionTrue) &amp;&amp; readOnlyFSCond.LastTransitionTime.Time &gt; 5m
// discuss this
&quot;]
--&gt;ChkSkipDrain{&quot;skipDrain true?&quot;}
ChkSkipDrain--Yes--&gt;SetOpStateProcessing
ChkSkipDrain--No--&gt;SetHasDrainTimedOut[&quot;hasDrainTimedOut = time.Now() &gt; machine.DeletionTimestamp + drainTimeout&quot;]
SetHasDrainTimedOut--&gt;ChkForceDelOrTimedOut{&quot;machine.Labels['force-deletion']
  || hasDrainTimedOut&quot;}

ChkForceDelOrTimedOut--Yes--&gt;SetForceDelParams[&quot;
  forceDeletePods=true
  drainTimeout=1m
  maxEvictRetries=1
  &quot;]
SetForceDelParams--No--&gt;UpdateNodeTermCond[&quot;err=c.UpdateNodeTerminationCondition(ctx, machine)&quot;]
ChkForceDelOrTimedOut--No--&gt;UpdateNodeTermCond

UpdateNodeTermCond--&gt;ChkUpdateErr{&quot;err != nil ?&quot;}
ChkUpdateErr--No--&gt;InitDrainOpts[&quot;
  // params reduced for brevity
  drainOptions := drain.NewDrainOptions(
    c.targetCoreClient,
    drainTimeout,
    maxEvictRetries,
    c.safetyOptions.PvDetachTimeout.Duration,
    c.safetyOptions.PvReattachTimeout.Duration,
    nodeName,
    forceDeletePods,
    c.driver,
		c.pvcLister,
		c.pvLister,
    c.pdbV1Lister,
		c.nodeLister,
		c.volumeAttachmentHandler)
&quot;]
ChkUpdateErr--&quot;Yes&amp;&amp;forceDelPods&quot;--&gt;InitDrainOpts
ChkUpdateErr--Yes--&gt;SetOpStateFailed[&quot;opstate = v1alpha1.MachineStateFailed
  description=machineutils.InitiateDrain
  //drain failed. retry next sync
  &quot;]

InitDrainOpts--&gt;RunDrain[&quot;err = drainOptions.RunDrain(ctx)&quot;]
RunDrain--&gt;ChkDrainErr{&quot;err!=nil?&quot;}
ChkDrainErr--No--&gt;SetOpStateProcessing[&quot;
  opstate= v1alpha1.MachineStateProcessing
  description=machineutils.InitiateVMDeletion
// proceed with vm deletion&quot;]
ChkDrainErr--&quot;Yes &amp;&amp; forceDeletePods&quot;--&gt;SetOpStateProcessing
ChkDrainErr--Yes--&gt;SetOpStateFailed
SetOpStateProcessing--&gt;
InitLastOp[&quot;lastOp:=v1alpha1.LastOperation{
			Description:    description,
			State:          state,
			Type:           v1alpha1.MachineOperationDelete,
			LastUpdateTime: metav1.Now(),
		}
  //lastOp is actually the *next* op semantically&quot;]
SetOpStateFailed--&gt;InitLastOp
InitLastOp--&gt;UpdateMachineStatus[&quot;c.machineStatusUpdate(ctx,machine,lastOp,machine.Status.CurrentStatus,machine.Status.LastKnownState)&quot;]
--&gt;Return((&quot;machineutils.ShortRetry, err&quot;))
</pre>
<p>Note on above</p>
<ol>
<li>We skip the drain if node is set to ReadonlyFilesystem for over 5 minutes
<ol>
<li>Check TODO:  <code>ReadonlyFilesystem</code> is a MCM condition and not a k8s core node condition. Not sure if we are mis-using this field. TODO: Check this.</li>
</ol>
</li>
<li>Check TODO: Why do we check that node is not ready for 5m in order to skip the drain ? Shouldn't we skip the drain if node is simply not ready ? Why wait for 5m here ?/</li>
<li>See <a href="machine-controller/./node_drain.html#run-drain">Run Drain</a></li>
</ol>
<h2 id="controllerreconcilemachinehealth"><a class="header" href="#controllerreconcilemachinehealth">controller.reconcileMachineHealth</a></h2>
<p><a href="https://github.com/gardener/machine-controller-manager/blob/v0.47.0/pkg/util/provider/machinecontroller/machine_util.go#L584">controller.reconcileMachineHealth</a> reconciles the machine object with any change in node conditions or VM health.</p>
<pre><code class="language-go">func (c *controller) reconcileMachineHealth(ctx context.Context, machine *Machine) 
  (machineutils.RetryPeriod, error)
</code></pre>
<p>NOTES:</p>
<ol>
<li>Reference <a href="machine-controller/./mc_helper_methods.html#controllerishealthy">controller.isHealth</a> which checks the machine status conditions.</li>
</ol>
<h3 id="health-check-flow-diagram"><a class="header" href="#health-check-flow-diagram">Health Check FLow Diagram</a></h3>
<pre class="mermaid">
%%{init: {'themeVariables': { 'fontSize': '10px'}, &quot;flowchart&quot;: {&quot;useMaxWidth&quot;: false }}}%%
flowchart TD

ShortR((&quot;return machineutils.ShortRetry, err&quot;))
Begin((&quot; &quot;))--&gt;Init[&quot;
cloneDirty = false
machineClone = machine.DeepCopy()
&quot;]--&gt;GetNode[&quot;
  node, err := c.nodeLister.Get(machine.Status.Node)
&quot;]--&gt;CheckErr{err!-nil}

CheckErr--Yes--&gt;
  ChkIsNotFound{&quot;IsNotFound(err)&quot;}
    --Yes--&gt;ChkMachinePhase{&quot;
    len(machine.Status.Conditions) &gt; 0
    &amp;&amp;
  machine.Status.CurrentStatus.Phase == MachineRunning
&quot;} --&quot;Yes\n(node missing)&quot;
  --&gt;SetUnhealthyNotFound[&quot;
    lastOpDesc='machine unhealthy due to node obj missing'
    lastOpState=MachineStateProcessing
    machinePhase: MachineUnknown
    cloneDirty=true
    &quot;]
  --&gt;TODO

ChkIsNotFound--No--&gt;ShortR
ChkMachinePhase--No--&gt;TODO


CheckErr--No--&gt;CheckNodeConditions{&quot;nodeConditionsHaveChanged(
  machine.Status.Conditions, 
  node.Status.Conditions) ? &quot;}

CheckNodeConditions--Yes--&gt;SetChangedConditions[&quot;
   machineClone.Status.Conditions = node.Status.Conditions
   cloneDirty = true
&quot;]--&gt;ChkNotHealthyButRunning
CheckNodeConditions--No--&gt;ChkNotHealthyButRunning


ChkNotHealthyButRunning{&quot;!c.isHealth(machine)
&amp;&amp;
machine.Status.CurrentStatus.Phase == MachineRunning
// machine not healthy, and current state running,&quot;}
--Yes--&gt;SetUnhealtyDesc[&quot;
  lastOpDesc ='Machine Unealthy due to conditions:' + machine.Status.Condtions
  lastOpState=MachineStateProcessing
  machinePhase: MachineUnknown
  cloneDirty=true&quot;]
--&gt;ChkHealthyButNotRunning{&quot;!c.isHealthy(clone)
  &amp;&amp; 
  clone.Status.CurrentStatus.Phase == MachineRunning
  //machine healthy, but curr phase not running
  &quot;}
  --&gt;ChkMachineCreateOk{&quot;
    machine.Status.LastOperation.Type == MachineOperationCreate 
    &amp;&amp;
		machine.Status.LastOperation.State != MachineStateSuccessful 
  &quot;}
  --&gt;ChkLastOpCreateAndOpStateNotMarkedSuccess{&quot;
   machine.Status.LastOperation.Type == MachineOperationCreate 
   &amp;&amp;
	 machine.Status.LastOperation.State != MachineStateSuccessful 
   //create ok but not marked yet as success
  &quot;}
  --Yes--&gt;SetSuccessDesc[&quot;
    lastOpDes = 'Machine successfully joined the cluster'
		lastOpType = MachineOperationCreate
  &quot;]--&gt;DeleteBootstrapToken[&quot;
    c.deleteBootstrapToken(ctx, Machine.Name)
    // delete bootstrap token created at machine launch
  &quot;]--&gt;SetLastOpStateSuccessAndPhaseRuning[&quot;
    lastOpState = MachineStateSuccessful,
    machinePhase: MachineRunning
    cloneDirty=true
  &quot;]

  ChkLastOpCreateAndOpStateNotMarkedSuccess--No--&gt;SetMachineRejoinCluster[&quot;
    lastOpDes = 'Machine successfully re-joined the cluster'
		lastOpType = MachineOperationHealthCheck
  &quot;]--&gt;SetLastOpStateSuccessAndPhaseRuning


  SetLastOpStateSuccessAndPhaseRuning--&gt;TODO


style SetUnknown text-align:left

</pre>
<h3 id="health-check-summary"><a class="header" href="#health-check-summary">Health Check Summary</a></h3>
<ol>
<li>Gets the <code>Node</code> obj associated with the machine. If it IS NOT found, yet the current machine phase is <code>Running</code>, change the machine phase to <code>Unknown</code>, the last operation state to <code>Processing</code>, the last operation type to <code>HealthCheck</code>, update the machine status and return with a short retry.</li>
<li>If the <code>Node</code> object IS found, then it checks whether the <code>Machine.Status.Conditions</code> are different from <code>Node.Status.Conditions</code>. If so it sets the machine conditions to the node conditions.</li>
<li>If the machine IS NOT healthy (See <a href="machine-controller/./mc_helper_methods.html#controllerishealthy">isHealthy</a>) but the current machine phase is <code>Running</code>, change the machine phase to <code>Unknown</code>, the last operation state to <code>Processing</code>, the last operation type to <code>HealthCheck</code>, update the machine status and return with a short retry.</li>
<li>If the machine IS healthy but the current machine phase is NOT <code>Running</code>,  check whether the last operation type was a <code>Create</code>.
<ol>
<li>If the last operation type was a <code>Create</code> and last operation state is not marked as <code>Successful</code>, then delete the bootstrap token associated with the machine. Change the last operation state to <code>Successful</code>.</li>
<li>If the last operation type was NOT a <code>Create</code>, change the last operation type to <code>HealthCheck</code></li>
<li>Change the machine phase to <code>Running</code> and update the machine status and return with a short retry.</li>
</ol>
</li>
<li>If the current machine phase is <code>Pending</code> (ie machine being created) get the configured machine creation timeout and check.
<ol>
<li>If the timoeut HAS NOT expired, enqueue the machine key on the machine work queue after 1m. </li>
<li>If the timeout HAS expired, then change the last operation state to <code>Failed</code> and the machine phase to <code>Failed</code>. Update the machine status and return with a short retry.</li>
</ol>
</li>
<li>If the current machine phase is <code>Unknown</code>, get the effective machine health timeout and check. 
<ol>
<li>If the timoeut HAS NOT expired, enqueue the machine key on the machine work queue after 1m. </li>
<li>If the timoeut HAS expired 
<ol>
<li>Get the machine deployment name <code>machine.Labels['name']</code></li>
<li>Register ONE permit with this name. See <a href="machine-controller/../mcm_facilities.html#permitspermitgiver">Permit Giver</a></li>
</ol>
</li>
</ol>
</li>
</ol>
<pre><code>    machineClone.Status.CurrentStatus = CurrentStatus {
      Phase: MachineUnknown,
      LastUpdateTime: Now(),
    };
    machineClone.Status.LastOperation = LastOperation{
        Description:    statusDesc,
        State:          MachineStateProcessing,
        Type:           MachineOperationHealthCheck,
        LastUpdateTime: Now(),
    }
    cloneDirty = true
</code></pre>
<h3 id="health-check-doubts"><a class="header" href="#health-check-doubts">Health Check Doubts</a></h3>
<ol>
<li>TODO: Why don't we check the machine health using the <code>Driver.GetMachineStatus</code> in the reconcile Machine health ? (seems like something obvious to do and would have helped in those meltdown issues where machine was incorrectly marked as failed)</li>
<li>TODO: Why do we do <code>len(machine.Status.Condtions)==0</code> in the below when ?</li>
<li>TODO: why doesn't this code make use of the helper method: <code>c.machineStatusUpdate</code> ?</li>
<li>TODO: Unclear why <code>LastOperation.Description</code> does not use/concatenate one of the predefined constants in <code>machineutils</code></li>
<li>TODO: code makes too much use of <code>cloneDirty</code> to check whether machine clone obj has changed, when it could easily return early in several branches.</li>
<li>TODO: Code directly makes calls to enqueue machine keys on the machine queue and still returns retry periods to caller leanding to un-necessary enqueue of machine keys. (spurious design)</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><ul>
<li><a href="machine-controller/mc_helper_methods.html#machine-controller-helper-methods">Machine Controller Helper Methods</a>
<ul>
<li><a href="machine-controller/mc_helper_methods.html#controllervalidatemachineclass">controller.ValidateMachineClass</a></li>
<li><a href="machine-controller/mc_helper_methods.html#controlleraddmachinefinalizers">controller.addMachineFinalizers</a></li>
<li><a href="machine-controller/mc_helper_methods.html#controllersetmachineterminationstatus">controller.setMachineTerminationStatus</a></li>
<li><a href="machine-controller/mc_helper_methods.html#controllermachinestatusupdate">controller.machineStatusUpdate</a></li>
<li><a href="machine-controller/mc_helper_methods.html#controllerupdatenodeterminationcondition">controller.UpdateNodeTerminationCondition</a></li>
<li><a href="machine-controller/mc_helper_methods.html#controllerishealthy">controller.isHealthy</a></li>
</ul>
</li>
</ul>
<h1 id="machine-controller-helper-methods"><a class="header" href="#machine-controller-helper-methods">Machine Controller Helper Methods</a></h1>
<h2 id="controllervalidatemachineclass"><a class="header" href="#controllervalidatemachineclass">controller.ValidateMachineClass</a></h2>
<pre><code class="language-go">func (c *controller) ValidateMachineClass(ctx context.Context, classSpec *v1alpha1.ClassSpec) (*v1alpha1.MachineClass, map[string][]byte, machineutils.RetryPeriod, error) 
</code></pre>
<ul>
<li>Checks whether <code>MachineClass.Spec.Kind</code> is <code>MachineClass</code>. If not, thijs implies an deprecated, in-tree provider-specific machine class. Performs migration to the modern machine class object, creates the new machine class object and updates class references. (Details not covered here)</li>
<li>Confirms the presence of the machine class using <a href="https://pkg.go.dev/github.com/gardener/machine-controller-manager@v0.47.0/pkg/client/listers/machine/v1alpha1#MachineClassLister">MachineClassLister</a> through <code>c.machineClassLister.MachineClasses(c.namespace).Get(classSpec.Name)</code></li>
<li>Gets the <a href="https://pkg.go.dev/github.com/gardener/machine-controller-manager@v0.47.0/pkg/apis/machine/v1alpha1#MachineClass">MachineClass</a> <code>SecretRef</code> and <code>CredentialsSecretRef</code>- which are both <a href="https://pkg.go.dev/k8s.io/api/core/v1#SecretReference">k8s.io/api/core/v1.SecretReference</a>'s.</li>
<li>Retrives the k8s secrets using the secret lister using the secret references and checks that there are no errors in doing so.</li>
<li>Validates the node templates for the machine class. (TODO: more on this later)</li>
<li>Checks that the <code>MCMFinalizerName</code> constant <code>machine.sapcloud.io/machine-controller-manager</code> is present in <code>MachineClass.Finalizers</code>. if not, adds the macine class name to the machine class queue using <code>c.machineClassQueue.Add(machineClass.Name)</code>.</li>
<li>If validation fails in any of the above steps, returns <code>machineutils.ShortRetry</code> else returns <code>machineutils.LongRetry</code></li>
</ul>
<h2 id="controlleraddmachinefinalizers"><a class="header" href="#controlleraddmachinefinalizers">controller.addMachineFinalizers</a></h2>
<p>This method checks for the <code>MCMFinalizer</code> Value: <code>machine.sapcloud.io/machine-controller-manager</code> and adds it if it is not present. It leverages <code>k8s.io/apimachinery/pkg/util/sets</code> package for its work.</p>
<p>This method is regularly called during machine reconciliation, if a machine does not have a deletion timestamp so that all non-deleted machines possess this finalizer.</p>
<pre><code class="language-go">func (c *controller) addMachineFinalizers(ctx context.Context, machine *v1alpha1.Machine) (machineutils.RetryPeriod, error)
	if finalizers := sets.NewString(machine.Finalizers...); !finalizers.Has(MCMFinalizerName) {
		finalizers.Insert(MCMFinalizerName)
		clone := machine.DeepCopy()
		clone.Finalizers = finalizers.List()
		_, err := c.controlMachineClient.Machines(clone.Namespace).Update(ctx, clone, metav1.UpdateOptions{})
		if err != nil {
			// Keep retrying until update goes through
			klog.Errorf(&quot;Failed to add finalizers for machine %q: %s&quot;, machine.Name, err)
		} else {
			// Return error even when machine object is updated
			klog.V(2).Infof(&quot;Added finalizer to machine %q with providerID %q and backing node %q&quot;, machine.Name, getProviderID(machine), getNodeName(machine))
			err = fmt.Errorf(&quot;Machine creation in process. Machine finalizers are UPDATED&quot;)
		}
	}
	return machineutils.ShortRetry, err

</code></pre>
<h2 id="controllersetmachineterminationstatus"><a class="header" href="#controllersetmachineterminationstatus">controller.setMachineTerminationStatus</a></h2>
<p><code>setMachineTerminationStatus</code> set's the machine status to terminating. This is illustrated below. Please note that <code>Machine.Status.LastOperation</code> is set an instance of the <code>LastOperation</code> struct. (This appears a bit misleading as this can be interpreted as sometimes the Next Operation carried in the next pickup by the reconciler func?: Discuss this)</p>
<pre><code class="language-go">func (c *controller) setMachineTerminationStatus(ctx context.Context, dmr *driver.DeleteMachineRequest) (machineutils.RetryPeriod, error)  
</code></pre>
<pre class="mermaid">%%{init: {'themeVariables': { 'fontSize': '10px'}, &quot;flowchart&quot;: {&quot;useMaxWidth&quot;: false }}}%%
flowchart TD

CreateClone[&quot;clone := dmr.Machine.DeepCopy()&quot;]
NewCurrStatus[&quot;currStatus := &amp;v1alpha1.CurrentStatus{Phase:\n MachineTerminating, LastUpdateTime: time.Now()}&quot;]
SetCurrentStatus[&quot;clone.Status.CurrentStatus = currStatus&quot;]
UpdateStatus[&quot;c.controlMachineClient.Machines(ns).UpdateStatus(clone)&quot;]
ShortR[&quot;retryPeriod=machineUtils.ShortRetry&quot;]
Z((&quot;Return&quot;))

CreateClone--&gt;NewCurrStatus
NewCurrStatus--&gt;SetCurrentStatus
SetCurrentStatus--&gt;UpdateStatus
UpdateStatus--&gt;ShortR
ShortR--&gt;Z
</pre>
<h2 id="controllermachinestatusupdate"><a class="header" href="#controllermachinestatusupdate">controller.machineStatusUpdate</a></h2>
<p>Updates <code>machine.Status.LastOperation</code>, <code>machine.Status.CurrentStatus</code> and <code>machine.Status.LastKnownState</code></p>
<pre><code class="language-go">func (c *controller) machineStatusUpdate(
	ctx context.Context,
	machine *v1alpha1.Machine,
	lastOperation v1alpha1.LastOperation,
	currentStatus v1alpha1.CurrentStatus,
	lastKnownState string) error 
</code></pre>
<pre class="mermaid">%%{init: {'themeVariables': { 'fontSize': '10px'}, &quot;flowchart&quot;: {&quot;useMaxWidth&quot;: false }}}%%
flowchart TD

CreateClone[&quot;clone := machine.DeepCopy()&quot;]
--&gt;InitClone[&quot;
	clone.Status.LastOperation = lastOperation
	clone.Status.CurrentStatus = currentStatus
	clone.Status.LastKnownState = lastKnownState
&quot;]
--&gt;ChkSimilarStatus{&quot;isMachineStatusSimilar(
	clone.Status,
	machine.Status)&quot;}

ChkSimilarStatus--No--&gt;UpdateStatus[&quot;
	err:=c.controlMachineClient
	.Machines(clone.Namespace)
	.UpdateStatus(ctx, clone, metav1.UpdateOptions{})
&quot;]
--&gt;Z1((&quot;return err&quot;))
ChkSimilarStatus--Yes--&gt;Z2((&quot;return nil&quot;))
</pre>
<p>NOTE: <a href="https://github.com/gardener/machine-controller-manager/blob/v0.47.0/pkg/util/provider/machinecontroller/machine_util.go#L544">isMachineStatusSimilar</a> implementation is quite sad. TODO: we should improve stuff like this when we move to controller-runtime.</p>
<h2 id="controllerupdatenodeterminationcondition"><a class="header" href="#controllerupdatenodeterminationcondition">controller.UpdateNodeTerminationCondition</a></h2>
<p><a href="https://github.com/gardener/machine-controller-manager/blob/v0.47.0/pkg/util/provider/machinecontroller/machine_util.go#L1316">controller.UpdateNodeTerminationCondition</a> adds or updates the termination condition to the <code>Node.Status.Conditions</code> of the node object corresponding to the machine.</p>
<pre><code class="language-go">func (c *controller) UpdateNodeTerminationCondition(ctx context.Context, machine *v1alpha1.Machine) error 
</code></pre>
<pre class="mermaid">%%{init: {'themeVariables': { 'fontSize': '10px'}, &quot;flowchart&quot;: {&quot;useMaxWidth&quot;: false }}}%%
flowchart TD

Init[&quot;
	nodeName := machine.Labels['node']
	newTermCond := v1.NodeCondition{
		Type:               machineutils.NodeTerminationCondition,
		Status:             v1.ConditionTrue,
		LastHeartbeatTime:  Now(),
		LastTransitionTime: Now()}&quot;]
--&gt;GetCond[&quot;oldTermCond, err := nodeops.GetNodeCondition(ctx, c.targetCoreClient, nodeName, machineutils.NodeTerminationCondition)&quot;]
--&gt;ChkIfErr{&quot;err != nil ?&quot;}
ChkIfErr--Yes--&gt;ChkNotFound{&quot;apierrors.IsNotFound(err)&quot;}
ChkNotFound--Yes--&gt;ReturnNil((&quot;return nil&quot;))
ChkNotFound--No--&gt;ReturnErr((&quot;return err&quot;))
ChkIfErr--No--&gt;ChkOldTermCondNotNil{&quot;oldTermCond != nil
&amp;&amp; machine.Status.CurrentStatus.Phase 
== MachineTerminating ?&quot;}

ChkOldTermCondNotNil--No--&gt;ChkMachinePhase{&quot;Check\nmachine\n.Status.CurrentStatus\n.Phase?&quot;}
ChkMachinePhase--MachineFailed--&gt;NodeUnhealthy[&quot;newTermCond.Reason = machineutils.NodeUnhealthy&quot;]
ChkMachinePhase--&quot;else&quot;--&gt;NodeScaleDown[&quot;newTermCond.Reason=machineutils.NodeScaledDown
//assumes scaledown..why?&quot;]
NodeUnhealthy--&gt;UpdateCondOnNode[&quot;err=nodeops.AddOrUpdateConditionsOnNode(ctx, c.targetCoreClient, nodeName, newTermCond)&quot;]
NodeScaleDown--&gt;UpdateCondOnNode


ChkOldTermCondNotNil--Yes--&gt;CopyTermReasonAndMessage[&quot;
newTermCond.Reason=oldTermCond.Reason
newTermCond.Message=oldTermCond.Message
&quot;]
CopyTermReasonAndMessage--&gt;UpdateCondOnNode


UpdateCondOnNode--&gt;ChkNotFound
</pre>
<h2 id="controllerishealthy"><a class="header" href="#controllerishealthy">controller.isHealthy</a></h2>
<p>Checks if machine is healty by checking its conditions.</p>
<pre><code class="language-go">func (c *controller) isHealthy(machine *.Machine) bool 
</code></pre>
<pre class="mermaid">%%{init: {'themeVariables': { 'fontSize': '10px'}, &quot;flowchart&quot;: {&quot;useMaxWidth&quot;: false }}}%%
flowchart TD

Begin((&quot; &quot;))
--&gt;Init[&quot;
	conditions = machine.Status.Conditions
	badTypes = strings.Split(
	 'KernelDeadlock,ReadonlyFilesystem,DiskPressure,NetworkUnavailable', 
		',')
&quot;]--&gt;ChkCondLen{&quot;len(conditions)==0?&quot;}

ChkCondLen--Yes--&gt;ReturnF((&quot;return false&quot;))
ChkCondLen--No--&gt;IterCond[&quot;c:= range conditions&quot;]
IterCond--&gt;ChkNodeReady{&quot;c.Type=='Ready'
&amp;&amp; c.Status != 'True' ?&quot;}--Yes--&gt;ReturnF
ChkNodeReady
--Yes--&gt;IterBadConditions[&quot;badType := range badTypes&quot;]
--&gt;ChkType{&quot;badType == c.Type
&amp;&amp;
c.Status != 'False' ?&quot;}
--Yes--&gt;ReturnF

IterBadConditions--loop--&gt;IterCond
ChkType--loop--&gt;IterBadConditions




style Init text-align:left
</pre>
<p>NOTE</p>
<ol>
<li>controller.NodeConditions should be called controller.BadConditionTypes</li>
<li>Iterate over <code>machine.Status.Conditions</code>
<ol>
<li>If <code>Ready</code> condition inis not <code>True</code>, node is determined as un-healty.</li>
<li>If any of the bad condition types are detected, then node is determine as un-healthy</li>
</ol>
</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><ul>
<li><a href="machine-controller/node_drain.html#node-drain">Node Drain</a>
<ul>
<li><a href="machine-controller/node_drain.html#drain-utilities">Drain Utilities</a>
<ul>
<li><a href="machine-controller/node_drain.html#volumeattachmenthandler">VolumeAttachmentHandler</a></li>
</ul>
</li>
<li><a href="machine-controller/node_drain.html#drain">Drain</a>
<ul>
<li><a href="machine-controller/node_drain.html#drain-types">Drain Types</a>
<ul>
<li><a href="machine-controller/node_drain.html#drain-constants">Drain Constants</a></li>
<li><a href="machine-controller/node_drain.html#drainoptions">drain.Options</a></li>
</ul>
</li>
<li><a href="machine-controller/node_drain.html#drainpodvolumeinfo">drain.PodVolumeInfo</a></li>
<li><a href="machine-controller/node_drain.html#drainoptionsevictpod">drain.Options.evictPod</a></li>
<li><a href="machine-controller/node_drain.html#drainoptionsdeletepod">drain.Options.deletePod</a></li>
<li><a href="machine-controller/node_drain.html#drainoptionsrundrain">drain.Options.RunDrain</a>
<ul>
<li><a href="machine-controller/node_drain.html#drainfilterpodswithpv">drain.filterPodsWithPv</a></li>
</ul>
</li>
<li><a href="machine-controller/node_drain.html#drainoptionsevictpodswithoutpv">drain.Options.evictPodsWithoutPv</a>
<ul>
<li><a href="machine-controller/node_drain.html#drainoptionsevictpodwithoutpvinternal">drain.Options.evictPodWithoutPVInternal</a></li>
<li><a href="machine-controller/node_drain.html#ismisconfiguredpdb">isMisconfiguredPdb</a></li>
</ul>
</li>
<li><a href="machine-controller/node_drain.html#drainoptionsevictpodswithpv">drain.Options.evictPodsWithPv</a>
<ul>
<li><a href="machine-controller/node_drain.html#drainoptionsdoaccountingofpvs">drain.Options.doAccountingOfPvs</a></li>
<li><a href="machine-controller/node_drain.html#drainoptionsgetpvlist">drain.Options.getPVList</a></li>
<li><a href="machine-controller/node_drain.html#drainoptionsgetvolidsfromdriver">drain.Options.getVolIDsFromDriver</a></li>
<li><a href="machine-controller/node_drain.html#drainoptionsevictpodswithpvinternal">drain.Options.evictPodsWithPVInternal</a></li>
</ul>
</li>
<li><a href="machine-controller/node_drain.html#drainoptionswaitfordelete">drain.Options.waitForDelete</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<h1 id="node-drain"><a class="header" href="#node-drain">Node Drain</a></h1>
<p>Node Drain code is in <a href="https://github.com/gardener/machine-controller-manager/blob/v0.47.0/pkg/util/provider/drain/drain.go">github.com/gardener/machine-controller-manager/pkg/util/provider/drain/drain.go</a></p>
<h2 id="drain-utilities"><a class="header" href="#drain-utilities">Drain Utilities</a></h2>
<h3 id="volumeattachmenthandler"><a class="header" href="#volumeattachmenthandler">VolumeAttachmentHandler</a></h3>
<p><a href="https://pkg.go.dev/github.com/gardener/machine-controller-manager@v0.47.0/pkg/util/provider/drain#VolumeAttachmentHandler">pkg/util/provider/drain.VolumeAttachmentHandler</a> is an handler used to distribute
incoming <a href="https://pkg.go.dev/k8s.io/api/storage/v1#VolumeAttachment">k8s.io/api/storage/v1.VolumeAttachment</a> requests to a number of workers where each worker is a channel of type <code>*VolumeAttachment</code>. </p>
<p>A <a href="https://pkg.go.dev/k8s.io/api/storage/v1#VolumeAttachment">k8s.io/api/storage/v1.VolumeAttachment</a> is a non-namespaced k8s object that captures the intent to attach or detach the specified volume to/from the specified node. See <a href="machine-controller/../src/k8s_facilities.html#volumeattachment">VolumeAttachment</a></p>
<pre><code class="language-go">type VolumeAttachmentHandler struct {
	sync.Mutex
	workers []chan *storagev1.VolumeAttachment
}

// NewVolumeAttachmentHandler returns a new VolumeAttachmentHandler
func NewVolumeAttachmentHandler() *VolumeAttachmentHandler {
	return &amp;VolumeAttachmentHandler{
		Mutex:   sync.Mutex{},
		workers: []chan *storagev1.VolumeAttachment{},
	}
}
</code></pre>
<p>The <code>dispatch</code> method is responsible for distributing incomding <code>VolumeAttachent</code>s to available channels.</p>
<pre><code class="language-go">func (v *VolumeAttachmentHandler) dispatch(obj interface{}) {
	if len(v.workers) == 0 {
		// As no workers are registered, nothing to do here.
		return
	}
	volumeAttachment := obj.(*storagev1.VolumeAttachment)
	v.Lock()
	defer v.Unlock()

	for i, worker := range v.workers {
		select {
		case worker &lt;- volumeAttachment:
		default:
			klog.Warningf(&quot;Worker %d/%v is full. Discarding value.&quot;, i, worker)
			// TODO: Umm..isn't this problematic if we miss this ?
		}
	}
}
</code></pre>
<p>The <code>Add|Update</code> methods below delegate to dispatch. The usage of this utility involves specifying the add/update methods below as the event handler callbacks on an instance of <a href="https://pkg.go.dev/k8s.io/client-go@v0.25.2/informers/storage/v1#VolumeAttachmentInformer">k8s.io/client-go/informers/storage/v1.VolumeAttachmentInformer</a>. This way incoming volume attachments are distributed to several worker channels.</p>
<pre><code class="language-go">func (v *VolumeAttachmentHandler) AddVolumeAttachment(obj interface{}) {
	v.dispatch(obj)
}

func (v *VolumeAttachmentHandler) UpdateVolumeAttachment(oldObj, newObj interface{}) {
	v.dispatch(newObj)
}
</code></pre>
<h4 id="volumeattachmenthandler-usage"><a class="header" href="#volumeattachmenthandler-usage">VolumeAttachmentHandler Usage</a></h4>
<p>During construction of the MC:</p>
<pre><code class="language-go">volumeAttachmentInformer.Informer().AddEventHandler(
	cache.ResourceEventHandlerFuncs{
			AddFunc:    controller.volumeAttachmentHandler.AddVolumeAttachment,
			UpdateFunc: controller.volumeAttachmentHandler.UpdateVolumeAttachment,
});
</code></pre>
<h2 id="drain"><a class="header" href="#drain">Drain</a></h2>
<h3 id="drain-types"><a class="header" href="#drain-types">Drain Types</a></h3>
<h4 id="drain-constants"><a class="header" href="#drain-constants">Drain Constants</a></h4>
<ul>
<li><code>PodEvictionRetryInterval</code> is the interval in which to retry eviction for pods</li>
<li><code>GetPvDetailsMaxRetries</code> is the number of max retries to get PV details using the <a href="https://pkg.go.dev/k8s.io/client-go/listers/core/v1#PersistentVolumeLister">PersistentVolumeLister</a> or <a href="https://pkg.go.dev/k8s.io/client-go/listers/core/v1#PersistentVolumeClaimLister">PersistentVolumeClaimLister</a></li>
<li><code>GetPvDetailsRetryInterval</code> is the interval in which to retry getting PV details</li>
</ul>
<pre><code class="language-go">const (
    PodEvictionRetryInterval = time.Second * 20
	GetPvDetailsMaxRetries = 3
	GetPvDetailsRetryInterval = time.Second * 5
)
</code></pre>
<h4 id="drainoptions"><a class="header" href="#drainoptions">drain.Options</a></h4>
<p><code>drain.Options</code> are configurable options while draining a node before deletion</p>
<p>NOTE: Unused fields/Fields with constant defaults omitted for brevity</p>
<pre><code class="language-go">type Options struct {
	client                       kubernetes.Interface
	kubernetesVersion            *semver.Version
	Driver                       driver.Driver
	drainStartedOn               time.Time
	drainEndedOn                 time.Time
	ErrOut                       io.Writer
	ForceDeletePods              bool
	MaxEvictRetries              int32
	PvDetachTimeout              time.Duration
	PvReattachTimeout            time.Duration
	nodeName                     string
	Out                          io.Writer
	pvcLister                    corelisters.PersistentVolumeClaimLister
	pvLister                     corelisters.PersistentVolumeLister
	pdbV1Lister                  policyv1listers.PodDisruptionBudgetLister
	nodeLister                   corelisters.NodeLister
	volumeAttachmentHandler      *VolumeAttachmentHandler
	Timeout                      time.Duration
}

</code></pre>
<h3 id="drainpodvolumeinfo"><a class="header" href="#drainpodvolumeinfo">drain.PodVolumeInfo</a></h3>
<p><code>drain.PodVolumeInfo</code> is the struct used to encapsulate the PV names and PV ID's for all the <a href="https://kubernetes.io/docs/concepts/storage/persistent-volumes/">PVs</a> attached to the pod</p>
<pre><code class="language-go">PodVolumeInfo struct {
	persistentVolumeList []string
	volumeList           []string
}
</code></pre>
<p>NOTE: The struct fields are badly named.</p>
<ul>
<li><code>PodVolumeInfo.persistentVolumeList</code> is a slice of persistent volume names. This is from <a href="https://pkg.go.dev/k8s.io/api/core/v1#PersistentVolumeSpec">PersistentVolumeSpec.VolumeName</a></li>
<li><code>PodVolumeInfo.volumeList</code> is a slice of persistent volume IDs. This is obtained using <a href="machine-controller/../src/mcm_facilities.html#driver">driver.GetVolumeIDs</a> given the PV Spec.</li>
</ul>
<h3 id="drainoptionsevictpod"><a class="header" href="#drainoptionsevictpod">drain.Options.evictPod</a></h3>
<pre><code class="language-go">func (o *Options) evictPod(ctx context.Context, pod *corev1.Pod, policyGroupVersion string) error 
</code></pre>
<p><a href="https://github.com/gardener/machine-controller-manager/blob/v0.47.0/pkg/util/provider/drain/drain.go#L363">drain.Options.evictPod</a> is a simple helper method to evict a Pod using <a href="https://pkg.go.dev/k8s.io/client-go@v0.25.2/kubernetes/typed/policy/v1#EvictionExpansion">Eviction API</a></p>
<ul>
<li>TODO: <code>GracePeriodSeconds</code> in the code is useless here and should be removed as it is always -1.</li>
<li>TODO: Currently this method uses old <code>k8s.io/api/policy/v1beta1</code>. It must be changed to  <code>k8s.io/api/policy/v1</code>
TODO NOTE: </li>
</ul>
<pre class="mermaid">%%{init: {'themeVariables': { 'fontSize': '10px'}, &quot;flowchart&quot;: {&quot;useMaxWidth&quot;: false }}}%%
flowchart TD

Begin((&quot;&quot; ))
--&gt;InitTypeMeta[&quot;
		typeMeta:= metav1.TypeMeta{
			APIVersion: policyGroupVersion,
			Kind:       'Eviction',
		},
&quot;]
--&gt;InitObjectMeta[&quot;
		objectMeta := ObjectMeta: metav1.ObjectMeta{
			Name:      pod.Name,
			Namespace: pod.Namespace,
		},
&quot;]
--&gt;InitEviction[&quot;
eviction := &amp;.Eviction{TypeMeta: typeMeta, ObjectMeta: objectMeta }
&quot;]
--&gt;EvictPod[&quot;
 err := o.client.PolicyV1beta1().Evictions(eviction.Namespace).Evict(ctx, eviction)
&quot;]
--&gt;ReturnErr((&quot;return err&quot;))

style InitEviction text-align:left
</pre>
<h3 id="drainoptionsdeletepod"><a class="header" href="#drainoptionsdeletepod">drain.Options.deletePod</a></h3>
<p>Simple helper method to delete a Pod</p>
<pre><code class="language-go">func (o *Options) deletePod(ctx context.Context, pod *corev1.Pod) error {
</code></pre>
<p>Just delegates to <a href="https://pkg.go.dev/k8s.io/client-go@v0.25.2/kubernetes/typed/core/v1#PodInterface">PodInterface.Delete</a></p>
<pre><code class="language-go">o.client.CoreV1().Pods(pod.Namespace).Delete(ctx, pod.Name, metav1.DeleteOptions{} )
</code></pre>
<h3 id="drainoptionsrundrain"><a class="header" href="#drainoptionsrundrain">drain.Options.RunDrain</a></h3>
<pre><code class="language-go">func (o *Options) RunDrain(ctx context.Context) error
</code></pre>
<pre class="mermaid">%%{init: {'themeVariables': { 'fontSize': '10px'}, &quot;flowchart&quot;: {&quot;useMaxWidth&quot;: false }}}%%
flowchart TD


GetNode[&quot;node, err = .client.CoreV1().Nodes().Get(ctx, o.nodeName, metav1.GetOptions{})&quot;]
--&gt;ChkGetNodeErr{err != nil}

ChkGetNodeErr--Yes--&gt;ReturnNilEarly((&quot;return nil
(case where deletion 
triggered during machine creation, 
so node is nil. 
TODO: should use apierrors.NotFound)&quot;))

ChkGetNodeErr--No--&gt;ChkNodeUnschedulable{node.Spec.Unschedulable?}

ChkNodeUnschedulable--Yes--&gt;GetPodsForDeletion[&quot;
    pods, err := o.getPodsForDeletion(ctx)
    if err!=nil return err&quot;]
ChkNodeUnschedulable--No--&gt;CloneNode[&quot;clone := node.DeepCopy()
		clone.Spec.Unschedulable = true&quot;]
        --&gt;UpdateNode[&quot;_, err = o.client.CoreV1().Nodes().Update(ctx, clone, metav1.UpdateOptions{})
        if err != nil return err
        &quot;]

UpdateNode--&gt;GetPodsForDeletion
GetPodsForDeletion--&gt;GetEvictionPGV[&quot;
    policyGroupVersion, err := SupportEviction(o.client)
    if err != nil return err
    &quot;]
--&gt;
DefineAttemptEvict[&quot;
attemptEvict := !o.ForceDeletePods &amp;&amp; len(policyGroupVersion) &gt; 0
&quot;]
--&gt;
DefineGetPodFn[&quot;
getPodFn := func(namespace, name string) (*corev1.Pod, error) {
		return o.client.CoreV1().Pods(namespace).Get(ctx, name, metav1.GetOptions{})
}&quot;]
--&gt;
CreateReturnChannel[&quot;
    returnCh := make(chan error, len(pods))
	defer close(returnCh)
    &quot;]
--&gt;ChkForceDelPods{&quot;o.ForceDeletePods?&quot;}

ChkForceDelPods--Yes--&gt;EvictPodsWithoutPV[&quot;go o.evictPodsWithoutPv(ctx, attemptEvict, pods, policyGroupVersion, getPodFn, returnCh)
// go-routine feels un-necessary here.&quot;]
ChkForceDelPods--No--&gt;FilterPodsWithPv[&quot;
podsWithPv, podsWithoutPv := filterPodsWithPv(pods)
&quot;]

FilterPodsWithPv--&gt;EvictPodsWithPv[&quot;
go o.evictPodsWithPv(ctx, attemptEvict, podsWithPv, policyGroupVersion, getPodFn, returnCh)
&quot;]
--&gt;EvictPodsWithoutPV

EvictPodsWithoutPV--&gt;CreateAggregateError[&quot;
	var errors []error
    errors =
	for i = 0; i &lt;  len(pods); ++i {
		err := &lt;-returnCh
		if err != nil {
			errors = append(errors, err)
		}
	}
	
&quot;]
--&gt;ReturnAggError((&quot;return\nerrors.NewAggregate(errors)&quot;))

</pre>
<p>Notes:</p>
<ol>
<li><a href="https://github.com/gardener/machine-controller-manager/blob/v0.47.0/pkg/util/provider/drain/drain.go#L1106">machine-controller-manager/pkg/util/provider/drain.SupportEviction</a> uses Discovery API to find out if the server support eviction subresource and if so return its groupVersion or &quot;&quot; if it doesn't.
<ol>
<li><a href="https://pkg.go.dev/k8s.io/kubectl/pkg/drain#CheckEvictionSupport">k8s.io/kubectl/pkg/drain.CheckEvictionSupport</a> already does this.</li>
</ol>
</li>
<li><a href="https://github.com/gardener/machine-controller-manager/blob/v0.47.0/pkg/util/provider/drain/drain.go#L400">attemptEvict boolean</a> usage is confusing.</li>
</ol>
<h4 id="drainfilterpodswithpv"><a class="header" href="#drainfilterpodswithpv">drain.filterPodsWithPv</a></h4>
<p>NOTE: should have been named <code>partitionPodsWithPVC</code></p>
<p>Utility function that iterates through given <code>pods</code> and for each <code>pod</code>, iterates through its <code>pod.Spec.Volumes</code>. For each such pod <code>volume</code> checks <code>volume.PersistentVolumeClaim</code>. If not nil, adds <code>pod</code> to slice <code>podsWithPV</code> else adds <code>pod</code> to slice <code>podsWithoutPV</code></p>
<pre><code class="language-go">func filterPodsWithPv(pods []corev1.Pod) 
    (podsWithPV []*corev1.Pod, podsWithoutPV []*corev1.Pod) 
</code></pre>
<h3 id="drainoptionsevictpodswithoutpv"><a class="header" href="#drainoptionsevictpodswithoutpv">drain.Options.evictPodsWithoutPv</a></h3>
<p>drain method that iterates through each given pod and for each pod launches a go-routine that simply delegates to <code>Options.evictPodsWithoutPv</code>.</p>
<pre><code class="language-go">func (o *Options) evictPodsWithoutPv(ctx context.Context, 
    pods []*corev1.Pod,
	policyGroupVersion string, //eviction API's GV
	getPodFn func(namespace, name string) (*corev1.Pod, error),
	returnCh chan error) {
    for _, pod := range pods {
		go o.evictPodWithoutPVInternal(ctx, attemptEvict, pod, policyGroupVersion, getPodFn, returnCh)
	}
	return
}
</code></pre>
<p>NOTE:</p>
<ul>
<li><code>attemptEvict</code> parameter is very badly named. It is more meant to be a <code>retryEvict</code></li>
</ul>
<h4 id="drainoptionsevictpodwithoutpvinternal"><a class="header" href="#drainoptionsevictpodwithoutpvinternal">drain.Options.evictPodWithoutPVInternal</a></h4>
<p>drian method that  that either evicts or deletes a Pod with retry handling until <code>Options.MaxEvictRetries</code> is reached.</p>
<pre><code class="language-go">func (o *Options) evictPodWithoutPVInternal(
    ctx context.Context, 
    attemptEvict bool, 
    pod *corev1.Pod, 
    policyGroupVersion string, 
    getPodFn func(namespace, name string) (*corev1.Pod, error), 
    returnCh chan error) 

</code></pre>
<pre class="mermaid">%%{init: {'themeVariables': { 'fontSize': '10px'}, &quot;flowchart&quot;: {&quot;useMaxWidth&quot;: false }}}%%
flowchart TD


RangePod[&quot;pod := range pods&quot;]
RangePod--&gt;EvictOrDelPod[&quot;go evictPodWithoutPVInternal(attemptEvict bool, pod, policyGroupVersion,pod,getPodFn,returnCh)&quot;]
EvictOrDelPod--&gt;Begin

subgraph &quot;evictPodWithoutPVInternal (evicts or deletes Pod) &quot;
Begin((&quot;Begin&quot;))--&gt;SetRetry[&quot;retry := 0&quot;]
SetRetry
--&gt;SetAttemptEvict[&quot;if retry &gt;= o.MaxEvictRetries {attemptEvict=false}&quot;]
--&gt;ChkAttemptEvict{&quot;attemptEvict ?&quot;}

ChkAttemptEvict--Yes--&gt;EvictPod[&quot;err=o.evictPod(ctx, pod, policyGroupVersion)&quot;]
ChkAttemptEvict--No--&gt;DelPod[&quot;err=o.deletePod(ctx, pod)&quot;]

EvictPod--&gt;ChkErr
DelPod--&gt;ChkErr

ChkErr{&quot;Check err&quot;}
ChkErr--&quot;Nil&quot;--&gt;ChkForceDelPods
ChkErr--&quot;IsTooManyRequests(err)&quot;--&gt;GetPdb[&quot;
    // Possible case where Pod couldn't be evicted because of PDB violation
    pdbs, err = pdbLister.GetPodPodDisruptionBudgets(pod)
    pdb=pdbs[0] if err !=nil &amp;&amp; len(pdbs) &gt; 0
&quot;]
ChkErr--&quot;IsNotFound(err)\n(pod evicted)&quot;--&gt;SendNilChannel--&gt;NilReturn
ChkErr--&quot;OtherErr&quot;--&gt;SendErrChannel
GetPdb--&gt;ChkMisConfiguredPdb{&quot;isMisconfiguredPdb(pdb)?&quot;}
ChkMisConfiguredPdb--Yes--&gt;SetPdbError[&quot;err=fmt.Errorf('pdb misconfigured')&quot;]
SetPdbError--&gt;SendErrChannel

ChkMisConfiguredPdb--No--&gt;SleepEvictRetryInterval[&quot;time.Sleep(PodEvictionRetryInterval)&quot;]
SleepEvictRetryInterval--&gt;IncRetry[&quot;retry+=1&quot;]--&gt;SetAttemptEvict


SendErrChannel--&gt;NilReturn

ChkForceDelPods{&quot;o.ForceDeletePods&quot;}
ChkForceDelPods--&quot;Yes\n(dont wait for\npod disappear)&quot;--&gt;SendNilChannel
ChkForceDelPods--No--&gt;GetPodTermGracePeriod[&quot;
    // TODO: discuss this, shouldn't pod grace period override drain ?
    timeout=Max(pod.Spec.TerminationGracePeriodSeconds,o.timeout)
&quot;]
--&gt;SetBufferPeriod[&quot;bufferPeriod := 30 * time.Second&quot;]
--&gt;WaitForDelete[&quot;pendingPods=o.waitForDelete(pods, timeout,getPodFn)&quot;]
--&gt;ChkWaitForDelError{err != nil ?}

ChkWaitForDelError--Yes--&gt;SendErrChannel
ChkWaitForDelError--No--&gt;ChkPendingPodsLength{&quot;len(pendingPods) &gt; 0?&quot;}
ChkPendingPodsLength--Yes--&gt;SetTimeoutError[&quot;err = fmt.Errorf('pod term timeout')&quot;]
SetTimeoutError--&gt;SendErrChannel

ChkPendingPodsLength--No--&gt;SendNilChannel
end

SendNilChannel[&quot;returnCh &lt;- nil&quot;]
SendErrChannel[&quot;returnCh &lt;- err&quot;]
NilReturn((&quot;return&quot;))


</pre>
<h4 id="ismisconfiguredpdb"><a class="header" href="#ismisconfiguredpdb">isMisconfiguredPdb</a></h4>
<p>TODO: Discuss/Elaborate on why this is considered misconfigured.</p>
<pre><code class="language-go">func isMisconfiguredPdbV1(pdb *policyv1.PodDisruptionBudget) bool {
	if pdb.ObjectMeta.Generation != pdb.Status.ObservedGeneration {
		return false
	}

	return pdb.Status.ExpectedPods &gt; 0 &amp;&amp; 
        pdb.Status.CurrentHealthy &gt;= pdb.Status.ExpectedPods
        &amp;&amp; pdb.Status.DisruptionsAllowed == 0
}
</code></pre>
<h3 id="drainoptionsevictpodswithpv"><a class="header" href="#drainoptionsevictpodswithpv">drain.Options.evictPodsWithPv</a></h3>
<pre><code class="language-go">func (o *Options) evictPodsWithPv(ctx context.Context, 
    attemptEvict bool, 
    pods []*corev1.Pod,
	policyGroupVersion string,
	getPodFn func(namespace, name string) (*corev1.Pod, error),
	returnCh chan error)
</code></pre>
<p>NOTE</p>
<ul>
<li>See <a href="https://github.com/gardener/machine-controller-manager/blob/v0.47.0/pkg/util/provider/drain/drain.go#L580">drain.Options.evictPodsWithPv</a></li>
<li>This method basically delegates to <code>o.evictPodsWithPVInternal</code> with retry handling</li>
<li>TODO: UNHAPPY with logic of this method. Needs refactoring!</li>
<li>Flow diagram is a MESS because code is confusing. sorry.</li>
</ul>
<pre class="mermaid">%%{init: {'themeVariables': { 'fontSize': '10px'}, &quot;flowchart&quot;: {&quot;useMaxWidth&quot;: false }}}%%
flowchart TD

Begin((&quot; &quot;))
--&gt;SortPods[&quot;
    sortPodsByPriority(pods)
    //Desc priority: pods[i].Spec.Priority &gt; *pods[j].Spec.Priority
&quot;]
--&gt;DoVolumeAccounting[&quot;
	podVolumeInfoMap := o.doAccountingOfPvs(ctx, pods)
&quot;]
--&gt;ChkAttemptEvict{attemptEvict ?}

ChkAttemptEvict--Yes--&gt;RetryTillLimit[&quot;
	until MaxEvictRetries
&quot;]
--&gt;
InvokeHelper[&quot;
	remainingPods, aborted = o.evictPodsWithPVInternal(ctx, attemptEvict, pods, podVolumeInfoMap, policyGroupVersion,  returnCh)
&quot;]
InvokeHelper--&gt;ChkAbort{&quot;
	aborted ||
	len(remainingPods) == 0
&quot;}
ChkAbort--Yes--&gt;RangeRemainingPods
ChkAbort--No--&gt;Sleep[&quot;
	pods = remainingPods
	time.Sleep(PodEvictionRetryInterval)
&quot;]
Sleep--loop--&gt;RetryTillLimit

RetryTillLimit--loopend--&gt;ChkRemaining{&quot;len(remainingPods) &gt; 0?&quot;}
ChkRemaining--Yes--&gt;InvokeHelper1[&quot;
// force delete pods
	remainingPods, _ = o.evictPodsWithPVInternal(ctx, false, pods, podVolumeInfoMap, policyGroupVersion, getPodFn, returnCh)
&quot;]

ChkAttemptEvict--No--&gt;InvokeHelper1
InvokeHelper1--&gt;RangeRemainingPods
ChkRemaining--No--&gt;RangeRemainingPods

RangeRemainingPods[&quot;pod := range remainingPods&quot;]
RangeRemainingPods--aborted?--&gt;SendNil[&quot;returnCh &lt;- nil&quot;]
RangeRemainingPods--attemptEvict?--&gt;SendEvictErr[&quot;returnCh &lt;- fmt.Errorf('pod evict error')&quot;]
RangeRemainingPods--else--&gt;SendDelErr[&quot;returnCh &lt;- fmt.Errorf('pod delete error')&quot;]


SendNil--&gt;NilReturn
SendEvictErr--&gt;NilReturn
SendDelErr--&gt;NilReturn
NilReturn((&quot;return&quot;))
</pre>
<h4 id="drainoptionsdoaccountingofpvs"><a class="header" href="#drainoptionsdoaccountingofpvs">drain.Options.doAccountingOfPvs</a></h4>
<p><a href="https://github.com/gardener/machine-controller-manager/blob/v0.47.0/pkg/util/provider/drain/drain.go#L509">drain.Options.doAccountingOfPvs</a> returns a map of the pod key <code>pod.Namespace + '/' + pod.Name</code> to a <a href="machine-controller/node_drain.html#drainpodvolumeinfo">PodVolumeInfo</a> struct which holds a slice of PV names and PV IDs.</p>
<p>NOTES:</p>
<ul>
<li>See <a href="https://github.com/gardener/machine-controller-manager/blob/v0.47.0/pkg/util/provider/drain/drain.go#L544">filterSharedPVs</a></li>
</ul>
<pre class="mermaid">%%{init: {'themeVariables': { 'fontSize': '10px'}, &quot;flowchart&quot;: {&quot;useMaxWidth&quot;: false }}}%%
flowchart TD
Begin((&quot; &quot;))
--&gt;Init[&quot;
	podKey2VolNamesMap = make(map[string][]string)
	podKey2VolInfoMap = make(map[string]PodVolumeInfo)
&quot;]
--&gt;RangePods[&quot;
	for pod := range pods
&quot;]
--&gt;PopPod2VolNames[&quot;
	podKey2VolNamesMap[pod.Namespace + '/' pod.Name] = o.getPVList(pod)
&quot;]
--loop--&gt;RangePods
PopPod2VolNames--done--&gt;FilterSharedPVs[&quot;
	filterSharedPVs(podKey2VolNamesMap)
// filters out the PVs that are shared among pods.
&quot;]
--&gt;RangePodKey2VolNamesMap[&quot;
	for podKey, volNames := range podKey2VolNamesMap
&quot;]
--&gt;GetVolumeIds[&quot;
	volumeIds, err := o.getVolIDsFromDriver(ctx, volNames)
	if err != nil continue; //skip set of volumes
&quot;]
--&gt;InitPodVolInfo[&quot;
	podVolumeInfo := PodVolumeInfo{
			persistentVolumeList: volNames,
			volumeList:           volumeIds
	}
	//struct field names are bad.
&quot;]
--&gt;PopPodVolInfoMap[&quot;
	podVolumeInfoMap[podKey] = podVolumeInfo
&quot;]
--loop--&gt;RangePodKey2VolNamesMap
PopPodVolInfoMap--done--&gt;Return((&quot;return podVolumeInfoMap&quot;))
</pre>
<h4 id="drainoptionsgetpvlist"><a class="header" href="#drainoptionsgetpvlist">drain.Options.getPVList</a></h4>
<p>NOTE: Should be called <code>getPVNames</code>.  Gets a slice of the persistent volume names bound to the given <code>pod</code>. </p>
<pre><code class="language-go">func (o *Options) getPVList(pod *corev1.Pod) (pvNames []string, err error) 
</code></pre>
<ol>
<li>Iterate over <code>pod.Spec.Volumes</code>.</li>
<li>If <code>volume.PersistentVolumeClaim</code> reference is not nil, gets the <code>PersistentVolumeClaim</code> using <code>o.pvcLister</code> using <code>vol.PersistentVolumeClaim.ClaimName</code>.
<ol>
<li>Implements error handling and retry till <code>GetPvDetailsMaxRetries</code> is reached with interval <code>GetPvDetailsRetryInterval</code> for the above.</li>
</ol>
</li>
<li>Adds <code>pvc.Spec.VolumeName</code> to <code>pvNames</code></li>
<li>Return <code>pvNames</code></li>
</ol>
<h4 id="drainoptionsgetvolidsfromdriver"><a class="header" href="#drainoptionsgetvolidsfromdriver">drain.Options.getVolIDsFromDriver</a></h4>
<p>Given a slice of PV Names, this method gets the corresponding volume ids from the driver. </p>
<ul>
<li>It does this by first getting the <a href="https://pkg.go.dev/k8s.io/api/core/v1#PersistentVolumeSpec">PersistentVolumeSpec</a> using <code>o.pvLister.Get(pvName)</code> for each PV name and adding to the <code>pvSpecs</code> slice of type <code>PersistentVolumeSpec</code>. See <a href="https://pkg.go.dev/k8s.io/client-go/listers/core/v1#PersistentVolumeLister">k8s.io/client-go/listers/core/v1.PersistentVolumeLister</a></li>
<li>Retry handling is implemented here while looking up pvName till <code>GetPvDetailsMaxRetries</code> is reached with sleep interval of <code>GetPvDetailsRetryInterval</code> between each retry attempt.</li>
<li>Once <code>pvSpecs</code> slice is populated it constructs a <a href="https://pkg.go.dev/github.com/gardener/machine-controller-manager@v0.47.0/pkg/util/provider/driver#GetVolumeIDsRequest">driver.GetVolumeIDsRequest</a> from the same and then invokes <code>driver.GetVolumeIDs(driver.GetVolumeIDsRequest))</code> to obtain the <a href="https://pkg.go.dev/github.com/gardener/machine-controller-manager@v0.47.0/pkg/util/provider/driver#GetVolumeIDsResponse">driver.GetVolumeIDsResponse</a> and retruns <code>driver.GetVolumeIDsResponse.VolumeIDs</code></li>
</ul>
<p>TODO: BUG ? In case the PV is not found or retry limit is reached the slice of volume ids will not have a 1:1 correspondence with slice of PV names passed in.</p>
<pre><code class="language-go">func (o *Options) getVolIDsFromDriver(ctx context.Context, pvNames []string) ([]string, error)
</code></pre>
<h3 id="drainoptionsevictpodswithpvinternal"><a class="header" href="#drainoptionsevictpodswithpvinternal"># drain.Options.evictPodsWithPVInternal</a></h3>
<p><a href="https://github.com/gardener/machine-controller-manager/blob/v0.47.0/pkg/util/provider/drain/drain.go#L646">drain.Options.evictPodsWithPVInternal</a> is a drain helper method that actually evicts/deletes pods and waits for volume detachment. It returns a <code>remainingPods</code> slice and a <code>fastTrack</code> boolean is meant to abort the pod eviction and exit the calling go-routine. (TODO: should be called <code>abort</code> or even better should use custom error here)</p>
<pre><code class="language-go">func (o *DrainOptions) evictPodsWithPVInternal(ctx context.Context,
    attemptEvict bool, 
    pods []*corev1.Pod, 
    volMap map[string][]string,
	policyGroupVersion string,
	returnCh chan error
    ) (remainingPods []*api.Pod, fastTrack bool) 
</code></pre>
<h3 id="drainoptionswaitfordelete"><a class="header" href="#drainoptionswaitfordelete">drain.Options.waitForDelete</a></h3>
<p>NOTE: Ideally should have been named <code>waitForPodDisappearance</code></p>
<p><a href="https://github.com/gardener/machine-controller-manager/blob/v0.47.0/pkg/util/provider/drain/drain.go#L1068">pkg/util/provider/drain.Options.waitForDelete</a> is a helper method defined on <code>drain.Options</code> that leverages <a href="machine-controller/./k8s_facilities.html#waitpollimmediate">wait.PollImmediate</a> and the <code>getPodFn</code> (get pod by name and namespace) and checks that all pods have disappeared within <code>timeout</code>. The set of pods that did not disappear within timeout is returned as <code>pendingPods</code></p>
<pre><code class="language-go">func (o *Options) waitForDelete(
        pods []*corev1.Pod, interval, 
        timeout time.Duration,  
        getPodFn func(string, string) (*corev1.Pod, error)
    ) (pendingPods []*corev1.Pod, err error) 
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><p>üöß WIP at the moment. Lot more material to be added here from notes. Please do not read presently.</p>
<ul>
<li><a href="issues.html#issues">Issues</a>
<ul>
<li><a href="issues.html#design-issues">Design Issues</a>
<ul>
<li><a href="issues.html#bad-packaging">Bad Packaging</a></li>
<li><a href="issues.html#lastoperation-is-actually-next-operation">LastOperation is actually Next Operation</a></li>
<li><a href="issues.html#description-misused">Description misused</a></li>
</ul>
</li>
<li><a href="issues.html#gaps">Gaps</a>
<ul>
<li><a href="issues.html#deaddeprecated-code">Dead/Deprecated Code</a>
<ul>
<li><a href="issues.html#controllertriggerupdationflow">controller.triggerUpdationFlow</a>
<ul>
<li><a href="issues.html#safetyoptionsmachinedraintimeout">SafetyOptions.MachineDrainTimeout</a></li>
</ul>
</li>
<li><a href="issues.html#dup-code">Dup Code</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="issues.html#drainnode-handling">drainNode Handling</a></li>
<li><a href="issues.html#node-conditions">Node Conditions</a></li>
<li><a href="issues.html#volumeattachment">VolumeAttachment</a>
- <a href="issues.html#dead-reconcileclusternodekey">Dead? reconcileClusterNodeKey</a>
<ul>
<li><a href="issues.html#dead-machinego--triggerupdationflow">Dead? machine.go | triggerUpdationFlow</a></li>
</ul>
</li>
<li><a href="issues.html#duplicate-initialization-of-eventrecorder-in-mc">Duplicate Initialization of EventRecorder in MC</a>
<ul>
<li><a href="issues.html#q-internal-to-external-scheme-conversion">Q? Internal to External Scheme Conversion</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<h1 id="issues"><a class="header" href="#issues">Issues</a></h1>
<p>This section is very basic WIP atm. Please check after this warning has been removed. Lots more to be added here from notes and appropriately structured.</p>
<h2 id="design-issues"><a class="header" href="#design-issues">Design Issues</a></h2>
<h3 id="bad-packaging"><a class="header" href="#bad-packaging">Bad Packaging</a></h3>
<ul>
<li><code>package controller</code> is inside import path <code>github.com/gardener/machine-controller-manager/pkg/util/provider/machinecontroller</code></li>
</ul>
<h3 id="lastoperation-is-actually-next-operation"><a class="header" href="#lastoperation-is-actually-next-operation">LastOperation is actually Next Operation</a></h3>
<p>Badly named. TODO: Describe more.</p>
<h3 id="description-misused"><a class="header" href="#description-misused">Description misused</a></h3>
<p>Error Prone stuff like below due to misuse of description.</p>
<pre><code class="language-go">// isMachineStatusSimilar checks if the status of 2 machines is similar or not.
func isMachineStatusSimilar(s1, s2 v1alpha1.MachineStatus) bool {
	s1Copy, s2Copy := s1.DeepCopy(), s2.DeepCopy()
	tolerateTimeDiff := 30 * time.Minute

	// Since lastOperation hasn't been updated in the last 30minutes, force update this.
	if (s1.LastOperation.LastUpdateTime.Time.Before(time.Now().Add(tolerateTimeDiff * -1))) || (s2.LastOperation.LastUpdateTime.Time.Before(time.Now().Add(tolerateTimeDiff * -1))) {
		return false
	}

	if utilstrings.StringSimilarityRatio(s1Copy.LastOperation.Description, s2Copy.LastOperation.Description) &gt; 0.75 {
		// If strings are similar, ignore comparison
		// This occurs when cloud provider errors repeats with different request IDs
		s1Copy.LastOperation.Description, s2Copy.LastOperation.Description = &quot;&quot;, &quot;&quot;
	}

	// Avoiding timestamp comparison
	s1Copy.LastOperation.LastUpdateTime, s2Copy.LastOperation.LastUpdateTime = metav1.Time{}, metav1.Time{}
	s1Copy.CurrentStatus.LastUpdateTime, s2Copy.CurrentStatus.LastUpdateTime = metav1.Time{}, metav1.Time{}

	return apiequality.Semantic.DeepEqual(s1Copy.LastOperation, s2Copy.LastOperation) &amp;&amp; apiequality.Semantic.DeepEqual(s1Copy.CurrentStatus, s2Copy.CurrentStatus)
}

</code></pre>
<h2 id="gaps"><a class="header" href="#gaps">Gaps</a></h2>
<p>TODO: Not comprehensive. Lots more to be added here</p>
<h3 id="deaddeprecated-code"><a class="header" href="#deaddeprecated-code">Dead/Deprecated Code</a></h3>
<h4 id="controllertriggerupdationflow"><a class="header" href="#controllertriggerupdationflow">controller.triggerUpdationFlow</a></h4>
<p>This is unused and appears to be dead code.</p>
<h5 id="safetyoptionsmachinedraintimeout"><a class="header" href="#safetyoptionsmachinedraintimeout">SafetyOptions.MachineDrainTimeout</a></h5>
<p>This field is commented as deprecated but is still in <code>MCServer.AddFlags</code> and in the launch script of individual providers.
Ex</p>
<pre><code>go run
cmd/machine-controller/main.go
...
machine-drain-timeout=5m
</code></pre>
<h4 id="dup-code"><a class="header" href="#dup-code">Dup Code</a></h4>
<ul>
<li>Nearly all files in <code>pkg/controller/*.go</code></li>
<li>Ex: Types/func/smethods in <code>pkg/controller/machine_util.go</code>
<ul>
<li>Ex: Dup <a href="https://github.com/gardener/machine-controller-manager/blob/v0.47.0/pkg/controller/machine_util.go#L48">NodeTerminationCondition</a> in <code>pkg/controller/machine_util.go</code>. The one that is being actively used is <a href="https://github.com/gardener/machine-controller-manager/blob/v0.47.0/pkg/util/provider/machineutils/utils.go#L70">machineutils.NodeTerminationCondition</a></li>
</ul>
</li>
<li>Types/funcs/methods in <code>pkg/controller/drain.go</code> </li>
</ul>
<h2 id="drainnode-handling"><a class="header" href="#drainnode-handling">drainNode Handling</a></h2>
<ol>
<li>Does not set err when <code>c.machineStatusUpdate</code> is called</li>
<li><code>o.RunCordonOrUncordon</code> should use <code>apierrors.NotFound</code> while checking error returned by a get node op</li>
<li><a href="https://github.com/gardener/machine-controller-manager/blob/v0.47.0/pkg/util/provider/drain/drain.go#L400">attemptEvict bool usage</a> is confusing. Better design needed. <code>attemptEvict</code> is overridden in  <code>evictPodsWithoutPv</code>.</li>
<li>Misleading deep copy in <code>drain.Options.doAccountingOfPvs</code>
<pre><code class="language-go">for podKey, persistentVolumeList := range pvMap {
 	persistentVolumeListDeepCopy := persistentVolumeList
 	//...
</code></pre>
</li>
</ol>
<h2 id="node-conditions"><a class="header" href="#node-conditions">Node Conditions</a></h2>
<ul>
<li><code>CloneAndAddCondition</code> logic seems erroneous ?</li>
</ul>
<h2 id="volumeattachment-1"><a class="header" href="#volumeattachment-1">VolumeAttachment</a></h2>
<pre><code class="language-go">func (v *VolumeAttachmentHandler) dispatch(obj interface{}) {
//...
volumeAttachment := obj.(*storagev1.VolumeAttachment)
	if volumeAttachment == nil {
		klog.Errorf(&quot;Couldn't convert to volumeAttachment from object %v&quot;, obj)
		// Should return here.
	}
//...
</code></pre>
<h4 id="dead-reconcileclusternodekey"><a class="header" href="#dead-reconcileclusternodekey">Dead? reconcileClusterNodeKey</a></h4>
<p>This just delegates to <code>reconcileClusterNode</code> which does nothing..</p>
<pre><code class="language-go">func (c *controller) reconcileClusterNode(node *v1.Node) error {
	return nil
}

</code></pre>
<h3 id="dead-machinego--triggerupdationflow"><a class="header" href="#dead-machinego--triggerupdationflow">Dead? machine.go | triggerUpdationFlow</a></h3>
<p>Can't find usages</p>
<h2 id="duplicate-initialization-of-eventrecorder-in-mc"><a class="header" href="#duplicate-initialization-of-eventrecorder-in-mc">Duplicate Initialization of EventRecorder in MC</a></h2>
<p><code>pkg/util/provider/app.createRecorder</code> already dones this below.</p>
<pre><code class="language-go">func createRecorder(kubeClient *kubernetes.Clientset) record.EventRecorder {
eventBroadcaster := record.NewBroadcaster()
	eventBroadcaster.StartLogging(klog.Infof)
	eventBroadcaster.StartRecordingToSink(&amp;v1core.EventSinkImpl{Interface: v1core.New(kubeClient.CoreV1().RESTClient()).Events(&quot;&quot;)})
	return eventBroadcaster.NewRecorder(kubescheme.Scheme, v1.EventSource{Component: controllerManagerAgentName})
}
</code></pre>
<p>We get the recorder from this eventBroadcaster and then pass it to the <code>pkg/util/provider/machinecontroller/controller.NewController</code> method which again does:</p>
<pre><code class="language-go">	eventBroadcaster := record.NewBroadcaster()
	eventBroadcaster.StartLogging(klog.Infof)
	eventBroadcaster.StartRecordingToSink(&amp;typedcorev1.EventSinkImpl{Interface: typedcorev1.New(controlCoreClient.CoreV1().RESTClient()).Events(namespace)})
</code></pre>
<p>The above is useless.</p>
<h3 id="q-internal-to-external-scheme-conversion"><a class="header" href="#q-internal-to-external-scheme-conversion">Q? Internal to External Scheme Conversion</a></h3>
<p>Why do we do this ?</p>
<pre><code class="language-go">internalClass := &amp;machine.MachineClass{}
	err := c.internalExternalScheme.Convert(class, internalClass, nil)
	if err != nil {
		return err
	}
</code></pre>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->


                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">

            </nav>

        </div>




        <script type="text/javascript">
            window.playground_copyable = true;
        </script>


        <script src="elasticlunr.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="mark.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="searcher.js" type="text/javascript" charset="utf-8"></script>

        <script src="clipboard.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="highlight.js" type="text/javascript" charset="utf-8"></script>
        <script src="book.js" type="text/javascript" charset="utf-8"></script>

        <!-- Custom JS scripts -->
        <script type="text/javascript" src="mermaid.min.js"></script>
        <script type="text/javascript" src="mermaid-init.js"></script>

        <script type="text/javascript">
        window.addEventListener('load', function() {
            window.setTimeout(window.print, 100);
        });
        </script>

    </body>
</html>
